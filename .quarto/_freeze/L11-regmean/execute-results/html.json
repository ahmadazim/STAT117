{
  "hash": "703e15d0a5607a7c81f4156d99068787",
  "result": {
    "engine": "knitr",
    "markdown": "---\ndate: February 28, 2023\n---\n\n\n\\newpage\n\n# Lecture 11: Regression to the Mean\n\n## Intro\n\nRegression to the mean refers to the tendency of units selected based on performance in noisy criteria to revert back towards the center of the distribution of performance in replication experiments, or over time.\n\nIn this lecture we build some intuition based on a simple simulation and then explore regression to the mean in TCGA data. The goal is to motivate methods, like multilevel models, that can help you anticipate and predict the effects of regression to the mean on the practical performance of biomarkers selected through a discovery process.\n\n### Data\n\nContinuous genomic feature: gene expression microarray readout in the TCGA study\n\nBinary phenotype (optimal surgical debulking)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(curatedOvarianData)\nlibrary(ROCR)\ndata(TCGA_eset)\nXX = as.matrix(cbind(exprs(TCGA_eset)))\nYY = 1 * as.vector(pData(TCGA_eset)[,\"debulking\"]==\"optimal\")\nXX = XX[,!is.na(YY)]; \nYY = YY[!is.na(YY)]\n\nXXX = XX\nYYY = YY\n# subset\nsubs = 1:100\nXX = XX[,subs]; YY = YY[subs]\n```\n:::\n\n\nAs before, we create two sets of summary scores. `ScoresSub` yields the four metrics computed on the first 100 patients, while `ScoresAll` gives the four metrics computed on the entire set of patients.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"RScripts/Scores.R\")\nScoresSub = CompScores(XX,YY)\nScoresAll = CompScores(XXX,YYY)\n```\n:::\n\n\nWe also recreate the permutation distribution of the scores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\nYYNull = YY[ sample(1:length(YY)) ]\nScoresSubNull = CompScores(XX,YYNull)\n\nset.seed(1)\nYYYNull = YYY[ sample(1:length(YYY)) ]\nScoresAllNull = CompScores(XXX,YYYNull)\n```\n:::\n\n\n### Motivation\n\nBefore looking at regression to the mean, let's first consider some simple exploration of the TCGA data. I picked a cutoff on the AUC and applied it to both the subsample and the full sample. Then I cross-tabulated discoveries. I did that with both the real data and the data after permutation of the obtimal debulking label.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacut = .59\naucDiscSub = ScoresSub[,\"AUC\"]>acut\naucDiscSubNull= ScoresSubNull[,\"AUC\"]>acut\naucDiscAll = ScoresAll[,\"AUC\"]>acut\naucDiscAllNull = ScoresAllNull[,\"AUC\"]>acut\ntable(aucDiscSub,aucDiscAll)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          aucDiscAll\naucDiscSub FALSE TRUE\n     FALSE  9854   51\n     TRUE   3167   32\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(aucDiscSubNull)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\naucDiscSubNull\nFALSE  TRUE \n 9344  3760 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(aucDiscAllNull)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\naucDiscAllNull\nFALSE  TRUE \n13099     5 \n```\n\n\n:::\n:::\n\n\n::: callout-note\nWhat can we learn from the null distribution?\n:::\n\n\\newpage\n\n## Simulated Example\n\nSimulated example of the regression to the mean phenomenon. Here for simplicity I bypass the two group setting and just model a single group. The lessons in this example translate almost directly to making inferences on fold change. Fold change is defined over two groups. The analogy is between the means in this simulation and the *mean difference* in the two group case. The caveat is that the sample size does translate directly from one scenario to the other (the TCGA data are not paired), but the general behavior of the estimates as sample size(s) increase remains the same.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN1 = 10\nN2 = 100\nNG = 50\n\nset.seed(127)\nTrueNoise = rexp(NG,1/5)\nset.seed(123)\nTrueMeans = rnorm(NG,0,1)\nset.seed(124)\nMeans1 = rnorm(NG,TrueMeans,TrueNoise*sqrt(1/N1))\nset.seed(125)\nMeans2 = ( N1*Means1 + (N2-N1) * \n             rnorm(NG,TrueMeans,TrueNoise*sqrt(1/(N2-N1))) ) / N2\n```\n:::\n\n\nIn this simulation, I introduce two sources of variation: variation in the gene-level parametrs (TrueMeans and TrueNoise) and sampling variation. As you go through the results try to tease out the roles of these two sources of variation. Figuring it out on your own is the best strategy. This is a good read if you are stuck [\\@Barnett2004ije](https://doi.org/10.1093/ije/dyh299)\n\n\\newpage\n\nSelecting biomarkers based on fold change after 10 and 100 observations\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncutoff = 1.4\nTrueDiscoveries = abs(TrueMeans) > cutoff\nDiscoveries1 = abs(Means1) > cutoff\nDiscoveries2 = abs(Means2) > cutoff\nND = sum(Discoveries1)\n```\n:::\n\n\nCross-tabulating result, with gold standard\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(Discoveries1,Discoveries2,TrueDiscoveries)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n, , TrueDiscoveries = FALSE\n\n            Discoveries2\nDiscoveries1 FALSE TRUE\n       FALSE    26    1\n       TRUE     16    1\n\n, , TrueDiscoveries = TRUE\n\n            Discoveries2\nDiscoveries1 FALSE TRUE\n       FALSE     0    1\n       TRUE      2    3\n```\n\n\n:::\n:::\n\n\n\\newpage\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(c(0,N2*1.2),range(Means1),type=\"n\",\n     xlab=\"SAMPLE SIZE\",ylab=\"FOLD CHANGE\")\npoints(rep(0,ND),TrueMeans[Discoveries1==\"TRUE\"],pch=\"-\",cex=2,col=\"red\")\npoints(rep(N1,ND),Means1[Discoveries1==\"TRUE\"],pch=\"-\",cex=2)\npoints(rep(N2,ND),Means2[Discoveries1==\"TRUE\"],pch=\"-\",cex=2)\nsegments(rep(0,ND),TrueMeans[Discoveries1==\"TRUE\"],\n         rep(N1,ND),Means1[Discoveries1==\"TRUE\"])\nsegments(rep(N1,ND),Means1[Discoveries1==\"TRUE\"],\n         rep(N2,ND),Means2[Discoveries1==\"TRUE\"])\nabline(h=cutoff,col=\"blue\",lwd=2)\nabline(h=-cutoff,col=\"blue\",lwd=2)\n```\n\n::: {.cell-output-display}\n![Each line corresponts to a simulated marker. True means are graphed at n=0 in red. Blue lines represent discovery cutoffs. Only marker that exceed the cutoffs in absolute value at n=10 (small study) are graphed here.](L11-regmean_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\\newpage\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(c(0,N2*1.2),range(Means1),type=\"n\",\n     xlab=\"SAMPLE\",ylab=\"ESTIMATED FOLD CHANGE\")\npoints(rep(0,NG),TrueMeans,pch=\"-\",cex=2, col = \"red\")\npoints(rep(N1,NG),Means1,pch=\"-\",cex=2)\npoints(rep(N2,NG),Means2,pch=\"-\",cex=2)\nsegments(rep(0,NG),TrueMeans,rep(N1,NG),Means1)\nsegments(rep(N1,NG),Means1,rep(N2,NG),Means2)\n```\n\n::: {.cell-output-display}\n![Each line corresponts to a simulated marker. True means are graphed at n=0 in red. Blue lines represent discovery cutoffs. Same as the previous figure except now all markers are graphed.](L11-regmean_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\\newpage\n\n## Regression to the mean in the TCGA data\n\n\n::: {.cell}\n\n```{.r .cell-code}\npcut = 4.25\nacut = .66\nfcut = .5\n\nallTrue = abs(ScoresSub[,\"FoldChange\"])>fcut & \n  ScoresSub[,\"nlpvalueT\"]>pcut & ScoresSub[,\"AUC\"]>acut\naucOnly = abs(ScoresSub[,\"FoldChange\"])<fcut & \n  ScoresSub[,\"nlpvalueT\"]<pcut & ScoresSub[,\"AUC\"]>acut\npOnly = abs(ScoresSub[,\"FoldChange\"])<fcut & \n  ScoresSub[,\"nlpvalueT\"]>pcut & ScoresSub[,\"AUC\"]<acut\nfcOnly = abs(ScoresSub[,\"FoldChange\"])>fcut & \n  ScoresSub[,\"nlpvalueT\"]<pcut & ScoresSub[,\"AUC\"]<acut\nfcDisc = abs(ScoresSub[,\"FoldChange\"])>fcut\n```\n:::\n\n\n\\newpage\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN1 = 100\nN2 = length(YYY)\nNG = nrow(XXX)\nNDfc = sum(fcDisc)\nplot(c(N1*.8,N2*1.2),range(ScoresSub[,\"FoldChange\"]),\n     type=\"n\",xlab=\"SAMPLE\",ylab=\"ESTIMATED FOLD CHANGE\")\ntitle(\"\")\npoints(rep(N1,NDfc),ScoresSub[fcDisc,\"FoldChange\"],\n       pch=\"-\",cex=2)\npoints(rep(N2,NDfc),ScoresAll[fcDisc,\"FoldChange\"],\n       pch=\"-\",cex=2)\nsegments(rep(N1,NDfc),ScoresSub[fcDisc,\"FoldChange\"],\n         rep(N2,NG),ScoresAll[fcDisc,\"FoldChange\"])\n```\n\n::: {.cell-output-display}\n![Same format as simulated data (except no truth :). Only plotting markers discovered by fold change int he small sample at a threshold of .05.](L11-regmean_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\\newpage\n\n::: callout-note\nYou are the advisor to an investor who is considering funding a company that collected data on 100 samples. The company is proposing to commercialize a marker whose fold change is greater than 1, emphasizing the clinical implication of such a large difference. You have seen data like this figure before. How do you explain to the investor what is likely to happen and why?\n:::\n\n\\newpage\n\nScatterplot version of the same data, to emphasize \"shrinkage\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nScores0 = ScoresSub[fcOnly,]\nScores1 = CompScores(XXX[fcOnly,],YYY)\nplot(Scores0[,\"FoldChange\"],Scores1[,\"FoldChange\"],\n     asp=1,ylim=range(Scores0[,\"FoldChange\"]))\nabline(h=fcut); abline(h=-fcut); abline(v=fcut)\nabline(v=-fcut); abline(0,1)\n```\n\n::: {.cell-output-display}\n![](L11-regmean_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\\newpage\n\nLet's now look at the p-value counterpart of this figure.\n\n\n::: {.cell cfig.height='5' ache='true'}\n\n```{.r .cell-code}\nScores0 = ScoresSub[pOnly,]\nScores1 = CompScores(XXX[pOnly,],YYY)\n#par(pty=\"s\")\nplot(Scores0[,\"nlpvalueT\"],Scores1[,\"nlpvalueT\"],\n     xlim=c(min(Scores1[,\"nlpvalueT\"]),max(Scores1[,\"nlpvalueT\"])))\nabline(v=pcut); abline(h=pcut); abline(0,1)\n```\n\n::: {.cell-output-display}\n![](L11-regmean_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n::: callout-note\n-   compare and contrast the effect a bigger sample the means to the effect on the negative log p-values\n:::\n\n\\newpage\n\n## References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}