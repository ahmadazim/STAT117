{"title":"Lecture 12: Shrinkage","markdown":{"headingText":"Lecture 12: Shrinkage","containsRefs":false,"markdown":"\n## Recap\n\nSo far, we have studied the following concepts:\n\n```{=tex}\n\\begin{itemize}\n\\item Metrics for assessing whether a biomarker is potentially useful\n\\item Discovery Rates for biomarker lists obtained by selecting a subset based on these metrics\n\\item Regression to the mean of performance metrics\n\\end{itemize}\n```\n## Multilevel Models\n\n### Motivation\n\nIn this chapter we are going to start thinking about what about multi-level models. These specify a joint statistical model, not just for an individual biomarker in an individual study, but either multiple biomarkers or multiple studies at the same time. And if we get adventurous before the end of the course we will write models where encompassing both multiple biomarkers and multiple studies. The idea for this chapter is to do one of these at the time.\n\nSome of the main concepts will be:\n\n```{=tex}\n\\begin{itemize}\n\\item Heterogeneity\n\\item Random Effects\n\\item Multi-level Models\n\\end{itemize}\n```\nThe methods we will utilize will be Monte Carlo Markov Chains (MCMC).\n\nAnalyses of individual biomarkers are seemingly separate problems, which in reality share important statistical features. Importantly they share common sources of noise from the technology.\n\nAnalyses of the same gene in different studies are seemingly identical problems, which in reality present important differences. Importantly they inherit differences in study inclusion criteria, design and populations.\n\n\\newpage\n\n### Data Structure\n\nLet's begin by reminding ourselves of the data structure that we're going to be using. It is essentially the data structure of our curated ovarian data, where you have a set of studies, each of which includes a matrix of biomarkers and a vector of labels.\n\n```{=html}\n<!---\n\\begin{figure}[h]\n\\centerline{\\includegraphics[width=.8\\textwidth]{figures/multilevel.pdf}}\n\\caption{\\label{podlaha2}}\n\\end{figure}\n\\newpage\n-->\n```\nLet's focus on a single biomarker, say CXCL12, in a single study. There you have a row of $X$ that represents the levels of CXCL12 and you have a role a corresponding row of labels. That's the structure on which we have looked at all our statistics so far, when we did when we did discovery. We did a battery of these, but we always did them one at a time.\n\nHere we are going to think about extending this paradigm in two directions. One is to look at variability across biomarkers within a study (this lecture), and the other is to look at variability of biomarker behavior across studies (next lecture).\n\n\\newpage\n\n## Multilevel Modeling of Genes\n\n### Reasons for modeling genes as if coming from a higher level population\n\n```{=tex}\n\\begin{itemize}\n\\item\nGenome features share sources of variation, both biological and technological.\nThey are not independent.  \n\\item\nMultilevel models consider the gene to gene variability explicitly.\n\\item\nSimultaneous estimation of many related quantities is an old\n  problem in statistics.\n\\item\nKeywords: Stein (50's), Empirical Bayes, Hierarchical Bayes.\n\\item\nMultilevel models have been explored for microarrays since the earliest\ndays. \n\\end{itemize}\n```\n\\newpage\n\nSince the \"MCMC revolution\" multilevel models have been the backbone of Bayesian data analysis\n\nIn genomic data sets they can be used to implement:\n\n```{=tex}\n\\begin{itemize} \n\\item Shrinkage\n\\item Sparsity / Built-in Hypothesis Testing\n\\item Modular Structures\n\\item Flexible \"not-so-parametric\" models via mixtures\n\\item Useful Latent Classes\n\\item Small Samples Uncertainty Assessment\n\\end{itemize}\n```\nThis is a useful introduction. [Laredo](http://research.iac.es/winterschool/2014/media/loredo/iac14-3-IntroMLMs.pdf) provides a very useful introduction (pages 1-28) and a cool application in astronomy. I recommend you go over pages 1-28 before going forward with our lecture notes.\n\nFor those who want to dig a bit deeper [Morris and Lysy](https://arxiv.org/pdf/1203.5610.pdf) offer a great review.\n\nMost textbooks on Bayesian statistics have chapters on multi-level models.\n\n\\newpage\n\n### Differential Expression Analysis of TCGA\n\nGene-level Summaries:\n\n```{=tex}\n\\begin{center} \n\\begin{tabular}{ll}\n\\hline\n Overall Average (Abundance) & $a_g$ \\\\ \\hline\n Difference Between Group Averages & $d_g$ \\\\ \\hline\n Within-class Standard deviation & $s_g$ \\\\ \\hline\n Their ratio & $d_g / s_g$ \\\\ \\hline\n\\end{tabular}\n\\end{center}\n```\ncontinuous genomic feature: gene expression microarray readout in the TCGA study\n\nbinary phenotype (optimal surgical debulking)\n\n\\newpage\n\n```{r, cache=TRUE, message=F, warnings = F}\nlibrary(curatedOvarianData)\ndata(\"TCGA_eset\")\nXX = as.matrix(cbind(exprs(TCGA_eset)))\nYY = 1 * as.vector(pData(TCGA_eset)[,\"debulking\"]==\"optimal\")\nXX = XX[,!is.na(YY)];\nYY = YY[!is.na(YY)]\n```\n\n\\newpage\n\nCompute Gene-Level Summaries\n\n<!-- redo with class-conditional variance -->\n\n```{r, cache=TRUE}\nCompSummaries = function(XX,YY){\nNGenes = nrow(XX)\nSSS = data.frame(matrix(NA,NGenes,4))\ncolnames(SSS) = \n  c(\"abundance\",\"difference\",\"variance\",\"SNratio\")\nfor (gg in 1:NGenes){\n  SSS[gg,\"abundance\"] = mean(XX[gg,])\n  m1 = mean( XX[gg,YY==1] ); m0 = mean( XX[gg,YY==0] ); \n  n1 = sum(YY==1); n0 = sum(YY==0); \n  SSS[gg,\"difference\"] = m1 - m0\n  SSS[gg,\"variance\"] = ( sum( ( XX[gg,YY==1] - m1 )^2 ) + sum( ( XX[gg,YY==0] - m0 )^2 ) ) / (n0+n1-2)\n  SSS[gg,\"SNratio\"] = \n    SSS[gg,\"difference\"] / sqrt( SSS[gg,\"variance\"] )\n}\nreturn(SSS)\n}\nGeneSummaries = CompSummaries(XX,YY)\n```\n\n\\newpage\n\n### Exploring marginal distributions\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\nhist(GeneSummaries[,\"abundance\"],nclass=100)\n```\n\n\\newpage\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\nhist(GeneSummaries[,\"difference\"],nclass=100)\n```\n\n\\newpage\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\nqqnorm(GeneSummaries[,\"difference\"])\n```\n\n\\newpage\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\nhist(sqrt(GeneSummaries[,\"variance\"]),nclass=100)\n```\n\n\\newpage\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\nhist(GeneSummaries[,\"SNratio\"],nclass=100)\n```\n\n### Exploring joint distributions\n\n\\newpage\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\nplot(GeneSummaries[,\"abundance\"],GeneSummaries[,\"difference\"],pch=\".\")\n```\n\n\\newpage\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\nplot(GeneSummaries[,\"abundance\"],sqrt(GeneSummaries[,\"variance\"]),pch=\".\")\n```\n\n\\newpage\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\nplot(sqrt(GeneSummaries[,\"variance\"]),GeneSummaries[,\"difference\"],pch=\".\")\n```\n\n\\newpage\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\nplot(GeneSummaries[,\"abundance\"],GeneSummaries[,\"SNratio\"],pch=\".\")\n```\n\n\\newpage\n\n### Gene-specific Distribution\n\nWe begin with a relatively simple setting where the class-conditional distributions are gaussian.\n\n```{=tex}\n\\begin{tabular}{p{6in}} \n      \\begin{eqnarray*} \n        X_{0gi} | \\alpha_{g}, \\sigma_g^2 , \\delta_g &\\sim& \n        N \\left( \\alpha_{g} - \\pi \\delta_g, \\sigma_g^2 \\right)  \\\\\n        X_{1gi} | \\alpha_{g} , \\sigma_g^2, \\delta_g &\\sim& \n        N \\left( \\alpha_{g} + (1-\\pi) \\delta_g,   \\sigma_g^2 \\right)\n      \\end{eqnarray*}\n    \\end{tabular}\n```\nEach gene distribution is characterized by three parameters:\n\n$\\delta_g$: true mean difference across classes\n\n$\\sigma_g$: true noise, common to both classes\n\n$\\alpha_g$: true abundance (average overeall expression marginally)\n\nIn addition we have $\\pi$: proportion of label 1's, assumed known.\n\nGenes are assumed to be conditionally independent.\n\n::: callout-note\nIn this model, does the data on genes 2 through G give you information you did not have before about gene 1?\n\nWhy or why not?\n:::\n\n\\newpage\n\n### Distribution of gene specific parameters across the genome\n\nOu next step is to model the distribution of the gene specific parameters, to describe how these parameters vary across the genome. We have three of them and we can make all sorts of assumptions about how they are jointly distributed. Here are some options\n\n```{=tex}\n\\begin{tabular}{|p{4in}|p{4in}|}\n  \\hline\n  \\multicolumn{1}{|c|}{II. Independence}  &\n  \\multicolumn{1}{c|}{CI. S\\&N Independence} \\\\ \n  \\begin{eqnarray*}\n    \\alpha_g | \\tau^2  &\\sim&  N ( 0, \\tau^2 ) \\\\\n    \\delta_g | \\lambda^2 &\\sim& N(0,\\lambda^2) \\\\\n    \\sigma_g^{-2}| \\nu, \\beta &\\sim& Ga (\\nu, \\beta)\n  \\end{eqnarray*}\n  & \n  \\begin{eqnarray*}\n    \\alpha_g | \\tau^2, \\sigma^{2}_g  & \\sim & \n    N ( 0, {\\sigma^{2}_g} \\tau^2 ) \\\\\n    \\delta_g | \\lambda^2\n    & \\sim & N ( 0, \\lambda^2 ) \\\\\n    \\sigma^{-2}_g | \\nu, \\beta & \\sim & Ga (\\nu, \\beta) \n  \\end{eqnarray*} \\\\\n  \\hline\n  \\multicolumn{1}{|c|}{IC. A\\&N Independence}  &\n  \\multicolumn{1}{c|}{CC. Complete Conjugacy} \\\\\n  \\begin{eqnarray*}\n    \\alpha_g | \\tau^2 & \\sim & \n    N ( 0, \\tau^2 ) \\\\\n    \\delta _g | \\lambda^2, \\sigma^{2}_g  \n    & \\sim & N ( 0, {\\sigma^{2}_g} \\lambda^2 ) \\\\\n    \\sigma^{-2}_g | \\nu, \\beta & \\sim & Ga (\\nu, \\beta) \n  \\end{eqnarray*}& \n  \\begin{eqnarray*}\n    \\alpha_g | \\tau^2, \\sigma^{2}_g  & \\sim & \n    N ( 0, {\\sigma^{2}_g} \\tau^2 ) \\\\\n    \\delta _g | \\lambda^2, \\sigma^{2}_g  \n    & \\sim & N ( 0, {\\sigma^{2}_g} \\lambda^2 ) \\\\\n    \\sigma^{-2}_g | \\nu, \\beta & \\sim & Ga (\\nu, \\beta) \n  \\end{eqnarray*} \\\\\n  \\hline\n\\end{tabular}\n```\n\\newpage\n\n### Estimation Methods: 1. Empirical Bayes\n\nGene-level Parameters: $\\theta_g = (\\alpha_g,\\delta_g,\\sigma_g)$\n\nGenome-level Parameters: $\\gamma = \\tau, \\lambda, \\nu, \\beta$\n\nData: $D$\n\nLikelihood: $p( D | \\gamma, \\theta_1, \\ldots, \\theta_G)$\n\n```{=tex}\n\\begin{itemize} \n\\item Derive or approximate marginal Likelihood $p( D | \\gamma)$\n\\item Find $\\hat \\gamma$ maximizing marginal likelihood.\n\\item Estimate $\\theta_g$ one gene at the time using $p( D | \\hat \\gamma, \\theta_g)$ (other genes can be left out because of conditional independence)\n\\end{itemize}\n```\nThis bypasses specification of a prior at the top level, and still gives a shrinkage estimate of the gene-level parameters.\n\nFor example in the conjugate model written earlier:\n\n$$ E ( \\delta_g | D, \\gamma) = d_g  \\left( \\frac {1}{ 1 + \\frac {2}{\\lambda n}} \\right)$$\n\nThis provides a shrinkage estimate of $\\delta_g$. The amount of shrinkage is controlled by the estimate of $\\lambda$, the genome-wide variance of the $\\delta$'s\n\n\\newpage\n\n### Estimation Methods: 2. MCMC\n\nDraw samples of parameters to get a sense for their location and spread.\n\n```{=tex}\n\\begin{itemize} \n\\item Derive or approximate \"full conditional distributions\" \n\n$p( \\gamma | D, \\theta_1, \\ldots, \\theta_G))$\n\n$p( \\theta_1 | D, \\gamma, \\theta_2, \\ldots, \\theta_G))$\n\n....\n\n$p( \\theta_G | D, \\gamma, \\theta_1, \\ldots, \\theta_{G-1}))$\n\n\\item Iteratively simulate samples of parameters looping through these.\n\\item Summarize the simulation to derive parameter estimates.\n\n\\end{itemize}\n```\n\\newpage\n\n### MCMC Illustration\n\nWe select genes with an abundance of at least 5, and then take a random sample of the rest.\n\n```{r, cache=TRUE}\nhighAbundance = GeneSummaries[,\"abundance\"] > 5\nXXX = XX[highAbundance,]\nNha = sum(highAbundance)\nset.seed(117)\nNinclude = 900\ninclude = sample(1:Nha,Ninclude)\nXXX = XXX[include,]\nYYY = YY\nGeneSummInclude = CompSummaries(XXX,YYY)\n```\n\n\\newpage\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\npairs(GeneSummInclude,pch=\".\")\n```\n\n\\newpage\n\n### Conjugate Model\n\n```{r}\ndiffexpModel =\"model\n{\n  precision.s ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.a ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.d ~ dnorm( 0.0, 0.01 ) T(0,);\n  for ( g in 1:G ){\n    sigma2inv[g] ~ dnorm( 0.0, precision.s ) T(0,);\n    alpha[g] ~ dnorm(cut, precision.a) T(cut,);\n    delta[g] ~ dnorm(0.0, sigma2inv[g] * precision.d);\n  }\n  for ( g in 1:G ) {\n    for ( i in 1:N ) {\n            XX[g,i] ~ dnorm( alpha[g] + \n            ( YY[i] * (1-pi) - \n            (1-YY[i]) * pi ) * delta[g], sigma2inv[g]);\n      } \n    }\n}\n\"\n```\n\n\\newpage\n\n```{r, cache=TRUE, message=F}\nlibrary(rjags)\nlibrary(R2jags)\nlibrary(coda)\ndiffexp = jags.model(textConnection(diffexpModel),\n                   data = list( XX = XXX, YY=YYY, N=length(YYY), G=nrow(XXX), pi=mean(YYY),cut=5),\n                   n.chains = 1,\n                   n.adapt = 100)\n\nmcmc.out = coda.samples(diffexp,c(\"alpha\",\"delta\",\"sigma2inv\",\n                                  \"precision.a\",\"precision.d\",\"precision.s\"),\n                        n.iter = 1000,thin=10)\nalpha = mcmc.out[[1]][,grep(\"alpha\",colnames(mcmc.out[[1]]))]\ndelta = mcmc.out[[1]][,grep(\"delta\",colnames(mcmc.out[[1]]))]\nsigma = 1 / sqrt( mcmc.out[[1]][,grep(\"sigma2inv\",colnames(mcmc.out[[1]]))] )\nalpha.hat = apply(alpha,2,mean)\ndelta.hat = apply(delta,2,mean)\n```\n\n\\newpage\n\nOne way to look at shrinkage is to compare the posterior estimates to the corresponding gene-specific MLEs.\n\nLet's look at the $\\alpha$'s\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\nplot(GeneSummInclude[,\"abundance\"],alpha.hat)\n```\n\n\\newpage\n\nLet's now look at the $\\delta$'s\n\n```{r, cache=TRUE, fig.height=10, fig.width=10}\nplot(GeneSummInclude[,\"difference\"],delta.hat)\nabline(0,1)\n```\n\n\\newpage\n\n::: callout-note\nwhy is the shrinkage of the alpha's so much less pronounced than the shrinkage of the delta's?\n:::\n\n\\newpage\n\n### Point and slab Model\n\nTo contrast, this code implements a point and slab model which assumes that some unknown proportion of genes have a $\\delta$ that is superclose to zero.\n\n::: callout-note\nCan you tell how I did that?\n\nHow do we interpert the hh variable?\n\nWhy is hh a good letter in this case?\n:::\n\n```{r, cache=TRUE}\ndiffexpModel.01 =\"model\n{\n  precision.s ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.a ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.d ~ dnorm( 0.0, 0.01 ) T(0,);\n  ph0 ~ dunif(0,1);\n  for ( g in 1:G ){\n    hh[g] ~ dbern(1-ph0);\n    sigma2inv[g] ~ dnorm( 0.0, precision.s ) T(0,);\n    alpha[g] ~ dnorm(cut, precision.a) T(cut,);\n     delta[g] ~ dnorm(0.0, (1-hh[g]) * 10000 + hh[g] * sigma2inv[g] * (precision.d)  );\n  }\n  for ( g in 1:G ) {\n    for ( i in 1:N ) {\n            XX[g,i] ~ dnorm( alpha[g] + \n            ( YY[i] * (1-pi) - \n            (1-YY[i]) * pi ) * delta[g], sigma2inv[g] );\n      } \n    }\n}\n\"\n```\n\n\\newpage\n\n```{r, cache=TRUE}\nlibrary(rjags)\nlibrary(R2jags)\nlibrary(coda)\ndiffexp = jags.model(textConnection(diffexpModel.01),\n                   data = list( XX = XXX, YY=YYY, N=length(YYY), G=nrow(XXX), pi=mean(YYY),cut=5 ),\n                   n.chains = 1,\n                   n.adapt = 100)\n\nmcmc.out = coda.samples(diffexp,c(\"alpha\",\"delta\",\"sigma2inv\",\"hh\",\"ph0\",\n                                  \"precision.a\",\"precision.d\",\"precision.s\"),\n                        n.iter = 1000,thin=10)\nalpha = mcmc.out[[1]][,grep(\"alpha\",colnames(mcmc.out[[1]]))]\ndelta = mcmc.out[[1]][,grep(\"delta\",colnames(mcmc.out[[1]]))]\nsigma = 1 / sqrt( mcmc.out[[1]][,grep(\"sigma2inv\",colnames(mcmc.out[[1]]))] )\nhh = mcmc.out[[1]][,grep(\"hh\",colnames(mcmc.out[[1]]))]\nalpha.hat = apply(alpha,2,mean)\ndelta.hat = apply(delta,2,mean)\ndelta.med = apply(delta,2,median)\nhh.hat = apply(hh,2,mean)\n```\n\n\\newpage\n\n```{r}\nsummary(mcmc.out[[1]][,c(\"ph0\",\"precision.a\",\"precision.d\",\"precision.s\")])\n```\n\n\\newpage\n\n```{r, fig.height=10, fig.width=10}\nplot(GeneSummInclude[,\"abundance\"],alpha.hat,pch=\".\")\nabline(0,1)\n```\n\n\\newpage\n\n```{r, fig.height=10, fig.width=10}\nplot(GeneSummInclude[,\"difference\"],delta.hat,pch=\".\")\nabline(0,1)\n```\n\n```{r, fig.height=10, fig.width=10}\nplot(GeneSummInclude[,\"difference\"],delta.med,pch=\".\")\nabline(0,1)\n```\n\n::: callout-note\ncontrast this shrinkage pattern to the fully conjugate\n:::\n\n\\newpage\n\n```{r, fig.height=10, fig.width=10}\npairs(cbind(GeneSummInclude,hh.hat),pch=\".\")\n```\n\n\\newpage\n\n```{r, fig.height=10, fig.width=10}\nplot(delta.hat,hh.hat,pch=\".\")\n```\n\n::: callout-note\nthink about how to construct an estimate of FDR if all hou have is hh.hat\n:::\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"L12-shrinkage.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.545","editor":"visual","theme":"cosmo"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}