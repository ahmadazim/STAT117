[
  {
    "objectID": "L2-biomarkers.html",
    "href": "L2-biomarkers.html",
    "title": "Lecture 2: Cancer Biomarkers",
    "section": "",
    "text": "Cancer arises from evolution of cells within tissues. Changes in the genome code and organization result in changes in cell characteristics. Natural selection operates on this variability so that, for example, cells that divide faster and invade surrounding tissues are sometimes able to grow large colonies and generate tumors. @Podlaha:2012vw explains these concepts. Figure 1 From @Podlaha:2012vw illustrates the typical stages of cancer progression for a cancer that resists to treatment. In this example, we begin with normal cells (blue circles). The progression to cancer starts when a cell acquires a genetic change (for example a DNA mutation, or a chromosomal translocation) which results in a larger and more fit population compared to the normal cells. @Podlaha:2012vw remarks that “This process involves the evolution of multiple ‘novel’ cellular traits. Most somatic alterations in epithelial cells lining the colon, for instance, are not advantageous and will disappear with the death of a cell. Occasionally, an alteration that increases the proliferation rate of a cell arises, allowing this cell to increase in number. This population of ‘rogue’ cells can decline with the onset of anti-cancer therapy; however, the arrival of an alteration conferring drug resistance reverses the effects of treatment and allows new growth (b). In some cases, resistance to an anti-cancer drug may already be present in a small subset of tumor cells. In such a scenario, the population of sensitive cancer cells will decline and eventually be replaced by drug-resistant cells. Further alterations may be necessary to enable tumor cells to metastasize (c) and spread to other tissues (d).”\n\n\n\n\n\n\nFigure 1: Cancer Evolution a the Cell Level\n\n\n\n\n\n\n\nMany factors contribute to the changes in the genome represented by a lighting in Figure 1. @Song2018s review the main categories of causes, also summarized in Figure 2\n\n\n\n\n\n\nFigure 2: Categories of Cancer Causes and their Position in Cancer Evolution\n\n\n\n\n\n\n\n\n\nA biomarker is any readout of biological activity.\n\nCommon biomarkers types used in cancer, with examples\n\n\n\n\n\n\nType\nExemple\n\n\n\n\nPhysiologic\nPatient Performance Status (a score that estimates the patient’s ability to perform activities of daily living)\n\n\nImage-based\nMammograms\n\n\nSpecific molecules\nProstate-Specific Antigen (PSA)\n\n\n\nCirculating Tumor Cells (CTC)\n\n\nGermline Genetic Alterations\nBRCA mutations\n\n\nTumor products in Serum\nCirculating Tumor Cells\n\n\n\nCirculating Tumor DNA\n\n\nTumor Biology Readouts\nGene expression\n\n\n\nProtein Levels\n\n\n\nMetabolite Levels\n\n\n\nMethylation\n\n\n\nCopy Number Alterations\n\n\n\nMutational Signatures\n\n\n\n\n\n\n\nThe period between the origin of the cancer and the manifestation of clinical symptoms is called pre-clinical. The clinical period begins with the diagnosis.\nEarly detection biomarkers are used to anticipate the clinical symptoms and begin cancer therapy earlier. Early treatment is often associated with better results, because the cancer is less likely to have begun the process of invading other organs.\nIn contrast to early detection biomarkers, prognostic biomarkers are used at diagnosis to assess the severity of the disease.\nTherapy selection biomarkers are those that in addition to severity can predict response to specific treatments. The medical literature often uses the term “predictive” for these biomarkers, but we will avoid this here, because in statistics the word predictive has a broader meaning. These biomarkers can be used at any stage after diagnosis. Some biomarkers are both prognostic and helpful in therapy selection. The distinction between prognostic and therapy-selection markers is somewhat challenging empirically, because very few diagnosed patients go untreated.\n\n\n\n\n\n\nFigure 3: Broad Categories of Use for Biomarkers from @ou2021jto\n\n\n\nAdditional readings:\nContext: @Srivastava2020cebp; Broad Statistical Perspective: @ou2021jto\n\n\n\n\nToday the search for novel and more effective biomarkers often leverages our ability to interrogate the molecular biology of the cell using high throughput technologies.\nWe can measure:\n\nLevels and Types of High Throughput Biology Measurements used in Biomarker Research; An important take-home point is the trade-off between ease of measurement and biological relevance of high-throughput biology investigations.\n\n\n\n\n\n\nType\nIssues\n\n\n\n\nDNA\nWe can read most of the 6+ gigabase pairs in the human genome, count copies of genome sections, compare genomes across cells\n\n\n\nRelatively easy to define and read, getting cheaper\n\n\n\nA couple of steps removed from shedding light on what the cell(s) are doing\n\n\nVarious Aspects of Protein Production\nHard to define and poorly understood, somewhat hard to do well, getting cheaper\n\n\n\nFar more relevant for shedding light on what the cell(s) are doing\n\n\nProteins\nRelatively easy to define, very hard to measure well, expensive. 100.000+ estimated proteins, likely a substantial underestimate\n\n\n\nThe most relevant for shedding light on what the cell(s) are doing\n\n\n\n\nTo gain a better understanding of how gene expression analysis fits into the broader landscape of different omics data see @Chakraborty2018bmri who provides a brief overview of the different applications for high throughput biology platforms. Since 2018, when this article was written, at least to major brakthrough have occurred: the ability to measure these in single cells, and the ability to take measurement without disruptin the spatial organization of cells in the original tissue.\n\n\n\n\nPyramid of complexity. From @Chakraborty2018bmri “The pyramid represents the flow of information from genome (top) to transcriptome (middle), to proteome (bottom). The complexity increases from genome to proteome (indicated by down arrow). The complexity of transcriptome is largely mediated by temporal dynamics and alternative splicing. In contrast, spatiotemporal dynamics and posttranslational modifications (PTMs) are mainly responsible for high proteome complexity. Examples of PTMs include phosphorylation (P) and acetylation (Ac)”.\n\n\n\n\n\n\nOmics From @Chakraborty2018bmri\n\n\n\n\n\n\nRoles of NGS @Chakraborty2018bmri\n\n\n\n\n\n\nIn our course we will use high throughput “transcriptomics” data. This is a quantification of the number of copies of messenger RNAs in a sample. We will label RNA measurement by “gene” —these “genes” will be our candidate biomarkers. The next lecture will go into more detail into how this is done. For now it is important to understand that old-fashioned genes are a limited and somewhat arbitrary way of organizing information from RNA analysis. The “What is a gene?” box in @Hatje2019be is a very thoughtful and concise explanation. Highly recommended.\n\n\n\n\n\n\nRNA levels have a higher likelihood of being accurate predictors of phenotype (and thus future outcomes) if:\n\n\n\n\nGene expression levels correlate well with the corresponding protein levels\nMore abundant transcripts are more important in determining behavior of cells\nNormal cells have a stable expression profile\nChanges in expression indicate that ``something is happening’’\nGene expression are a proxy measure for the stimuli that control the cell\n\n\n\nA useful resource for those with limited biology lingo under their belt is the Talking Glossary of Genomic and Genetic Terms\nAnd for those who like historical landmarks…. @Gilbert1978n\n\n\n\n\nA biotech startup collects:\n\n100 blood samples from patients diagnosed with pancreas cancer at DFCI and\n100 blood samples from patients free of cancer.\n\nThey measure a blood biomarker in all samples and present you with the following plot:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe blue (orange) histogram represents the distribution of RNA counts (XX) for the candidate biomarker among cancer (normal) samples.\n\n\n\n\n\n\n\n\n\n\nQuestion for Debate\n\n\n\nThey approach you, a well endowed angel investor, about a business model based on using the biomarker for early detection of cancer. What do you ask them?\n\n\nBelow are some ideas to think about as you prepare to discuss this example in class. This list is not at all exhaustive. In fact that are at least a couple of very important additional questions for the investor to ask are not included.\n\n\n\n\n\n\nLongitudinal vs Cross-Sectional Data\n\n\n\nLongitudinal studies follow people over time; data on health and illness can be available for the same individual. Cross sectional and case-control study compare healthy and ill individuals.\n\n\n\n\n\n\n\n\nLead Time\n\n\n\nThe lead time of an early detection strategy refers to the gap between the time when a cancer is discovered using a biomarker, and the time it would have been discovered in the absence of biomarker screening.\nAre case control studies more or less likely than cross-sectional studies to discover biomarkers that become detectable early enough to generate a large lead time?\n\n\n\n\n\n\n\n\nReverse Causation\n\n\n\nDiscovering that a marker’s level is higher in cancer compared to normal samples is not ground to conclude that the high level is indicative of a cause of the cancer. This is because the cancer could be caused by the expression of gene A, and then produce large quantities of gene B. Gene B might still become detectable before symptoms occur and serve as a marker while being an effect and not a cause of the tumor.\nAs an angel investor, should you be worried or not about whether the biomarker is genuinely causative of cancer?"
  },
  {
    "objectID": "L2-biomarkers.html#cancer-evolution",
    "href": "L2-biomarkers.html#cancer-evolution",
    "title": "Lecture 2: Cancer Biomarkers",
    "section": "",
    "text": "Cancer arises from evolution of cells within tissues. Changes in the genome code and organization result in changes in cell characteristics. Natural selection operates on this variability so that, for example, cells that divide faster and invade surrounding tissues are sometimes able to grow large colonies and generate tumors. @Podlaha:2012vw explains these concepts. Figure 1 From @Podlaha:2012vw illustrates the typical stages of cancer progression for a cancer that resists to treatment. In this example, we begin with normal cells (blue circles). The progression to cancer starts when a cell acquires a genetic change (for example a DNA mutation, or a chromosomal translocation) which results in a larger and more fit population compared to the normal cells. @Podlaha:2012vw remarks that “This process involves the evolution of multiple ‘novel’ cellular traits. Most somatic alterations in epithelial cells lining the colon, for instance, are not advantageous and will disappear with the death of a cell. Occasionally, an alteration that increases the proliferation rate of a cell arises, allowing this cell to increase in number. This population of ‘rogue’ cells can decline with the onset of anti-cancer therapy; however, the arrival of an alteration conferring drug resistance reverses the effects of treatment and allows new growth (b). In some cases, resistance to an anti-cancer drug may already be present in a small subset of tumor cells. In such a scenario, the population of sensitive cancer cells will decline and eventually be replaced by drug-resistant cells. Further alterations may be necessary to enable tumor cells to metastasize (c) and spread to other tissues (d).”\n\n\n\n\n\n\nFigure 1: Cancer Evolution a the Cell Level"
  },
  {
    "objectID": "L2-biomarkers.html#cancer-causes",
    "href": "L2-biomarkers.html#cancer-causes",
    "title": "Lecture 2: Cancer Biomarkers",
    "section": "",
    "text": "Many factors contribute to the changes in the genome represented by a lighting in Figure 1. @Song2018s review the main categories of causes, also summarized in Figure 2\n\n\n\n\n\n\nFigure 2: Categories of Cancer Causes and their Position in Cancer Evolution"
  },
  {
    "objectID": "L2-biomarkers.html#biomarkers",
    "href": "L2-biomarkers.html#biomarkers",
    "title": "Lecture 2: Cancer Biomarkers",
    "section": "",
    "text": "A biomarker is any readout of biological activity.\n\nCommon biomarkers types used in cancer, with examples\n\n\n\n\n\n\nType\nExemple\n\n\n\n\nPhysiologic\nPatient Performance Status (a score that estimates the patient’s ability to perform activities of daily living)\n\n\nImage-based\nMammograms\n\n\nSpecific molecules\nProstate-Specific Antigen (PSA)\n\n\n\nCirculating Tumor Cells (CTC)\n\n\nGermline Genetic Alterations\nBRCA mutations\n\n\nTumor products in Serum\nCirculating Tumor Cells\n\n\n\nCirculating Tumor DNA\n\n\nTumor Biology Readouts\nGene expression\n\n\n\nProtein Levels\n\n\n\nMetabolite Levels\n\n\n\nMethylation\n\n\n\nCopy Number Alterations\n\n\n\nMutational Signatures\n\n\n\n\n\n\n\nThe period between the origin of the cancer and the manifestation of clinical symptoms is called pre-clinical. The clinical period begins with the diagnosis.\nEarly detection biomarkers are used to anticipate the clinical symptoms and begin cancer therapy earlier. Early treatment is often associated with better results, because the cancer is less likely to have begun the process of invading other organs.\nIn contrast to early detection biomarkers, prognostic biomarkers are used at diagnosis to assess the severity of the disease.\nTherapy selection biomarkers are those that in addition to severity can predict response to specific treatments. The medical literature often uses the term “predictive” for these biomarkers, but we will avoid this here, because in statistics the word predictive has a broader meaning. These biomarkers can be used at any stage after diagnosis. Some biomarkers are both prognostic and helpful in therapy selection. The distinction between prognostic and therapy-selection markers is somewhat challenging empirically, because very few diagnosed patients go untreated.\n\n\n\n\n\n\nFigure 3: Broad Categories of Use for Biomarkers from @ou2021jto\n\n\n\nAdditional readings:\nContext: @Srivastava2020cebp; Broad Statistical Perspective: @ou2021jto\n\n\n\n\nToday the search for novel and more effective biomarkers often leverages our ability to interrogate the molecular biology of the cell using high throughput technologies.\nWe can measure:\n\nLevels and Types of High Throughput Biology Measurements used in Biomarker Research; An important take-home point is the trade-off between ease of measurement and biological relevance of high-throughput biology investigations.\n\n\n\n\n\n\nType\nIssues\n\n\n\n\nDNA\nWe can read most of the 6+ gigabase pairs in the human genome, count copies of genome sections, compare genomes across cells\n\n\n\nRelatively easy to define and read, getting cheaper\n\n\n\nA couple of steps removed from shedding light on what the cell(s) are doing\n\n\nVarious Aspects of Protein Production\nHard to define and poorly understood, somewhat hard to do well, getting cheaper\n\n\n\nFar more relevant for shedding light on what the cell(s) are doing\n\n\nProteins\nRelatively easy to define, very hard to measure well, expensive. 100.000+ estimated proteins, likely a substantial underestimate\n\n\n\nThe most relevant for shedding light on what the cell(s) are doing\n\n\n\n\nTo gain a better understanding of how gene expression analysis fits into the broader landscape of different omics data see @Chakraborty2018bmri who provides a brief overview of the different applications for high throughput biology platforms. Since 2018, when this article was written, at least to major brakthrough have occurred: the ability to measure these in single cells, and the ability to take measurement without disruptin the spatial organization of cells in the original tissue.\n\n\n\n\nPyramid of complexity. From @Chakraborty2018bmri “The pyramid represents the flow of information from genome (top) to transcriptome (middle), to proteome (bottom). The complexity increases from genome to proteome (indicated by down arrow). The complexity of transcriptome is largely mediated by temporal dynamics and alternative splicing. In contrast, spatiotemporal dynamics and posttranslational modifications (PTMs) are mainly responsible for high proteome complexity. Examples of PTMs include phosphorylation (P) and acetylation (Ac)”.\n\n\n\n\n\n\nOmics From @Chakraborty2018bmri\n\n\n\n\n\n\nRoles of NGS @Chakraborty2018bmri\n\n\n\n\n\n\nIn our course we will use high throughput “transcriptomics” data. This is a quantification of the number of copies of messenger RNAs in a sample. We will label RNA measurement by “gene” —these “genes” will be our candidate biomarkers. The next lecture will go into more detail into how this is done. For now it is important to understand that old-fashioned genes are a limited and somewhat arbitrary way of organizing information from RNA analysis. The “What is a gene?” box in @Hatje2019be is a very thoughtful and concise explanation. Highly recommended.\n\n\n\n\n\n\nRNA levels have a higher likelihood of being accurate predictors of phenotype (and thus future outcomes) if:\n\n\n\n\nGene expression levels correlate well with the corresponding protein levels\nMore abundant transcripts are more important in determining behavior of cells\nNormal cells have a stable expression profile\nChanges in expression indicate that ``something is happening’’\nGene expression are a proxy measure for the stimuli that control the cell\n\n\n\nA useful resource for those with limited biology lingo under their belt is the Talking Glossary of Genomic and Genetic Terms\nAnd for those who like historical landmarks…. @Gilbert1978n\n\n\n\n\nA biotech startup collects:\n\n100 blood samples from patients diagnosed with pancreas cancer at DFCI and\n100 blood samples from patients free of cancer.\n\nThey measure a blood biomarker in all samples and present you with the following plot:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe blue (orange) histogram represents the distribution of RNA counts (XX) for the candidate biomarker among cancer (normal) samples.\n\n\n\n\n\n\n\n\n\n\nQuestion for Debate\n\n\n\nThey approach you, a well endowed angel investor, about a business model based on using the biomarker for early detection of cancer. What do you ask them?\n\n\nBelow are some ideas to think about as you prepare to discuss this example in class. This list is not at all exhaustive. In fact that are at least a couple of very important additional questions for the investor to ask are not included.\n\n\n\n\n\n\nLongitudinal vs Cross-Sectional Data\n\n\n\nLongitudinal studies follow people over time; data on health and illness can be available for the same individual. Cross sectional and case-control study compare healthy and ill individuals.\n\n\n\n\n\n\n\n\nLead Time\n\n\n\nThe lead time of an early detection strategy refers to the gap between the time when a cancer is discovered using a biomarker, and the time it would have been discovered in the absence of biomarker screening.\nAre case control studies more or less likely than cross-sectional studies to discover biomarkers that become detectable early enough to generate a large lead time?\n\n\n\n\n\n\n\n\nReverse Causation\n\n\n\nDiscovering that a marker’s level is higher in cancer compared to normal samples is not ground to conclude that the high level is indicative of a cause of the cancer. This is because the cancer could be caused by the expression of gene A, and then produce large quantities of gene B. Gene B might still become detectable before symptoms occur and serve as a marker while being an effect and not a cause of the tumor.\nAs an angel investor, should you be worried or not about whether the biomarker is genuinely causative of cancer?"
  },
  {
    "objectID": "L9-comparing.html#comparing-criteria-for-biomarker-discovery",
    "href": "L9-comparing.html#comparing-criteria-for-biomarker-discovery",
    "title": "Lecture 9: Comparing Criteria for Biomarker Discovery",
    "section": "Comparing Criteria for Biomarker Discovery",
    "text": "Comparing Criteria for Biomarker Discovery\nWith this lecture we move to the search for promising biomarkers in high dimension. This task is implicity in most variable selection and machine learning methodologies. Here we will dissect it in a more basic and exploratory way.\n\nData\nWe will start by going back to the TCGA_eset dataset and again consider the debulking variable. From before, this is a binary variable with optimal and suboptimal debulking. We will code an optimal debulking status as \\(1\\) and \\(0\\) otherwise. The biomarkers are on the continuous gene expression scale. We let XXX and YYY denote the biomarkers on the full set of patients, while XX and YY represent the biomarkers for the first 100 patients. For this analysis we remove any NA’s from both the response and gene expression predictor variables. In real applications we may consider imputation.\n\nlibrary(curatedOvarianData)\nlibrary(ROCR)\ndata(TCGA_eset)\nXX = as.matrix(cbind(exprs(TCGA_eset)))\nYY = 1 * as.vector(pData(TCGA_eset)[,\"debulking\"]==\"optimal\")\nXX = XX[,!is.na(YY)]; \nYY = YY[!is.na(YY)]\n\nXXX = XX\nYYY = YY\n# subset\nsubs = 1:100\nXX = XX[,subs]; YY = YY[subs]\n\n\n\n\nThree Scores\nWhat we have next is the CompScores() function. This function will compute the AUC, the negative log p-value, fold change, and the residual error associated with each gene on the subset of patients. The fold change is the difference in means, so names becasue the expression measurements in the Affy platform have been logged as part of the preprocessing. The residual error considers deviations of biomarker values from their class-specific means, and it includes two general sources of variation: expression measurement error and patient-to-patient variation.\nThese are only a few of the scores one can compute, of course. A good way to contribute to the discussion is to add your favorite metric to the mix and start exploring.\nNow we run the function on the first 100 patients. We save the full set for later.\n\nsource(\"RScripts/Scores.R\")\nScores = CompScores(XX,YY)\n\n\nWe will now focus on the sample of 100 first. To begin, we threshold negative log p-value at \\(4.25\\), AUC at \\(0.66\\), and the fold change at \\(0.5\\) and tabulate the results. TRUE and FALSE refer to whether the score exceeds the cutoff.\n\npcut = 4.25\nacut = .66\nfcut = .5\n\ntable( abs(Scores[,\"FoldChange\"])&gt;fcut , \n       Scores[,\"nlpvalueT\"]&gt;pcut, \n       Scores[,\"AUC\"]&gt;acut, dnn = c(\"FoldChange\",\"nlpvalueT\",\"AUC\"))\n\n, , AUC = FALSE\n\n          nlpvalueT\nFoldChange FALSE  TRUE\n     FALSE 12514    56\n     TRUE    118     7\n\n, , AUC = TRUE\n\n          nlpvalueT\nFoldChange FALSE  TRUE\n     FALSE   203   158\n     TRUE     24    24\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nDid you expect more agreement? Less?\n\n\n\n\nFor later use.\n\nallTrue = abs(Scores[,\"FoldChange\"])&gt;fcut & \n    Scores[,\"nlpvalueT\"]&gt;pcut & Scores[,\"AUC\"]&gt;acut\naucOnly = abs(Scores[,\"FoldChange\"])&lt;fcut & \n    Scores[,\"nlpvalueT\"]&lt;pcut & Scores[,\"AUC\"]&gt;acut\npOnly = abs(Scores[,\"FoldChange\"])&lt;fcut & \n    Scores[,\"nlpvalueT\"]&gt;pcut & Scores[,\"AUC\"]&lt;acut\nfcOnly = abs(Scores[,\"FoldChange\"])&gt;fcut & \n    Scores[,\"nlpvalueT\"]&lt;pcut & Scores[,\"AUC\"]&lt;acut\nlowresi = (1:nrow(Scores))[Scores[,\"ResiErr\"]&lt;.5^2]\nhighauc_lowresi &lt;- rownames(Scores[Scores[,\"ResiErr\"]&lt;.5 & Scores[,\"AUC\"]&gt;acut,])\nlowauc_lowresi &lt;- rownames(Scores[Scores[,\"ResiErr\"]&lt;.5 & Scores[,\"AUC\"]&lt;acut,])\nhighauc_higherresi &lt;- rownames(XX[which(Scores[,\"ResiErr\"]&gt;.8 & Scores[,\"AUC\"]&gt;acut,)])\n\n\n\n\nPairwise Comparisons of Scores\n\nlibrary(GGally)\nlowresi = Scores[,\"ResiErr\"]&lt;.25\nplotme = cbind(Scores,lowresi)\nggpairs(plotme,\n        columns = 1:4,\n        aes(color = plotme[,5],alpha=.7),\n        lower = list(continuous = wrap(\"points\", alpha = 0.05)))\n\n\n\n\nPairwise comparison of Scores\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nare the residual error and fold change correlated? Are they independent?\n\n\n\n\n\nAUC and Fold Change\n\npar(pty = \"m\")\nplot(Scores[,\"FoldChange\"],Scores[,\"AUC\"],pch=\".\", cex = 2)\npoints(Scores[lowresi,\"FoldChange\"],Scores[lowresi,\"AUC\"],col=\"green\",pch=\".\", cex = 2)\nabline(h = acut, lty = \"dashed\", col = \"deepskyblue3\")\n\n\n\n\nAUC on Fold Change with Green Points labeling Low Residual Error\n\n\n\n\n\nFor three specific biomarkers from each of the lists above, we will now plot their empirical densities. This will allow us to better understand how it is possible to have a low variance but high score in the AUC. Furthermore, what a biomarker with a high AUC but also a high variance looks like.\n\nACADM = XX[\"ACADM\",]\nScores[\"ACADM\",]\n\n            AUC nlpvalueT FoldChange   ResiErr\nACADM 0.6802168  3.919139 -0.4339855 0.6550141\n\nplot(density(ACADM[YY==1]),xlab=c(\"Log Expression\",\"ACADM\"),main = \"\", col= \"blue\")\nlines(density(ACADM[YY==0]), col=\"green\")\nrug(ACADM[YY==0],ticksize = .1,lwd=2, col = \"green\")\nrug(ACADM[YY==1],ticksize = .1,lwd=2, col = \"blue\")\n\n\n\n\nDensity Plots\n\n\n\n\n\n\nA4GNT = XX[\"A4GNT\",]\nScores[\"A4GNT\",]\n\n          AUC nlpvalueT FoldChange   ResiErr\nA4GNT 0.50271 0.4490836 0.01979107 0.1715732\n\nplot(density(A4GNT[YY==0]),xlab=c(\"Log Expression\",\"A4GNT\"),\n     main = \"\",ylim=c(0,3), col= \"green\")\nlines(density(A4GNT[YY==1]), col=\"blue\")\nrug(A4GNT[YY==0],ticksize = .1,lwd=2, col = \"green\")\nrug(A4GNT[YY==1],ticksize = .1,lwd=2, col = \"blue\")\n\n\n\n\nDensity Plots for A4GNT\n\n\n\n\n\nThis is a tyrosine kinase.\n\nARHGAP33 = XX[\"ARHGAP33\",]\nScores[\"ARHGAP33\",]\n\n               AUC nlpvalueT FoldChange   ResiErr\nARHGAP33 0.6944444  2.975095 -0.4351615 0.7970158\n\nplot(density(ARHGAP33[YY==0]),xlab=c(\"Log Expression\",\"ARHGAP33\"),main = \"\",ylim=c(0,1), col= \"green\")\nlines(density(ARHGAP33[YY==1]), col=\"blue\")\nrug(ARHGAP33[YY==0],ticksize = .1,lwd=2, col = \"green\")\nrug(ARHGAP33[YY==1],ticksize = .1,lwd=2, col = \"blue\")\n\n\n\n\nDensity Plots for ARHGAP33\n\n\n\n\n\n\n\nNegative Log P-Value and Fold Change.\nThe following plot, sometimes called a volcano plot, is the negative log p-value against the fold change. The blue dotted horizontal line corresponds to where an \\(\\alpha = 0.05\\) significance level would sit. Everything above the blue dotted line would indicated \\(\\alpha = 0.05\\) significance. The darker green dotted lines show where a (logged) fold chance of 0.5 would be on either side.\n\nplot(Scores[,\"FoldChange\"],Scores[,\"nlpvalueT\"],pch=\".\", cex = 2)\nlowresi = (1:nrow(Scores))[Scores[,\"ResiErr\"] &lt; .5]\npoints(Scores[lowresi,\"FoldChange\"],Scores[lowresi,\"nlpvalueT\"],col=\"green\",pch=\".\")\nabline(h = -log(0.05), lty = \"dashed\", col = \"deepskyblue3\")\nabline(v = 0.5, lty = \"dashed\", col = \"darkgreen\")\nabline(v = -0.5, lty = \"dashed\", col = \"darkgreen\")\ninterest = (1:nrow(Scores))[abs(Scores[,\"FoldChange\"])&gt;0.5 & \n                                abs(Scores[,\"nlpvalueT\"])&gt;-log(0.05)]\npoints(Scores[interest,\"FoldChange\"],Scores[interest,\"nlpvalueT\"],col=\"red\",pch=\".\")\n\n\n\n\nNegative Log P-Value versus Fold Change\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo practitioners in biology, the top left and top right quadrants indicate biomarkers of exceptional interest. Why might the combination of the two conditions of interest to them?\n\n\n\n\n\nNegative Log P-Value and AUC.\nWe now have the nlpvalue against the AUC. We see that there is a linear trend in general. The top right quadrant would indicate biomarkers of specific interest. The green points indicate biomarkers of low variance. We see that the low variance genes don’t appear to be specifically clustered.\n\nplot(Scores[,\"nlpvalueT\"],Scores[,\"AUC\"],pch=\".\", main = \"NLP-value vs. AUC\", cex = 2)\nlowresi = (1:nrow(Scores))[Scores[,\"ResiErr\"]&lt;.5^2]\npoints(Scores[lowresi,\"nlpvalueT\"],Scores[lowresi,\"AUC\"],col=\"green\",pch=\".\", cex = 2)\nabline(h = 0.66, lty = \"dashed\", col = \"deepskyblue3\")\nabline(v = -log(0.05), lty = \"dashed\", col = \"deepskyblue3\")\n\n\n\n\nNegative Log P-Value on AUC\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nare the residual error and fold change correlated? Are they independent?\n\n\n\n\nLet’s revisit the marginal distribution of Residual Errors.\n\nhist(sqrt(Scores[,\"ResiErr\"]),nclass=100)\n\n\n\n\nMarginal Histogram of Residual Errors\n\n\n\n\nIt is apparent that there are two “humps” in the graph. The first hump are genes with low residual error. These are generally genes with low dynamic range and whose overall variability is small but dominated by technical noise. The second hump are points with higher residual error, predominantly drive by biological variability across subjects. These are also more likely to provide detectable signal when comparing across classes.\n\n\n\nNegative Log P-Value and Residual Error.\nWe now plot the nlpvalue against the residual error. The red dotted line indicates where points with a standard deviation of 0.2 would sit. The blue dotted line shows where an \\(\\alpha = 0.05\\) significance level would be at.\n\nplot(sqrt(Scores[,\"ResiErr\"]),Scores[,\"nlpvalueT\"],pch=\".\",cex = 2)\npoints(sqrt(Scores[lowresi,\"ResiErr\"]),Scores[lowresi,\"nlpvalueT\"],col=\"green\",pch=\".\", cex = 3)\nabline(h = -log(0.05), lty = \"dashed\", col = \"deepskyblue3\")\nabline(v = 0.2, lty = \"dashed\", col = \"red\")\n\n\n\n\nNegative Log P-Value versus Standard Deviation"
  },
  {
    "objectID": "L9-comparing.html#visualizations-of-individual-biomarkers.",
    "href": "L9-comparing.html#visualizations-of-individual-biomarkers.",
    "title": "Lecture 9: Comparing Criteria for Biomarker Discovery",
    "section": "Visualizations of Individual Biomarkers.",
    "text": "Visualizations of Individual Biomarkers.\nWe now would like to examine individual biomarkers that satisfy varying criteria in the CompScores() function. The names of the biomarkers that satisfy all three criteria, only the p-value, only the AUC, and only the fold change are given by the following vectors.\n\nallTrueNames &lt;- rownames(XX)[(1:length(allTrue))[allTrue==\"TRUE\"]]\npOnlyNames   &lt;- rownames(XX)[(1:length(pOnly))[pOnly==\"TRUE\"]]\naucOnlyNames &lt;- rownames(XX)[(1:length(aucOnly))[aucOnly==\"TRUE\"]]\nfcOnlyNames  &lt;- rownames(XX)[(1:length(fcOnly))[fcOnly==\"TRUE\"]]\n\n\n\nA biomarker meeting all three criteria above.\nWe first look at a gene that fulfills all three criteria and visualize its properties.\n\nlibrary(ROCR)\npar(pty=\"s\", mfrow = c(1,3))\nggg = 1485\nrownames(XX)[ggg] # CADM1\n\n[1] \"CADM1\"\n\nround(Scores[ggg,],digits=2)\n\n       AUC nlpvalueT FoldChange ResiErr\nCADM1 0.72      4.53       0.68    0.93\n\nrownames(XX)[ggg]\n\n[1] \"CADM1\"\n\nplot(density(XX[ggg,YY==0]),xlim=c(3,11), ylim = c(0, 0.7), main = \"\"); lines(density(XX[ggg,YY==1]),col=3); rug(XX[ggg,YY==1],.1,lwd=1.5, col=3); rug(XX[ggg,YY==0],.1,lwd=2)\nqqplot(XX[ggg,YY==0],XX[ggg,YY==1],asp=1); abline(0,1)\nplot(performance(prediction(as.vector(XX[ggg,]),YY),\"tpr\",\"fpr\")); abline(0,1, col = \"red\")\n\n\n\n\nVisualizations for CADM1 - All 3 Criteria Satisfied\n\n\n\n\n\n\n\nSelecting by P-value Only\nWe now look at a gene that only satisfies the p-value only, but NOT the other two criteria.\n\npar(pty=\"s\", mfrow = c(1,3))\nggg = 211\nrownames(XX)[ggg] # ADAMTSL3\n\n[1] \"ADAMTSL3\"\n\nround(Scores[ggg,],digits=2)\n\n          AUC nlpvalueT FoldChange ResiErr\nADAMTSL3 0.64      4.97       0.21    0.43\n\nrownames(XX)[ggg]\n\n[1] \"ADAMTSL3\"\n\nplot(density(XX[ggg,YY==0]),xlim=c(2,6), main = \"\"); lines(density(XX[ggg,YY==1]),col=3); rug(XX[ggg,YY==1],.1,lwd=1.5, col=3); rug(XX[ggg,YY==0],.1,lwd=2)\nqqplot(XX[ggg,YY==0],XX[ggg,YY==1],asp=1); abline(0,1)\nplot(performance(prediction(as.vector(XX[ggg,]),YY),\"tpr\",\"fpr\")); abline(0,1)\n\n\n\n\nVisualizations for ADAMTSL3 - Satisfying P-value Only\n\n\n\n\n\nWe can now look at where the ADAMTSL3 biomarker sits with relation to the rest of the biomarkers in our dataset.\n\npar(mfrow = c(1,3))\nhist(Scores[, \"FoldChange\"], breaks = 100, main = \"Fold Change\")\nabline(v=Scores[ggg,][\"FoldChange\"], col = \"red\")\nhist(Scores[, \"ResiErr\"], breaks = 100, main = \"ResiErr\")\nabline(v=Scores[ggg,][\"ResiErr\"], col = \"red\")\nhist(Scores[, \"nlpvalueT\"], breaks = 100, main = \"NLPValue\")\nabline(v=Scores[ggg,][\"nlpvalueT\"], col = \"red\")\n\n\n\n\nFC, ResiErr, and NLP-value Histograms for ADAMTSL3\n\n\n\n\n\n\n\nSelecting by AUC Only\nWe now look at a gene that only satisfies the AUC only, but NOT the other two criteria.\n\npar(pty=\"s\", mfrow = c(1,3))\nggg = 9952\nrownames(XX)[ggg] # SAYSD1\n\n[1] \"SAYSD1\"\n\nround(Scores[ggg,],digits=2)\n\n        AUC nlpvalueT FoldChange ResiErr\nSAYSD1 0.68      4.22       0.33    0.49\n\nrownames(XX)[ggg]\n\n[1] \"SAYSD1\"\n\nplot(density(XX[ggg,YY==0]), main = \"\"); \nlines(density(XX[ggg,YY==1]),col=3); \nrug(XX[ggg,YY==1],.1,lwd=1.5, col=3); \n\nWarning in rug(XX[ggg, YY == 1], 0.1, lwd = 1.5, col = 3): some values will be\nclipped\n\nrug(XX[ggg,YY==0],.1,lwd=2)\nqqplot(XX[ggg,YY==0],XX[ggg,YY==1],asp=1); abline(0,1, col = \"red\")\nplot(performance(prediction(as.vector(XX[ggg,]),YY),\"tpr\",\"fpr\")); abline(0,1)\n\n\n\n\nVisualizations for SAYSD1 - Satisfying AUC Only\n\n\n\n\n\nAgain, we can look at where the SAYSD1 biomarker sits with relation to the rest of the biomarkers in our dataset.\n\npar(mfrow = c(1,2))\nhist(Scores[, \"AUC\"], breaks = 100, main = \"AUC\")\nabline(v=Scores[ggg,][\"AUC\"], col = \"red\")\nhist(Scores[, \"nlpvalueT\"], breaks = 100, main = \"NLPValue\")\nabline(v=Scores[ggg,][\"nlpvalueT\"], col = \"red\")\n\n\n\n\nAUC and NLP-value Histograms for SAYSD1\n\n\n\n\n\n\n\nSelecting by Fold Change Only\nWe finally look at a biomarker that only satisfies the fold change criteria.\n\npar(pty=\"s\", mfrow = c(1,3))\nggg = 9903\nrownames(XX)[ggg] # S100A9\n\n[1] \"S100A9\"\n\nround(Scores[ggg,],digits=2)\n\n        AUC nlpvalueT FoldChange ResiErr\nS100A9 0.57      1.59       0.52    1.76\n\nrownames(XX)[ggg]\n\n[1] \"S100A9\"\n\nplot(density(XX[ggg,YY==0]), main = \"\"); \nlines(density(XX[ggg,YY==1]),col=3); rug(XX[ggg,YY==1],.1,lwd=1.5, col=3); \nrug(XX[ggg,YY==0],.1,lwd=2)\nqqplot(XX[ggg,YY==0],XX[ggg,YY==1],asp=1); abline(0,1)\nplot(performance(prediction(as.vector(XX[ggg,]),YY),\"tpr\",\"fpr\")); abline(0,1)\n\n\n\n\nVisualizations for S100A9 - Satisfying Fold Change Only\n\n\n\n\nwe can look at where the S100A9 biomarker sits with relation to the rest of the biomarkers in our dataset.\n\npar(mfrow = c(1,3))\nhist(Scores[, \"FoldChange\"], breaks = 100, main = \"Fold Change\")\nabline(v=Scores[ggg,][\"AUC\"], col = \"red\")\nhist(Scores[, \"ResiErr\"], breaks = 100, main = \"Residual Error\")\nabline(v=Scores[ggg,][\"ResiErr\"], col = \"red\")\nhist(Scores[, \"nlpvalueT\"], breaks = 100, main = \"NLPValue\")\nabline(v=Scores[ggg,][\"nlpvalueT\"], col = \"red\")\n\n\n\n\nFC, ResiErr, and NLP-value Histograms for S100A9"
  },
  {
    "objectID": "L9-comparing.html#to-log-or-not-to-log",
    "href": "L9-comparing.html#to-log-or-not-to-log",
    "title": "Lecture 9: Comparing Criteria for Biomarker Discovery",
    "section": "To log or not to log",
    "text": "To log or not to log\nOptional material.\nIt is interesting to explore the effect of having logged the data on the discovery process. Here, just to play a bit, I created the same scores after exponentiating the expression measurements.\n\nScoresExp = CompScores(exp(XX),YY)\n\n\n\n\n\n\n\nNote\n\n\n\nHow would you think about whether to log or not? Here are a few plots to get you started.\nIt would be nice to have a gold standard, or at least some sort of validation. What options do we have?\n\n\n\nhist(log(ScoresExp[,\"ResiErr\"]),nclass=100)\n\n\n\n\nMarginal Histogram of Residual Errors in Raw Intensity Scale (the x scale is logged for resolution, but the scores are computed in the raw scale).\n\n\n\n\n\nlowresiExp = ScoresExp[,\"ResiErr\"] &lt; exp(3)\nplot(log(ScoresExp[,\"ResiErr\"]),ScoresExp[,\"nlpvalueT\"],pch=\".\",cex = 2)\npoints(log(Scores[lowresiExp,\"ResiErr\"]),Scores[lowresiExp,\"nlpvalueT\"],col=\"green\",pch=\".\", cex = 3)\n\n\n\n\nNegative Log P-Value versus Standard Deviation\n\n\n\n\n\nplot(Scores[,\"nlpvalueT\"],ScoresExp[,\"nlpvalueT\"],pch=\".\",cex = 2)\n\n\n\n\nNegative Log P-Value with and without logging (is that a verb in math?)\n\n\n\n\n\nplot(log(abs(ScoresExp[,\"FoldChange\"])),ScoresExp[,\"nlpvalueT\"],pch=\".\",cex = 1.5)\n\n\n\n\nVolcano plot w/out logging (the x scale is logged for resolution, but the scores are computed in the raw scale)."
  },
  {
    "objectID": "L5-decision.html#decision-analysis",
    "href": "L5-decision.html#decision-analysis",
    "title": "Lecture 5: Decision Analysis",
    "section": "Decision Analysis",
    "text": "Decision Analysis\n\nDecision Tree\nWe will now introduce biomarker analysis through a decision-theoretic framework. “Modeling in Medical Decision Making” goes over these concepts in detail. I posted a copy on the canvas files. A seminal paper on this topic in the medical area is [@Pauker1980nejm].\nWe try to model the clinical application of biomarker expressions levels to medical decision making. Our model can be use to quantify the value using the marker for specific individuals and groups, and ca also be used to determine the optimal threshold for a continuous marker in a formal way. We begin with a fixed threshold.\nTo motivate our discussion, we introduce an example where a clinician must make an informed decision regarding whether to conduct a surgery for an ovarian cancer patient when it is not known ahead of time whether the surgery can be performed “optimally” as defined earlier. Should the clinician conduct a surgery where the tumor is operable optimally, then a large utility should be subsequently accrued by the patient. However, a low utility may be experienced by the patient when a surgery is performed while the tumor was only amanable to a suboptimal outcome. We present the following decision tree that captures such a scenario.\n\n\n\nDecision Tree for Evaluating the Clinical Utility of a Biomarker\n\n\nIn the decision tree, the clinician encounters two decisions: 1) whether to measure the biomarker and 2) whether to perform surgery, possibly using the biomarker to make a more informed decision. To simplify a bit, we assume that it is know that higher levels of the biomarkers are associated with a better chance that the tumor may be operable optimally. If biomarker analysis is to be done, then a surgery will be conducted on the basis of whether the biomarker expression level for the patient is above a pre-defined threshold. We will later study the results of varying the threshold. This yields a total of \\(2^3 = 8\\) possible outcomes. We let \\(q\\) denote the joint probability that the biomarker exceed the threshold. Let the condiational probabilities that the surgery is suboptimal given the biomarker is above (below) the threshold be \\(p_{+}\\) (\\(p_{-}\\)). Then the marginal probability that the surgery is suboptimal, \\(p = q p_+ + (1-q) p_-\\). This is relevant in the case in which no biomarker is observed. In the notation for utiilties the first index is 1 if surgery and 0 if not; the second index is 1 if the outcome is optimal and 0 if not.\n\n\nOptimal Decision w/out the Biomarker\nWe first focus on the bottom part of the tree which corresponds to proceeding to surgery without a biomarker. This admits four total outcomes based on the surgery decision and operability of the tumor. There are probabilities and utilities associated with each. The probabilities of a suboptimal outcome are marginalized with respect to the biomarker status because the biomarker data is not collected and thus unknown. These probabilities and utilities can be used to derive expected utilities, as follows:\nTo maximize the expected utility at the binary node representing sugery, we will choose a surgery if:\n\\[\np u_{11} + (1-p) u_{10} &gt; p u_{01} + (1-p) u_{00}\n\\]\nwhich is equivalent to\n\\[\np ( u_{11}-u_{01} ) &gt; (1-p) ( u_{00}-u_{10} )\n\\]\nHere, \\(u_{00}-u_{10}\\) compares the health outcome of a suboptimally operable patient without \\(u_{00}\\) and with \\(u_{10}\\) surgery. We expect the overall survival to be short and similar in both cases, although the quality of life will be worse if surgery is performed, so this difference will be positive and not very large.\nNext, \\(u_{11}-u_{01}\\) compares the health outcome of an optimally operable patient without \\(u_{01}\\) and with \\(u_{11}\\) surgery. We expect the overall survival to be far better under the surgery option, as the tumor is removed successfully, although the quality of life will be worse. Overall this difference will be positive and possibly large.\nHaving established the sign of these utility differences, we can rewrite the inequality as \\[\n\\frac {p} {1-p} &gt; \\frac {u_{00}-u_{10} }  { u_{11}-u_{01} }\n\\] emphasizing that the decision to perform surgery in the absence of the biomarker information depends on the probabilities only through the odds, and on the utilities only through the ratio of differences between the utilities associated with the same debulking state.\nAs the likelihood of a successful surgery is generally moderately high, say 30 to 70 percent depending on the population, and the ratio on the right is small, the standard practice in the absence of a biomarker is to perform surgery.\n\n\n\nOptimal Decision with the Biomarker\nCan a biomarker change this picture? Let’s consider the two surgery decision nodes at the top of the figure, those that are made after making the observation of whether the biomarker exceeds the threshold. Recall we are assuming the biomarker is positively and monotonically associated with the ability to perform an optimal surgery. So we expect \\(p_+ &gt; p\\) and without additional work we can conclude that the optimal option is surgery there too.\nSo the biomarker will be of clinical use is if it can reverse the decision for women whose biomarker level is below the threshold. Using the same logic as earlier, this requires \\[\n\\frac {p_-} {1-p_-} &gt; \\frac {u_{00}-u_{10} }  { u_{11}-u_{01} }\n\\] Let’s assume this hold at the chosen threshold. If there is no threshold for which this is the case, then we can rule the biomarker out.\n\nNow we that know the optimal decisions under each of the outcome of the biomarker “chance node” we can move back the the first decision: whether the biomarker should be collected. Without any cost or other consequences for the observation itself, the data should be collected, because the biomarker-based decisions will leave the positive women equally well off and the negative women better off. It is important to quantify how much better off on average women will be. This is a quantifiction of the worthyness of the biomarker in the context of this decision. If can be use to a) compare this worthiness to the cost or potential negative consequences of making the observation and b) compare biomarkers.\n\n\n\nOptimal Two-stage Decision Strategy\nThe expected utility of observing the biomarker and then proceeding optimally after the reslt is observed is \\[\nq ( p_+ u_{11} + (1-p_+) u_{10}) + (1-q) ( p_- u_{01} + (1-p_-) u_{00})\n\\]\nIt can be useful to rewrite this expression in terms of the sensitivity and specificity of the biomarker. Some definitions: the threshold is \\(\\tau\\), a positive test is \\(X &gt; \\tau\\), the positive label is “optimal”, the conditional cdfs of \\(X\\) given the label are \\(F_0\\) and \\(F_1\\). The sensitivity is \\[p( X &gt; \\tau | \\mbox{Optimal} ) = 1-F_1(\\tau)\\] and the specificity is \\[p( X \\leq \\tau | \\mbox{Suboptimal} ) = F_0(\\tau)\\]\nThese relate to the \\(p\\)’s and \\(q\\)’s via \\[\nqp_+ = p (1-F_1(\\tau)) \\quad \\quad\nq(1-p_+) = (1-p)(1-F_0(\\tau))  \\quad \\quad\n(1-q)p_- = p F_1(\\tau) \\quad \\quad\n(1-q)(1-p_-) = (1-p) F_0(\\tau)\n\\] so we can rewrite the expected utility as\n\\[\np \\left[ (1-F_1(\\tau)) u_{11} + F_1(\\tau) u_{01} \\right] + (1-p) \\left[ (1-F_0(\\tau)) u_{10} + F_0(\\tau)u_{00} \\right]\n\\]\n\nPutting all these pieces together now we have that the benefit of using the biomarker compared to making a decision without using the biomarker is:\n\\[\\begin{align*}\np \\left[ (1-F_1(\\tau)) u_{11} + F_1(\\tau) u_{10} \\right] + (1-p) \\left[ (1-F_0(\\tau)) u_{01} + F_0(\\tau)u_{00} \\right] \\\\\n- \\max  \\left( p u_{11} + (1-p) u_{10}, p u_{01} + (1-p) u_{00} \\right)\n\\end{align*}\\]\nThis quantity can be used to assess the expected utility as a function of the threshold, assuming one proceeds optimally.\nThis logic is an example of “Value of Information” analysis (VoI), a very general principle for quantifying the value of collecting a particular piece of data, in the context of solving a specific decision task. @Jackson2022arsa review this extensively and provide many useful references.\n@vickers2008as has an interesting perspective on how to bypass the specification of the ratio \\(( u_{00}-u_{10} )/( u_{11}-u_{01} )\\), which results in an approach called decision curve analysis.\n\n\n\nIllustration\nTo illustrate a decision analysis and show how it can be used to investigate alternative thresholds, we have created the following example. The biomarker is our friendly zinc finger protein from earlier. The label is debulking status.\n\nbenefit = function(X=XX,\n                   Y=YY,\n                   pp,\n                   u00 = 3, \n                   u11 = 20, \n                   u10 = 2, \n                   u01 = 15 \n                   ){\nuD2yes = pp*u11 + (1-pp)*u10\nuD2no = pp*u01 + (1-pp)*u00\nuNoMarker = max(uD2yes,uD2no)\ntau = seq(min(X),max(X),by= ( max(X)-min(X) )/100 )\nF0 = F1 = rep(NA,length(tau))\nfor (jj in 1:length(tau)){\n  F1[jj] = mean(X[Y==1] &lt;= tau[jj])\n  F0[jj] = mean(X[Y==0] &lt;= tau[jj])\n  }\nuMarker = pp * (1-F1) * u11 + (1-pp) * (1-F0)* u10 + pp * F1 * u01 +  (1-pp) * F0 * u00\nbenefitMarker = uMarker - uNoMarker\nreturn(list(tau=tau,benefitMarker=benefitMarker,\n            uD2yes=uD2yes,uD2no=uD2no))\n}\n\n\n\nlibrary(curatedOvarianData)\n\n\ndata(GSE32063_eset)\nGeneName = \"ZNF487\"\nXX = exprs(GSE32063_eset)[GeneName,]\nYY = pData(GSE32063_eset)[,\"debulking\"] == \"optimal\"\nplot(benefit(pp=1/6)$tau,benefit(pp=1/6)$benefitMarker,\n     type=\"l\",lwd=2,ylim=c(-1,.5),\n     ylab=\"Benefit of Biomarker\",xlab=\"tau\")\nlines(benefit(pp=.1)$tau,benefit(pp=.1)$benefitMarker,\n      type=\"l\",lwd=2,col=\"blue\")\nlines(benefit(pp=.3)$tau,benefit(pp=.4)$benefitMarker,\n      type=\"l\",lwd=2,col=\"green\")\nabline(0,0)\n\n\n\n\nBenefit of Biomarker against tau\n\n\n\n\n\n\n\n\n\n\nNegative Benefit?\n\n\n\n\nWhy are these curves not monotone?\nWhy is it that a biomarker can provide an average positive benefit for some threshold and a negative benefit for others?\nIs it good or bad that these curves are flat at the top over a fairly broad range?\nTinker with the utility values to get a better sense for how the trade-offs play out.\n\n\n\n\nWe can also analyze the various cost-benefit tradeoffs below:\n\nc(.1,benefit(pp=.1)$uD2yes,benefit(pp=.1)$uD2no)\n\n[1] 0.1 3.8 4.2\n\nc(.2,benefit(pp=.2)$uD2yes,benefit(pp=.2)$uD2no)\n\n[1] 0.2 5.6 5.4\n\nc(.4,benefit(pp=.4)$uD2yes,benefit(pp=.4)$uD2no)\n\n[1] 0.4 9.2 7.8"
  },
  {
    "objectID": "L5-decision.html#references",
    "href": "L5-decision.html#references",
    "title": "Lecture 5: Decision Analysis",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Syllabus",
    "section": "",
    "text": "Time: Tue/Thu, 9:00am–10:15am in Science Center 705\nInstructor: Giovanni Parmigiani\nE-mail: Please use canvas messaging for all course-related matters\nOffice Hours: Thu 2:00pm–3:00pm in SC 316.06, or by appointment\nCanvas site: https://canvas.harvard.edu/courses/129153\nTF: Ahmad Abdel-Azim\nSection Times: TBD\nTF Office Hours: TBD"
  },
  {
    "objectID": "about.html#objectives",
    "href": "about.html#objectives",
    "title": "Syllabus",
    "section": "Objectives",
    "text": "Objectives\nTo develop a sense for practical applications of statistical thinking and tools in biomedical sciences. To learn how to make and defend statistical modeling choices in complex realistic applications. To constructively critique the analyses of others. To develop a working knowledge of R tools relevant for biomedical data science applications."
  },
  {
    "objectID": "about.html#prerequisites",
    "href": "about.html#prerequisites",
    "title": "Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nRequired: Stat 110, AP Stat or 102 or 104, Stat 111 and Stat 139\nRecommended: Stat 115; Basics of R programming"
  },
  {
    "objectID": "about.html#homework-grading",
    "href": "about.html#homework-grading",
    "title": "Syllabus",
    "section": "Homework Grading",
    "text": "Homework Grading\nHomework assignments will be graded by a grader or TF on a scale from 1 to 5. Homeworks are graded in large part on the clarity of your presentation of the solutions, not just their correctness. Homeworks that are generally clear and correct will earn scores of 4 or 5; those less so will earn a 3. Sloppy, incorrect and/or incomplete homeworks will receive a 1 or 2. All homeworks will count toward your course grade – we will not drop any homework grades."
  },
  {
    "objectID": "about.html#you-use-it-you-cite-it",
    "href": "about.html#you-use-it-you-cite-it",
    "title": "Syllabus",
    "section": "You use it, you cite it",
    "text": "You use it, you cite it\nIf you use AI like chatGPT to generate text or code for canvas discussions, projects or class presentations, you need to acknowledge the source and put the code or comment in quotes (or equivalent) the way you would if you were citing John Tukey or Aristoteles.\nUsing chatGPT text or code without acknowledgment will be considered cheating."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 117: Data Analysis in Modern Biostatistics",
    "section": "",
    "text": "Teaching Fellow: Ahmad Abdel-Azim\nOverview: The course is an introduction to the application of statistical concepts in biomedical research, through the lens of biomarker research in cancer biology and medicine. The foundation are two comprehensive collections of data on gene expression and clinical characteristics for patients with cancer of the ovaries and breast.\nObjectives: To develop a sense for practical applications of statistical thinking and tools in biomedical sciences. To learn how to make and defend statistical modeling choices in complex realistic applications. To constructively critique the analyses of others. To develop a working knowledge of R tools relevant for biomedical data science applications."
  },
  {
    "objectID": "L15-metaanalysis2.html",
    "href": "L15-metaanalysis2.html",
    "title": "Lecture 15: Metaanalysis part 2",
    "section": "",
    "text": "Lecture 15: Metaanalysis part 2\nsplit current L13 into two"
  },
  {
    "objectID": "L1-intro.html#goal",
    "href": "L1-intro.html#goal",
    "title": "Lecture 1 Introduction",
    "section": "Goal",
    "text": "Goal\nThe course is an introduction to the application of statistical concepts in biomedical research, through the lens of biomarker research in cancer biology. The general objectives of the course are to develop a sense for practical applications of statistical thinking and tools in biomedical sciences. Concepts and interpretation receive more emphasis than how-to training. The code is often written with far more attention to interpretability than efficiency."
  },
  {
    "objectID": "L1-intro.html#audience-and-prerequisites",
    "href": "L1-intro.html#audience-and-prerequisites",
    "title": "Lecture 1 Introduction",
    "section": "Audience and Prerequisites",
    "text": "Audience and Prerequisites\nThe audience for this class consists mostly of Statistics and Computer Science concentrators at Harvard College. When we teach this course at Harvard we require students to have taken a statistical inference class and a regression/modeling class.\nAlso a class on statistical learning or introductory machine learning at the level of James et al is very helpful."
  },
  {
    "objectID": "L1-intro.html#r-and-rstudio-setup",
    "href": "L1-intro.html#r-and-rstudio-setup",
    "title": "Lecture 1 Introduction",
    "section": "R and RStudio Setup",
    "text": "R and RStudio Setup\nThis course is designed for R within RStudio. The course notes written in Quarto, a markdown language for R currently provided with the free version of RStudio.\nThis section guides you through setting up your computing environment. First install R and RStudio. This code checks you have the latest version of R. If not, this code will direct you to the R website where you can select your operating system for the appropriate updates.\n\nif(as.numeric(gsub(\".\", \"\",\n    substring(version[['version.string']], 11, 15),\n      fixed = TRUE)) &lt; 422)\n{\n  browseURL(\"https://cran.r-project.org/bin/\")\n  stop(\"Please update to the newest version of R!\")\n}\n\nNext, this code will install all the necessary R and Bioconductor packages to run the examples in the course. It will normally take a while to install. First we make a list of all the packages we need,\n\nR_package_list &lt;- c(\"BH\", \"BiocManager\", \"CompQuadForm\", \"DBI\", \"KernSmooth\",\n    \"MASS\", \"Matrix\", \"R2WinBUGS\", \"R2jags\", \"R6\", \"RCurl\", \"ROCR\",\n    \"RSQLite\", \"Rcpp\", \"RcppEigen\", \"SQUAREM\", \"SuppDists\", \"XML\",\n    \"abind\", \"assertthat\", \"base64enc\", \"bit\", \"bit64\", \"bitops\",\n    \"blob\", \"bookdown\", \"boot\", \"bootstrap\", \"caTools\", \"class\",\n    \"classInt\", \"cli\", \"clipr\", \"coda\", \"codetools\", \"combinat\",\n    \"crayon\", \"digest\", \"dplyr\", \"e1071\", \"ellipsis\", \"evaluate\",\n    \"fansi\", \"fastmap\", \"fdrtool\", \"forcats\", \"foreach\", \"formatR\",\n    \"futile.logger\", \"futile.options\", \"gam\", \"gdata\", \"glue\", \"gplots\",\n    \"gtools\", \"haven\", \"highr\", \"hms\", \"htmltools\", \"httpuv\", \"ipred\",\n    \"iterators\", \"jsonlite\", \"klaR\", \"knitr\", \"labelled\", \"lambda.r\",\n    \"later\", \"lattice\", \"lava\", \"lifecycle\", \"lme4\", \"locfit\", \"logging\",\n    \"magrittr\", \"markdown\", \"matrixStats\", \"memoise\", \"meta\", \"metafor\",\n    \"mime\", \"miniUI\", \"minqa\", \"nloptr\", \"nnet\", \"numDeriv\", \"pROC\",\n    \"pillar\", \"pkgconfig\", \"plogr\", \"plyr\", \"pracma\", \"prodlim\",\n    \"promises\", \"purrr\", \"questionr\", \"readr\", \"renv\", \"rjags\", \"rlang\",\n    \"rmarkdown\", \"rmeta\", \"rstudioapi\", \"shiny\", \"snow\", \"sourcetools\",\n    \"statmod\", \"stringi\", \"stringr\", \"survival\", \"survivalROC\", \"tibble\",\n    \"tidyselect\", \"tinytex\", \"tidyverse\", \"utf8\", \"vctrs\", \"xfun\",\n    \"xtable\", \"yaml\", \"ggplot2\")\nBioc_package_list &lt;- c(\"AnnotationDbi\", \"Biobase\", \"BiocGenerics\",\n    \"BiocParallel\", \"IRanges\", \"S4Vectors\", \"affy\", \"affyio\", \"annotate\",\n    \"curatedOvarianData\", \"curatedBreastData\", \"edgeR\", \"genefilter\",\n    \"impute\", \"limma\", \"preprocessCore\", \"survcomp\", \"sva\", \"switchBox\",\n    \"zlibbioc\")\n\nand then we proceed with the actual installation.\n\nR_packages_missing &lt;- R_package_list[which(R_package_list %in% installed.packages() ==\n    F)]\n# Finds which of the required CRAN R packages are missing\nBioc_packages_missing &lt;- Bioc_package_list[which(Bioc_package_list %in%\n    installed.packages() == F)]\n# Finds which of the required Bioconductor R packages are\n# missing\n# Installs Cran R packages if they are missing\nif (length(R_packages_missing) != 0) {\n    install.packages(pkgs = R_packages_missing, repos = \"https://cloud.r-project.org\")\n}\n# Installs Bioconductor Manager\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) {\n    install.packages(\"BiocManager\")\n}\n# Installs Bioconductor R packages if they are missing\nBiocManager::install()\nif (length(Bioc_packages_missing) != 0) {\n    BiocManager::install(Bioc_package_list)\n}"
  },
  {
    "objectID": "L1-intro.html#data",
    "href": "L1-intro.html#data",
    "title": "Lecture 1 Introduction",
    "section": "Data",
    "text": "Data\n\nData Sources\nThe foundation of the course is a comprehensive collection of gene expression and clinical characteristics for patients with cancer of the ovaries, called CuratedOvarianData LINK.\nThe package contains gene expression biomarker data collected at time of diagnosis from patients with ovarian cancer, along with matched “phenodata” about their subsequent health outcomes, such as how long they lived. A project culminating in the paper “curatedOvarianData: clinically annotated data for the ovarian cancer transcriptome” LINK, collected, processed and harmonized existing ovarian cancer data in the literature. Data is ready for direct data analysis.\nWe will also draw from the similar CuratedBreastData package LINK.\n\n\n\nData Structure\nFigure 1 is a cartoon of the data structure. Each of several studies includes a large number of candidate gene expression biomarkers, and a few outcomes, or labels, or phenotypes. Candidate biomarkers are arranged so that rows have comparable meaning across studies. This type of data allows us to explore biomarker evaluation, discovery, validation, meta-analysis, and classification using a single dataset.\n\n\n\n\n\n\nFigure 1: Data Structure"
  },
  {
    "objectID": "L1-intro.html#course-topics",
    "href": "L1-intro.html#course-topics",
    "title": "Lecture 1 Introduction",
    "section": "Course Topics",
    "text": "Course Topics\n\nQuestions considered in the course and their relation to Figure 1\n\n\n\n\n\n\n\nResearch Goal\nQuestion\nData\n\n\n\n\nBiomarker Evaluation\nUtility of biomarker for clinical decision and…\n1 study, 1 biomarker\n\n\n\n…its generalilzability\nk studies, 1 biomarker\n\n\nBiomarker Discovery\nSearch / prioritization of candidate biomarkers and…\n1 study, p biomarkers\n\n\n\n… its reblicability across studies\nk studies, p biomarkers\n\n\nBiomarker-based Risk Stratification\nPrediction of future patient outcomes\ndesign your own data subsets\n\n\n\n\nQuestions considered in the course and related methodologies\n\n\n\n\n\n\nResearch Goal\nQuantitative Method\n\n\n\n\nBiomarker Evaluation\nOdds ratios and relative risks, sensitivity, specificity, ROC analysis, effect sizes, priors + posteriors; MCMC (as implementable in Rjags), value of information analysis, time-to-event biomarkers\n\n\n\nBiomarker Meta-analysis Systematic reviews, basic hierarchical models, MCMC for hierarchical models\n\n\nBiomarker Discovery\nHigh dimensional biomarker searches, multiple testing, False Discovery Rates, regression to the mean\n\n\n\nCross-study concordance, r-values\n\n\nBiomarker-based Risk Stratification\nSelected basic machine learning algorithms (e.g. clipping, CART, top scoring pairs), cross-validation versus cross-study validation.\n\n\n\nSPUDS https://uraf.harvard.edu/uraf-opportunities/spuds"
  },
  {
    "objectID": "L14-shrinkage2.html",
    "href": "L14-shrinkage2.html",
    "title": "Lecture 14: Shrinkage part 2",
    "section": "",
    "text": "Lecture 14: Shrinkage part 2\nsplit current L12 into two"
  },
  {
    "objectID": "L12-shrinkage.html",
    "href": "L12-shrinkage.html",
    "title": "Lecture 12: Shrinkage",
    "section": "",
    "text": "So far, we have studied the following concepts:\n\n\n\n\n\nIn this chapter we are going to start thinking about what about multi-level models. These specify a joint statistical model, not just for an individual biomarker in an individual study, but either multiple biomarkers or multiple studies at the same time. And if we get adventurous before the end of the course we will write models where encompassing both multiple biomarkers and multiple studies. The idea for this chapter is to do one of these at the time.\nSome of the main concepts will be:\nThe methods we will utilize will be Monte Carlo Markov Chains (MCMC).\nAnalyses of individual biomarkers are seemingly separate problems, which in reality share important statistical features. Importantly they share common sources of noise from the technology.\nAnalyses of the same gene in different studies are seemingly identical problems, which in reality present important differences. Importantly they inherit differences in study inclusion criteria, design and populations.\n\n\n\n\nLet’s begin by reminding ourselves of the data structure that we’re going to be using. It is essentially the data structure of our curated ovarian data, where you have a set of studies, each of which includes a matrix of biomarkers and a vector of labels.\n\nLet’s focus on a single biomarker, say CXCL12, in a single study. There you have a row of \\(X\\) that represents the levels of CXCL12 and you have a role a corresponding row of labels. That’s the structure on which we have looked at all our statistics so far, when we did when we did discovery. We did a battery of these, but we always did them one at a time.\nHere we are going to think about extending this paradigm in two directions. One is to look at variability across biomarkers within a study (this lecture), and the other is to look at variability of biomarker behavior across studies (next lecture).\n\n\n\n\n\n\n\n\nSince the “MCMC revolution” multilevel models have been the backbone of Bayesian data analysis\nIn genomic data sets they can be used to implement:\nThis is a useful introduction. Laredo provides a very useful introduction (pages 1-28) and a cool application in astronomy. I recommend you go over pages 1-28 before going forward with our lecture notes.\nFor those who want to dig a bit deeper Morris and Lysy offer a great review.\nMost textbooks on Bayesian statistics have chapters on multi-level models.\n\n\n\n\nGene-level Summaries:\ncontinuous genomic feature: gene expression microarray readout in the TCGA study\nbinary phenotype (optimal surgical debulking)\n\n\nlibrary(curatedOvarianData)\ndata(\"TCGA_eset\")\nXX = as.matrix(cbind(exprs(TCGA_eset)))\nYY = 1 * as.vector(pData(TCGA_eset)[,\"debulking\"]==\"optimal\")\nXX = XX[,!is.na(YY)];\nYY = YY[!is.na(YY)]\n\n\nCompute Gene-Level Summaries\n\n\nCompSummaries = function(XX,YY){\nNGenes = nrow(XX)\nSSS = data.frame(matrix(NA,NGenes,4))\ncolnames(SSS) = \n  c(\"abundance\",\"difference\",\"variance\",\"SNratio\")\nfor (gg in 1:NGenes){\n  SSS[gg,\"abundance\"] = mean(XX[gg,])\n  m1 = mean( XX[gg,YY==1] ); m0 = mean( XX[gg,YY==0] ); \n  n1 = sum(YY==1); n0 = sum(YY==0); \n  SSS[gg,\"difference\"] = m1 - m0\n  SSS[gg,\"variance\"] = ( sum( ( XX[gg,YY==1] - m1 )^2 ) + sum( ( XX[gg,YY==0] - m0 )^2 ) ) / (n0+n1-2)\n  SSS[gg,\"SNratio\"] = \n    SSS[gg,\"difference\"] / sqrt( SSS[gg,\"variance\"] )\n}\nreturn(SSS)\n}\nGeneSummaries = CompSummaries(XX,YY)\n\n\n\n\n\n\nhist(GeneSummaries[,\"abundance\"],nclass=100)\n\n\n\n\n\n\n\n\n\n\nhist(GeneSummaries[,\"difference\"],nclass=100)\n\n\n\n\n\n\n\n\n\n\nqqnorm(GeneSummaries[,\"difference\"])\n\n\n\n\n\n\n\n\n\n\nhist(sqrt(GeneSummaries[,\"variance\"]),nclass=100)\n\n\n\n\n\n\n\n\n\n\nhist(GeneSummaries[,\"SNratio\"],nclass=100)\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot(GeneSummaries[,\"abundance\"],GeneSummaries[,\"difference\"],pch=\".\")\n\n\n\n\n\n\n\n\n\n\nplot(GeneSummaries[,\"abundance\"],sqrt(GeneSummaries[,\"variance\"]),pch=\".\")\n\n\n\n\n\n\n\n\n\n\nplot(sqrt(GeneSummaries[,\"variance\"]),GeneSummaries[,\"difference\"],pch=\".\")\n\n\n\n\n\n\n\n\n\n\nplot(GeneSummaries[,\"abundance\"],GeneSummaries[,\"SNratio\"],pch=\".\")\n\n\n\n\n\n\n\n\n\n\n\n\nWe begin with a relatively simple setting where the class-conditional distributions are gaussian.\nEach gene distribution is characterized by three parameters:\n\\(\\delta_g\\): true mean difference across classes\n\\(\\sigma_g\\): true noise, common to both classes\n\\(\\alpha_g\\): true abundance (average overeall expression marginally)\nIn addition we have \\(\\pi\\): proportion of label 1’s, assumed known.\nGenes are assumed to be conditionally independent.\n\n\n\n\n\n\nNote\n\n\n\nIn this model, does the data on genes 2 through G give you information you did not have before about gene 1?\nWhy or why not?\n\n\n\n\n\n\nOu next step is to model the distribution of the gene specific parameters, to describe how these parameters vary across the genome. We have three of them and we can make all sorts of assumptions about how they are jointly distributed. Here are some options\n\n\n\n\nGene-level Parameters: \\(\\theta_g = (\\alpha_g,\\delta_g,\\sigma_g)\\)\nGenome-level Parameters: \\(\\gamma = \\tau, \\lambda, \\nu, \\beta\\)\nData: \\(D\\)\nLikelihood: \\(p( D | \\gamma, \\theta_1, \\ldots, \\theta_G)\\)\nThis bypasses specification of a prior at the top level, and still gives a shrinkage estimate of the gene-level parameters.\nFor example in the conjugate model written earlier:\n\\[ E ( \\delta_g | D, \\gamma) = d_g  \\left( \\frac {1}{ 1 + \\frac {2}{\\lambda n}} \\right)\\]\nThis provides a shrinkage estimate of \\(\\delta_g\\). The amount of shrinkage is controlled by the estimate of \\(\\lambda\\), the genome-wide variance of the \\(\\delta\\)’s\n\n\n\n\nDraw samples of parameters to get a sense for their location and spread.\n\n\n\n\nWe select genes with an abundance of at least 5, and then take a random sample of the rest.\n\nhighAbundance = GeneSummaries[,\"abundance\"] &gt; 5\nXXX = XX[highAbundance,]\nNha = sum(highAbundance)\nset.seed(117)\nNinclude = 900\ninclude = sample(1:Nha,Ninclude)\nXXX = XXX[include,]\nYYY = YY\nGeneSummInclude = CompSummaries(XXX,YYY)\n\n\n\npairs(GeneSummInclude,pch=\".\")\n\n\n\n\n\n\n\n\n\n\n\n\n\ndiffexpModel =\"model\n{\n  precision.s ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.a ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.d ~ dnorm( 0.0, 0.01 ) T(0,);\n  for ( g in 1:G ){\n    sigma2inv[g] ~ dnorm( 0.0, precision.s ) T(0,);\n    alpha[g] ~ dnorm(cut, precision.a) T(cut,);\n    delta[g] ~ dnorm(0.0, sigma2inv[g] * precision.d);\n  }\n  for ( g in 1:G ) {\n    for ( i in 1:N ) {\n            XX[g,i] ~ dnorm( alpha[g] + \n            ( YY[i] * (1-pi) - \n            (1-YY[i]) * pi ) * delta[g], sigma2inv[g]);\n      } \n    }\n}\n\"\n\n\n\nlibrary(rjags)\nlibrary(R2jags)\nlibrary(coda)\ndiffexp = jags.model(textConnection(diffexpModel),\n                   data = list( XX = XXX, YY=YYY, N=length(YYY), G=nrow(XXX), pi=mean(YYY),cut=5),\n                   n.chains = 1,\n                   n.adapt = 100)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 456300\n   Unobserved stochastic nodes: 2703\n   Total graph size: 464026\n\nInitializing model\n\nmcmc.out = coda.samples(diffexp,c(\"alpha\",\"delta\",\"sigma2inv\",\n                                  \"precision.a\",\"precision.d\",\"precision.s\"),\n                        n.iter = 1000,thin=10)\nalpha = mcmc.out[[1]][,grep(\"alpha\",colnames(mcmc.out[[1]]))]\ndelta = mcmc.out[[1]][,grep(\"delta\",colnames(mcmc.out[[1]]))]\nsigma = 1 / sqrt( mcmc.out[[1]][,grep(\"sigma2inv\",colnames(mcmc.out[[1]]))] )\nalpha.hat = apply(alpha,2,mean)\ndelta.hat = apply(delta,2,mean)\n\n\nOne way to look at shrinkage is to compare the posterior estimates to the corresponding gene-specific MLEs.\nLet’s look at the \\(\\alpha\\)’s\n\nplot(GeneSummInclude[,\"abundance\"],alpha.hat)\n\n\n\n\n\n\n\n\n\nLet’s now look at the \\(\\delta\\)’s\n\nplot(GeneSummInclude[,\"difference\"],delta.hat)\nabline(0,1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nwhy is the shrinkage of the alpha’s so much less pronounced than the shrinkage of the delta’s?\n\n\n\n\n\n\nTo contrast, this code implements a point and slab model which assumes that some unknown proportion of genes have a \\(\\delta\\) that is superclose to zero.\n\n\n\n\n\n\nNote\n\n\n\nCan you tell how I did that?\nHow do we interpert the hh variable?\nWhy is hh a good letter in this case?\n\n\n\ndiffexpModel.01 =\"model\n{\n  precision.s ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.a ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.d ~ dnorm( 0.0, 0.01 ) T(0,);\n  ph0 ~ dunif(0,1);\n  for ( g in 1:G ){\n    hh[g] ~ dbern(1-ph0);\n    sigma2inv[g] ~ dnorm( 0.0, precision.s ) T(0,);\n    alpha[g] ~ dnorm(cut, precision.a) T(cut,);\n     delta[g] ~ dnorm(0.0, (1-hh[g]) * 10000 + hh[g] * sigma2inv[g] * (precision.d)  );\n  }\n  for ( g in 1:G ) {\n    for ( i in 1:N ) {\n            XX[g,i] ~ dnorm( alpha[g] + \n            ( YY[i] * (1-pi) - \n            (1-YY[i]) * pi ) * delta[g], sigma2inv[g] );\n      } \n    }\n}\n\"\n\n\n\nlibrary(rjags)\nlibrary(R2jags)\nlibrary(coda)\ndiffexp = jags.model(textConnection(diffexpModel.01),\n                   data = list( XX = XXX, YY=YYY, N=length(YYY), G=nrow(XXX), pi=mean(YYY),cut=5 ),\n                   n.chains = 1,\n                   n.adapt = 100)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 456300\n   Unobserved stochastic nodes: 3604\n   Total graph size: 467629\n\nInitializing model\n\nmcmc.out = coda.samples(diffexp,c(\"alpha\",\"delta\",\"sigma2inv\",\"hh\",\"ph0\",\n                                  \"precision.a\",\"precision.d\",\"precision.s\"),\n                        n.iter = 1000,thin=10)\nalpha = mcmc.out[[1]][,grep(\"alpha\",colnames(mcmc.out[[1]]))]\ndelta = mcmc.out[[1]][,grep(\"delta\",colnames(mcmc.out[[1]]))]\nsigma = 1 / sqrt( mcmc.out[[1]][,grep(\"sigma2inv\",colnames(mcmc.out[[1]]))] )\nhh = mcmc.out[[1]][,grep(\"hh\",colnames(mcmc.out[[1]]))]\nalpha.hat = apply(alpha,2,mean)\ndelta.hat = apply(delta,2,mean)\ndelta.med = apply(delta,2,median)\nhh.hat = apply(hh,2,mean)\n\n\n\nsummary(mcmc.out[[1]][,c(\"ph0\",\"precision.a\",\"precision.d\",\"precision.s\")])\n\n\nIterations = 110:1100\nThinning interval = 10 \nNumber of chains = 1 \nSample size per chain = 100 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n               Mean       SD  Naive SE Time-series SE\nph0          0.9585 0.029661 0.0029661      0.0172528\nprecision.a  0.1305 0.006263 0.0006263      0.0006263\nprecision.d 22.9849 8.180652 0.8180652      2.6154521\nprecision.s  0.1117 0.005536 0.0005536      0.0004727\n\n2. Quantiles for each variable:\n\n              2.5%     25%     50%     75%   97.5%\nph0         0.8967  0.9414  0.9625  0.9846  0.9969\nprecision.a 0.1179  0.1267  0.1299  0.1347  0.1417\nprecision.d 6.7714 17.3542 23.4045 28.4747 37.6601\nprecision.s 0.1019  0.1076  0.1119  0.1154  0.1216\n\n\n\n\nplot(GeneSummInclude[,\"abundance\"],alpha.hat,pch=\".\")\nabline(0,1)\n\n\n\n\n\n\n\n\n\n\nplot(GeneSummInclude[,\"difference\"],delta.hat,pch=\".\")\nabline(0,1)\n\n\n\n\n\n\n\n\n\nplot(GeneSummInclude[,\"difference\"],delta.med,pch=\".\")\nabline(0,1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ncontrast this shrinkage pattern to the fully conjugate\n\n\n\n\npairs(cbind(GeneSummInclude,hh.hat),pch=\".\")\n\n\n\n\n\n\n\n\n\n\nplot(delta.hat,hh.hat,pch=\".\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nthink about how to construct an estimate of FDR if all hou have is hh.hat"
  },
  {
    "objectID": "L12-shrinkage.html#recap",
    "href": "L12-shrinkage.html#recap",
    "title": "Lecture 12: Shrinkage",
    "section": "",
    "text": "So far, we have studied the following concepts:"
  },
  {
    "objectID": "L12-shrinkage.html#multilevel-models",
    "href": "L12-shrinkage.html#multilevel-models",
    "title": "Lecture 12: Shrinkage",
    "section": "",
    "text": "In this chapter we are going to start thinking about what about multi-level models. These specify a joint statistical model, not just for an individual biomarker in an individual study, but either multiple biomarkers or multiple studies at the same time. And if we get adventurous before the end of the course we will write models where encompassing both multiple biomarkers and multiple studies. The idea for this chapter is to do one of these at the time.\nSome of the main concepts will be:\nThe methods we will utilize will be Monte Carlo Markov Chains (MCMC).\nAnalyses of individual biomarkers are seemingly separate problems, which in reality share important statistical features. Importantly they share common sources of noise from the technology.\nAnalyses of the same gene in different studies are seemingly identical problems, which in reality present important differences. Importantly they inherit differences in study inclusion criteria, design and populations.\n\n\n\n\nLet’s begin by reminding ourselves of the data structure that we’re going to be using. It is essentially the data structure of our curated ovarian data, where you have a set of studies, each of which includes a matrix of biomarkers and a vector of labels.\n\nLet’s focus on a single biomarker, say CXCL12, in a single study. There you have a row of \\(X\\) that represents the levels of CXCL12 and you have a role a corresponding row of labels. That’s the structure on which we have looked at all our statistics so far, when we did when we did discovery. We did a battery of these, but we always did them one at a time.\nHere we are going to think about extending this paradigm in two directions. One is to look at variability across biomarkers within a study (this lecture), and the other is to look at variability of biomarker behavior across studies (next lecture)."
  },
  {
    "objectID": "L12-shrinkage.html#multilevel-modeling-of-genes",
    "href": "L12-shrinkage.html#multilevel-modeling-of-genes",
    "title": "Lecture 12: Shrinkage",
    "section": "",
    "text": "Since the “MCMC revolution” multilevel models have been the backbone of Bayesian data analysis\nIn genomic data sets they can be used to implement:\nThis is a useful introduction. Laredo provides a very useful introduction (pages 1-28) and a cool application in astronomy. I recommend you go over pages 1-28 before going forward with our lecture notes.\nFor those who want to dig a bit deeper Morris and Lysy offer a great review.\nMost textbooks on Bayesian statistics have chapters on multi-level models.\n\n\n\n\nGene-level Summaries:\ncontinuous genomic feature: gene expression microarray readout in the TCGA study\nbinary phenotype (optimal surgical debulking)\n\n\nlibrary(curatedOvarianData)\ndata(\"TCGA_eset\")\nXX = as.matrix(cbind(exprs(TCGA_eset)))\nYY = 1 * as.vector(pData(TCGA_eset)[,\"debulking\"]==\"optimal\")\nXX = XX[,!is.na(YY)];\nYY = YY[!is.na(YY)]\n\n\nCompute Gene-Level Summaries\n\n\nCompSummaries = function(XX,YY){\nNGenes = nrow(XX)\nSSS = data.frame(matrix(NA,NGenes,4))\ncolnames(SSS) = \n  c(\"abundance\",\"difference\",\"variance\",\"SNratio\")\nfor (gg in 1:NGenes){\n  SSS[gg,\"abundance\"] = mean(XX[gg,])\n  m1 = mean( XX[gg,YY==1] ); m0 = mean( XX[gg,YY==0] ); \n  n1 = sum(YY==1); n0 = sum(YY==0); \n  SSS[gg,\"difference\"] = m1 - m0\n  SSS[gg,\"variance\"] = ( sum( ( XX[gg,YY==1] - m1 )^2 ) + sum( ( XX[gg,YY==0] - m0 )^2 ) ) / (n0+n1-2)\n  SSS[gg,\"SNratio\"] = \n    SSS[gg,\"difference\"] / sqrt( SSS[gg,\"variance\"] )\n}\nreturn(SSS)\n}\nGeneSummaries = CompSummaries(XX,YY)\n\n\n\n\n\n\nhist(GeneSummaries[,\"abundance\"],nclass=100)\n\n\n\n\n\n\n\n\n\n\nhist(GeneSummaries[,\"difference\"],nclass=100)\n\n\n\n\n\n\n\n\n\n\nqqnorm(GeneSummaries[,\"difference\"])\n\n\n\n\n\n\n\n\n\n\nhist(sqrt(GeneSummaries[,\"variance\"]),nclass=100)\n\n\n\n\n\n\n\n\n\n\nhist(GeneSummaries[,\"SNratio\"],nclass=100)\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot(GeneSummaries[,\"abundance\"],GeneSummaries[,\"difference\"],pch=\".\")\n\n\n\n\n\n\n\n\n\n\nplot(GeneSummaries[,\"abundance\"],sqrt(GeneSummaries[,\"variance\"]),pch=\".\")\n\n\n\n\n\n\n\n\n\n\nplot(sqrt(GeneSummaries[,\"variance\"]),GeneSummaries[,\"difference\"],pch=\".\")\n\n\n\n\n\n\n\n\n\n\nplot(GeneSummaries[,\"abundance\"],GeneSummaries[,\"SNratio\"],pch=\".\")\n\n\n\n\n\n\n\n\n\n\n\n\nWe begin with a relatively simple setting where the class-conditional distributions are gaussian.\nEach gene distribution is characterized by three parameters:\n\\(\\delta_g\\): true mean difference across classes\n\\(\\sigma_g\\): true noise, common to both classes\n\\(\\alpha_g\\): true abundance (average overeall expression marginally)\nIn addition we have \\(\\pi\\): proportion of label 1’s, assumed known.\nGenes are assumed to be conditionally independent.\n\n\n\n\n\n\nNote\n\n\n\nIn this model, does the data on genes 2 through G give you information you did not have before about gene 1?\nWhy or why not?\n\n\n\n\n\n\nOu next step is to model the distribution of the gene specific parameters, to describe how these parameters vary across the genome. We have three of them and we can make all sorts of assumptions about how they are jointly distributed. Here are some options\n\n\n\n\nGene-level Parameters: \\(\\theta_g = (\\alpha_g,\\delta_g,\\sigma_g)\\)\nGenome-level Parameters: \\(\\gamma = \\tau, \\lambda, \\nu, \\beta\\)\nData: \\(D\\)\nLikelihood: \\(p( D | \\gamma, \\theta_1, \\ldots, \\theta_G)\\)\nThis bypasses specification of a prior at the top level, and still gives a shrinkage estimate of the gene-level parameters.\nFor example in the conjugate model written earlier:\n\\[ E ( \\delta_g | D, \\gamma) = d_g  \\left( \\frac {1}{ 1 + \\frac {2}{\\lambda n}} \\right)\\]\nThis provides a shrinkage estimate of \\(\\delta_g\\). The amount of shrinkage is controlled by the estimate of \\(\\lambda\\), the genome-wide variance of the \\(\\delta\\)’s\n\n\n\n\nDraw samples of parameters to get a sense for their location and spread.\n\n\n\n\nWe select genes with an abundance of at least 5, and then take a random sample of the rest.\n\nhighAbundance = GeneSummaries[,\"abundance\"] &gt; 5\nXXX = XX[highAbundance,]\nNha = sum(highAbundance)\nset.seed(117)\nNinclude = 900\ninclude = sample(1:Nha,Ninclude)\nXXX = XXX[include,]\nYYY = YY\nGeneSummInclude = CompSummaries(XXX,YYY)\n\n\n\npairs(GeneSummInclude,pch=\".\")\n\n\n\n\n\n\n\n\n\n\n\n\n\ndiffexpModel =\"model\n{\n  precision.s ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.a ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.d ~ dnorm( 0.0, 0.01 ) T(0,);\n  for ( g in 1:G ){\n    sigma2inv[g] ~ dnorm( 0.0, precision.s ) T(0,);\n    alpha[g] ~ dnorm(cut, precision.a) T(cut,);\n    delta[g] ~ dnorm(0.0, sigma2inv[g] * precision.d);\n  }\n  for ( g in 1:G ) {\n    for ( i in 1:N ) {\n            XX[g,i] ~ dnorm( alpha[g] + \n            ( YY[i] * (1-pi) - \n            (1-YY[i]) * pi ) * delta[g], sigma2inv[g]);\n      } \n    }\n}\n\"\n\n\n\nlibrary(rjags)\nlibrary(R2jags)\nlibrary(coda)\ndiffexp = jags.model(textConnection(diffexpModel),\n                   data = list( XX = XXX, YY=YYY, N=length(YYY), G=nrow(XXX), pi=mean(YYY),cut=5),\n                   n.chains = 1,\n                   n.adapt = 100)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 456300\n   Unobserved stochastic nodes: 2703\n   Total graph size: 464026\n\nInitializing model\n\nmcmc.out = coda.samples(diffexp,c(\"alpha\",\"delta\",\"sigma2inv\",\n                                  \"precision.a\",\"precision.d\",\"precision.s\"),\n                        n.iter = 1000,thin=10)\nalpha = mcmc.out[[1]][,grep(\"alpha\",colnames(mcmc.out[[1]]))]\ndelta = mcmc.out[[1]][,grep(\"delta\",colnames(mcmc.out[[1]]))]\nsigma = 1 / sqrt( mcmc.out[[1]][,grep(\"sigma2inv\",colnames(mcmc.out[[1]]))] )\nalpha.hat = apply(alpha,2,mean)\ndelta.hat = apply(delta,2,mean)\n\n\nOne way to look at shrinkage is to compare the posterior estimates to the corresponding gene-specific MLEs.\nLet’s look at the \\(\\alpha\\)’s\n\nplot(GeneSummInclude[,\"abundance\"],alpha.hat)\n\n\n\n\n\n\n\n\n\nLet’s now look at the \\(\\delta\\)’s\n\nplot(GeneSummInclude[,\"difference\"],delta.hat)\nabline(0,1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nwhy is the shrinkage of the alpha’s so much less pronounced than the shrinkage of the delta’s?\n\n\n\n\n\n\nTo contrast, this code implements a point and slab model which assumes that some unknown proportion of genes have a \\(\\delta\\) that is superclose to zero.\n\n\n\n\n\n\nNote\n\n\n\nCan you tell how I did that?\nHow do we interpert the hh variable?\nWhy is hh a good letter in this case?\n\n\n\ndiffexpModel.01 =\"model\n{\n  precision.s ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.a ~ dnorm( 0.0, 0.01 ) T(0,);\n  precision.d ~ dnorm( 0.0, 0.01 ) T(0,);\n  ph0 ~ dunif(0,1);\n  for ( g in 1:G ){\n    hh[g] ~ dbern(1-ph0);\n    sigma2inv[g] ~ dnorm( 0.0, precision.s ) T(0,);\n    alpha[g] ~ dnorm(cut, precision.a) T(cut,);\n     delta[g] ~ dnorm(0.0, (1-hh[g]) * 10000 + hh[g] * sigma2inv[g] * (precision.d)  );\n  }\n  for ( g in 1:G ) {\n    for ( i in 1:N ) {\n            XX[g,i] ~ dnorm( alpha[g] + \n            ( YY[i] * (1-pi) - \n            (1-YY[i]) * pi ) * delta[g], sigma2inv[g] );\n      } \n    }\n}\n\"\n\n\n\nlibrary(rjags)\nlibrary(R2jags)\nlibrary(coda)\ndiffexp = jags.model(textConnection(diffexpModel.01),\n                   data = list( XX = XXX, YY=YYY, N=length(YYY), G=nrow(XXX), pi=mean(YYY),cut=5 ),\n                   n.chains = 1,\n                   n.adapt = 100)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 456300\n   Unobserved stochastic nodes: 3604\n   Total graph size: 467629\n\nInitializing model\n\nmcmc.out = coda.samples(diffexp,c(\"alpha\",\"delta\",\"sigma2inv\",\"hh\",\"ph0\",\n                                  \"precision.a\",\"precision.d\",\"precision.s\"),\n                        n.iter = 1000,thin=10)\nalpha = mcmc.out[[1]][,grep(\"alpha\",colnames(mcmc.out[[1]]))]\ndelta = mcmc.out[[1]][,grep(\"delta\",colnames(mcmc.out[[1]]))]\nsigma = 1 / sqrt( mcmc.out[[1]][,grep(\"sigma2inv\",colnames(mcmc.out[[1]]))] )\nhh = mcmc.out[[1]][,grep(\"hh\",colnames(mcmc.out[[1]]))]\nalpha.hat = apply(alpha,2,mean)\ndelta.hat = apply(delta,2,mean)\ndelta.med = apply(delta,2,median)\nhh.hat = apply(hh,2,mean)\n\n\n\nsummary(mcmc.out[[1]][,c(\"ph0\",\"precision.a\",\"precision.d\",\"precision.s\")])\n\n\nIterations = 110:1100\nThinning interval = 10 \nNumber of chains = 1 \nSample size per chain = 100 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n               Mean       SD  Naive SE Time-series SE\nph0          0.9585 0.029661 0.0029661      0.0172528\nprecision.a  0.1305 0.006263 0.0006263      0.0006263\nprecision.d 22.9849 8.180652 0.8180652      2.6154521\nprecision.s  0.1117 0.005536 0.0005536      0.0004727\n\n2. Quantiles for each variable:\n\n              2.5%     25%     50%     75%   97.5%\nph0         0.8967  0.9414  0.9625  0.9846  0.9969\nprecision.a 0.1179  0.1267  0.1299  0.1347  0.1417\nprecision.d 6.7714 17.3542 23.4045 28.4747 37.6601\nprecision.s 0.1019  0.1076  0.1119  0.1154  0.1216\n\n\n\n\nplot(GeneSummInclude[,\"abundance\"],alpha.hat,pch=\".\")\nabline(0,1)\n\n\n\n\n\n\n\n\n\n\nplot(GeneSummInclude[,\"difference\"],delta.hat,pch=\".\")\nabline(0,1)\n\n\n\n\n\n\n\n\n\nplot(GeneSummInclude[,\"difference\"],delta.med,pch=\".\")\nabline(0,1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ncontrast this shrinkage pattern to the fully conjugate\n\n\n\n\npairs(cbind(GeneSummInclude,hh.hat),pch=\".\")\n\n\n\n\n\n\n\n\n\n\nplot(delta.hat,hh.hat,pch=\".\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nthink about how to construct an estimate of FDR if all hou have is hh.hat"
  },
  {
    "objectID": "L3-data.html",
    "href": "L3-data.html",
    "title": "Lecture 3: Data",
    "section": "",
    "text": "Specimen Acquisition (get the samples, preserve them between the clinic and the lab, isolate the cells of interest etc)\nExtraction / Preparation Protocols (extract RNA from the samples, often do additional preparation to get it ready for analysis (e.g add tags); often convert RNA into complementary DNA, or cDNA; break sequences into tiny fragments to be reassembled later)\nQuantification (run the experiment)\nRaw Data (typically images)\nYour Data (a heavily preprocessed summary attempting to quantify expression at the aggregate level of a “gene”)\n\n\n\n\n\nWe will work with expression data after it has been preprocessed and summarized at the gene label level. We will analyze a lot of data from the Affy platform. Preprocessing is a statistically challenging step. Some of the most important issues for Affymetrix data are discussed by @Owzar2008ccr\nI also highly recommend Katerina Taskova’s Introduction to Microarray Analysis slide deck.\n\n\n\n\n\n\nReading Notes\n\n\n\n\nRMA (slides 13-17) was used to preprocess the data we will use. A high-level understanding is useful. It produces summaries of expression at the level of the probe-set.\nIt is useful to know the difference between a probe (a single 25-nucleotide sequence), a probe-set (a group of probes predicted to appear on the coding sequence of a gene) and a gene (a region of DNA believed to often be the source of information for the production of a particular set of related proteins).\nMultiple probe-sets can map the same gene (for a digression about this see [@stalteri2007bmcb]) To keep things simple and to cross-reference features across technologies we have averaged over these and will use data at the gene level [@ganzfried2013curatedovariandata].\nThink about quantile normalization (QN) when looking at Slide 19. Does QN help? Does it remove the artifact in bad.cel completely? Does it remove the “fog” in NEG10-1?\nWe will cover differential expression later in the course (Slides 23-29). You are welcome to take a peek, but you can skip for now.\nEach of the bullets on Slide 30 embeds its own sources of both noise and systematic biases.\n\n\n\nMultiple probe sets for the same gene in Affy are sometimes designed to capture different isoforms (that is messenger RNAs made with different selection of exons). Because Affy needs to position probes near one end of the gene (long story), the extent to which they can capture different isoforms is not great compared to RNA-seq. But there could certainly be exceptions. Affy also used multiple probe sets to increase the number of probes dedicated to a certain genes, when the gene is important or there is uncertainty about mapping. In these cases averaging actually helps.\nRabbit hole: For those interested in a digression on imaging approaches (not covered at all in the class) including a menagerie of artifacts, see @arteaga-salas2007bb\n\n\n\n\nRNA-seq is the current alternative to hybridization microarrays. There are several RNA-seq datasets in the CuratedOvarianCanceer and CuratedBreastCancer package you will use in this class, but RNA-seq data exploration will be mostly optional. The main statistical lessons for this course can be learned equally well from Affy data. Of course I would not say this about a Bioinformatics class.\nFor those interested in understanding RNA-seq a bit more, I recommend the sections “Overview” and “Alignment and Quantification” from @VandenBerge2019arbds\n@Xu2013bmcb report a head-to-head comparison of Affy and RNA-seq high throughput measurements. RNA-seq generates count data. It is interesting to look at Figure 1 and think about how to interpret the “stripes” in panel B.\nMicroarrays are rarely used for discovery these days. Many of the statistical challenges of biomarker discovery, however, have remained the same. The advantage of using microarrays for this course is there there are far more studies readily available, so certain parts of the course still work a lot better with microarray than RNA-seq.\n\n\n\n\n\nHigh-throughput biology data are often produced in batches for efficiency or practical restrictions. Differences across how these batches are handled (in any of the bullets in Slide 30 of Katerina Taskova’s Introduction to Microarray Analysis), can drive significant variation across batches, resulting in so-called batch effects.\nCuratedOvarianData has been preprocessed to adjust for batches defined by the study of origin using Combat [@Johnson2006]. Other batch effects may be present.\n@Leek2010nrg wrote a useful overview of batch effects.\n\n\n\n\n\n\nComprehensive review of predictors and datasets for signature validation @Waldron2014\n\n\n\n\n\n\n\nScheme of preprocessing pipeline for the CuratedOvarianData Package\n\n\nDetailed description of dataset @ganzfried2013curatedovariandata\n\n\n\n\n\n\n\nThis heatmap visualizes for each curated clinical characteristic (rows) the availability in each data set (columns). Red indicates that the corresponding characteristic is available for at least one sample in the data set. See @ganzfried2013curatedovariandata for further details.\n\n\nIt may seem disappointing that there are only two clinical annotations that all of these datasets have. When we originally created the dataset we recontacted all the groups that originally generated the data to try to fill as many of the gaps as possible. Unfortunately some of the clinical data may not have been collected, or may not be easy to share due to privacy concerns or investigators’ reluctance. Since we compiled this data, the field has moved towards larger coordinated efforts across multiple institutions, which have had better outcomes in terms of completeness and homogeneity of phenotypes. An example is PCAWG but heterogeneity and missingness of labels remain important issues in health data.\n\n\n\n\nWe next load the CuratedOvarianData package and two datasets contained within. For now we will only consider the datasets TCGA_eset and GSE32063_eset. To check important characteristics of each of the studies, just enter the study ID (for example GSE32063) in the Gene Expression Omnibus query page\n\nlibrary(curatedOvarianData)\n# data(package=\"curatedOvarianData\")\n# Above line would lists all datasets available within the package.\ndata(TCGA_eset)\ndata(GSE32063_eset)\n\n\n\nhead(exprs(TCGA_eset)[1:6,1:6])\n\n      TCGA.20.0987 TCGA.23.1031 TCGA.24.0979 TCGA.23.1117 TCGA.23.1021\nA1CF      2.923522     3.052169     2.846371     3.002209     3.062993\nA2M      10.353008    11.635772     7.954542     9.971500     8.971334\nA4GNT     3.321405     3.666463     3.258038     3.596212     3.388706\nAAAS      4.608010     5.142133     5.025422     5.139928     5.256831\nAACS      7.279213     7.048869     7.750161     6.206031     7.835422\nAADAC     4.605331     5.775611     3.846412     4.468379     4.415817\n      TCGA.04.1337\nA1CF      2.974734\nA2M       9.042876\nA4GNT     3.269979\nAAAS      4.667723\nAACS      6.763047\nAADAC     4.159804\n\nhead(exprs(GSE32063_eset)[1:6,1:6])\n\n          GSM795125 GSM795126 GSM795127  GSM795128 GSM795129  GSM795130\nA1BG     -6.3146850 -4.566943 -6.998341 -5.6383615 -6.780428 -5.1891665\nA1BG-AS1 -3.6973042 -2.848625 -2.519599 -3.4870706 -3.043527 -2.6745200\nA1CF     -5.5054617 -3.861939 -4.552987 -4.5571017 -4.753347 -0.3129711\nA2M       3.2657738  3.373391  5.217385  4.3027153  3.599464  3.2226200\nA2ML1    -0.8923645 -0.733676 -1.512566 -0.7562313 -1.414893 -0.8385077\nA3GALT2  -5.0457100 -4.183009 -4.553020 -4.2992754 -4.304550 -4.4622746\n\n\n\n\n\n\nClustered heatmap of the top 100 most variable genes in the first 50 samples in TCGA. The expression scale is the log of the pre-processed intensities.\n\nsds = apply(exprs(TCGA_eset)[,1:50],1,sd)\nlibrary(gplots)\nheatmap.2((exprs(TCGA_eset)[,1:50])[order(sds,decreasing=TRUE)[1:20],],\n          margins = c(6, 10))\n\n\n\n\n\n\n\n\nTrees (dendrograms) on the top and sides represent the result of hierarchical clustering. The goal is to reorder rows and columns so that similar rows (column) are close to each other. In this case I am using them to facilitate visualization, but this is also a technique to identify patterns in the data or divide them into subgroups. This is a general overview @Garrett2005\nThe heatmap.2 function calls hclust to produce the dendrograms. The procedure is agglomerative —it starts by joining single rows, and proceeds iteratively from the bottom up. The lenth of the branches grows with the distance of the two entities (rows of clusters of rows) being joined. The default agglomeration method is the “complete linkage” method in which clusters are linked based on the similarity of the furthest members. Same for columns.\nBlue lines. Inside the legend: histogram frequencies; inside the heat map, the distance of the line from the center of each color-cell is proportional to the size of the measurement (overkill? depends, people perceive location differently from color so it could help). \nDistribution of location (median) and scale (Interquartile Range, or IQR), by gene and by sample.\n\niqr.g = apply(exprs(TCGA_eset),1,IQR) #\nhist(iqr.g, main =\"IQR by gene\")\n\n\n\n\n\n\n\niqr.s = apply(exprs(TCGA_eset),2,IQR) \nhist(iqr.s, main =\"IQR by sample\")\n\n\n\n\n\n\n\nmed.g = apply(exprs(TCGA_eset),1,median)\nhist(med.g, main =\"median by gene\")\n\n\n\n\n\n\n\nmed.s = apply(exprs(TCGA_eset),2,median)\nhist(med.s, main =\"median by sample\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantile Normlization\n\n\n\nIf quantile normalization was applied by sample, why aren’t all medians and all IQR’s the same in the histograms by sample?\nAt least two reasons: 1) QN was applied at the proble level. Within each study data sere subsequently aggregated first by probeset and then by gene. 2) To (hopefully) increase comparabiity across studies, data where further process with a batch adjustment model that regresses out gene specific effects.\n\n\n\nClustered heatmap of the top 100 most variable genes in the Yoshirara study. The technology is Agilent. @yoshihara2012 describes the preprocessing approach. This set of 40 patients is “Dataset B” in [@yoshihara2012].\n\nsds = apply(exprs(GSE32063_eset),1,sd)\nlibrary(gplots)\nheatmap.2(exprs(GSE32063_eset)[order(sds,decreasing=TRUE)[1:20],])\n\n\n\n\n\n\n\n\n\nDistribution of location (median) and scale (Interquartile Range, or IQR), by gene and by sample.\n\niqr.g = apply(exprs(GSE32063_eset),1,IQR)\nhist(iqr.g, main =\"IQR by gene\")\n\n\n\n\n\n\n\niqr.s = apply(exprs(GSE32063_eset),2,IQR) \nhist(iqr.s, main =\"IQR by sample\")\n\n\n\n\n\n\n\nmed.g = apply(exprs(GSE32063_eset),1,median)\nhist(med.g, main =\"median by gene\")\n\n\n\n\n\n\n\nmed.s = apply(exprs(GSE32063_eset),2,median)\nhist(med.s, main =\"median by sample\")"
  },
  {
    "objectID": "L3-data.html#high-throughput-gene-expression-measurement",
    "href": "L3-data.html#high-throughput-gene-expression-measurement",
    "title": "Lecture 3: Data",
    "section": "",
    "text": "Specimen Acquisition (get the samples, preserve them between the clinic and the lab, isolate the cells of interest etc)\nExtraction / Preparation Protocols (extract RNA from the samples, often do additional preparation to get it ready for analysis (e.g add tags); often convert RNA into complementary DNA, or cDNA; break sequences into tiny fragments to be reassembled later)\nQuantification (run the experiment)\nRaw Data (typically images)\nYour Data (a heavily preprocessed summary attempting to quantify expression at the aggregate level of a “gene”)\n\n\n\n\n\nWe will work with expression data after it has been preprocessed and summarized at the gene label level. We will analyze a lot of data from the Affy platform. Preprocessing is a statistically challenging step. Some of the most important issues for Affymetrix data are discussed by @Owzar2008ccr\nI also highly recommend Katerina Taskova’s Introduction to Microarray Analysis slide deck.\n\n\n\n\n\n\nReading Notes\n\n\n\n\nRMA (slides 13-17) was used to preprocess the data we will use. A high-level understanding is useful. It produces summaries of expression at the level of the probe-set.\nIt is useful to know the difference between a probe (a single 25-nucleotide sequence), a probe-set (a group of probes predicted to appear on the coding sequence of a gene) and a gene (a region of DNA believed to often be the source of information for the production of a particular set of related proteins).\nMultiple probe-sets can map the same gene (for a digression about this see [@stalteri2007bmcb]) To keep things simple and to cross-reference features across technologies we have averaged over these and will use data at the gene level [@ganzfried2013curatedovariandata].\nThink about quantile normalization (QN) when looking at Slide 19. Does QN help? Does it remove the artifact in bad.cel completely? Does it remove the “fog” in NEG10-1?\nWe will cover differential expression later in the course (Slides 23-29). You are welcome to take a peek, but you can skip for now.\nEach of the bullets on Slide 30 embeds its own sources of both noise and systematic biases.\n\n\n\nMultiple probe sets for the same gene in Affy are sometimes designed to capture different isoforms (that is messenger RNAs made with different selection of exons). Because Affy needs to position probes near one end of the gene (long story), the extent to which they can capture different isoforms is not great compared to RNA-seq. But there could certainly be exceptions. Affy also used multiple probe sets to increase the number of probes dedicated to a certain genes, when the gene is important or there is uncertainty about mapping. In these cases averaging actually helps.\nRabbit hole: For those interested in a digression on imaging approaches (not covered at all in the class) including a menagerie of artifacts, see @arteaga-salas2007bb\n\n\n\n\nRNA-seq is the current alternative to hybridization microarrays. There are several RNA-seq datasets in the CuratedOvarianCanceer and CuratedBreastCancer package you will use in this class, but RNA-seq data exploration will be mostly optional. The main statistical lessons for this course can be learned equally well from Affy data. Of course I would not say this about a Bioinformatics class.\nFor those interested in understanding RNA-seq a bit more, I recommend the sections “Overview” and “Alignment and Quantification” from @VandenBerge2019arbds\n@Xu2013bmcb report a head-to-head comparison of Affy and RNA-seq high throughput measurements. RNA-seq generates count data. It is interesting to look at Figure 1 and think about how to interpret the “stripes” in panel B.\nMicroarrays are rarely used for discovery these days. Many of the statistical challenges of biomarker discovery, however, have remained the same. The advantage of using microarrays for this course is there there are far more studies readily available, so certain parts of the course still work a lot better with microarray than RNA-seq."
  },
  {
    "objectID": "L3-data.html#batch-effects",
    "href": "L3-data.html#batch-effects",
    "title": "Lecture 3: Data",
    "section": "",
    "text": "High-throughput biology data are often produced in batches for efficiency or practical restrictions. Differences across how these batches are handled (in any of the bullets in Slide 30 of Katerina Taskova’s Introduction to Microarray Analysis), can drive significant variation across batches, resulting in so-called batch effects.\nCuratedOvarianData has been preprocessed to adjust for batches defined by the study of origin using Combat [@Johnson2006]. Other batch effects may be present.\n@Leek2010nrg wrote a useful overview of batch effects."
  },
  {
    "objectID": "L3-data.html#the-curatedovariandata-package",
    "href": "L3-data.html#the-curatedovariandata-package",
    "title": "Lecture 3: Data",
    "section": "",
    "text": "Comprehensive review of predictors and datasets for signature validation @Waldron2014\n\n\n\n\n\n\n\nScheme of preprocessing pipeline for the CuratedOvarianData Package\n\n\nDetailed description of dataset @ganzfried2013curatedovariandata\n\n\n\n\n\n\n\nThis heatmap visualizes for each curated clinical characteristic (rows) the availability in each data set (columns). Red indicates that the corresponding characteristic is available for at least one sample in the data set. See @ganzfried2013curatedovariandata for further details.\n\n\nIt may seem disappointing that there are only two clinical annotations that all of these datasets have. When we originally created the dataset we recontacted all the groups that originally generated the data to try to fill as many of the gaps as possible. Unfortunately some of the clinical data may not have been collected, or may not be easy to share due to privacy concerns or investigators’ reluctance. Since we compiled this data, the field has moved towards larger coordinated efforts across multiple institutions, which have had better outcomes in terms of completeness and homogeneity of phenotypes. An example is PCAWG but heterogeneity and missingness of labels remain important issues in health data.\n\n\n\n\nWe next load the CuratedOvarianData package and two datasets contained within. For now we will only consider the datasets TCGA_eset and GSE32063_eset. To check important characteristics of each of the studies, just enter the study ID (for example GSE32063) in the Gene Expression Omnibus query page\n\nlibrary(curatedOvarianData)\n# data(package=\"curatedOvarianData\")\n# Above line would lists all datasets available within the package.\ndata(TCGA_eset)\ndata(GSE32063_eset)\n\n\n\nhead(exprs(TCGA_eset)[1:6,1:6])\n\n      TCGA.20.0987 TCGA.23.1031 TCGA.24.0979 TCGA.23.1117 TCGA.23.1021\nA1CF      2.923522     3.052169     2.846371     3.002209     3.062993\nA2M      10.353008    11.635772     7.954542     9.971500     8.971334\nA4GNT     3.321405     3.666463     3.258038     3.596212     3.388706\nAAAS      4.608010     5.142133     5.025422     5.139928     5.256831\nAACS      7.279213     7.048869     7.750161     6.206031     7.835422\nAADAC     4.605331     5.775611     3.846412     4.468379     4.415817\n      TCGA.04.1337\nA1CF      2.974734\nA2M       9.042876\nA4GNT     3.269979\nAAAS      4.667723\nAACS      6.763047\nAADAC     4.159804\n\nhead(exprs(GSE32063_eset)[1:6,1:6])\n\n          GSM795125 GSM795126 GSM795127  GSM795128 GSM795129  GSM795130\nA1BG     -6.3146850 -4.566943 -6.998341 -5.6383615 -6.780428 -5.1891665\nA1BG-AS1 -3.6973042 -2.848625 -2.519599 -3.4870706 -3.043527 -2.6745200\nA1CF     -5.5054617 -3.861939 -4.552987 -4.5571017 -4.753347 -0.3129711\nA2M       3.2657738  3.373391  5.217385  4.3027153  3.599464  3.2226200\nA2ML1    -0.8923645 -0.733676 -1.512566 -0.7562313 -1.414893 -0.8385077\nA3GALT2  -5.0457100 -4.183009 -4.553020 -4.2992754 -4.304550 -4.4622746\n\n\n\n\n\n\nClustered heatmap of the top 100 most variable genes in the first 50 samples in TCGA. The expression scale is the log of the pre-processed intensities.\n\nsds = apply(exprs(TCGA_eset)[,1:50],1,sd)\nlibrary(gplots)\nheatmap.2((exprs(TCGA_eset)[,1:50])[order(sds,decreasing=TRUE)[1:20],],\n          margins = c(6, 10))\n\n\n\n\n\n\n\n\nTrees (dendrograms) on the top and sides represent the result of hierarchical clustering. The goal is to reorder rows and columns so that similar rows (column) are close to each other. In this case I am using them to facilitate visualization, but this is also a technique to identify patterns in the data or divide them into subgroups. This is a general overview @Garrett2005\nThe heatmap.2 function calls hclust to produce the dendrograms. The procedure is agglomerative —it starts by joining single rows, and proceeds iteratively from the bottom up. The lenth of the branches grows with the distance of the two entities (rows of clusters of rows) being joined. The default agglomeration method is the “complete linkage” method in which clusters are linked based on the similarity of the furthest members. Same for columns.\nBlue lines. Inside the legend: histogram frequencies; inside the heat map, the distance of the line from the center of each color-cell is proportional to the size of the measurement (overkill? depends, people perceive location differently from color so it could help). \nDistribution of location (median) and scale (Interquartile Range, or IQR), by gene and by sample.\n\niqr.g = apply(exprs(TCGA_eset),1,IQR) #\nhist(iqr.g, main =\"IQR by gene\")\n\n\n\n\n\n\n\niqr.s = apply(exprs(TCGA_eset),2,IQR) \nhist(iqr.s, main =\"IQR by sample\")\n\n\n\n\n\n\n\nmed.g = apply(exprs(TCGA_eset),1,median)\nhist(med.g, main =\"median by gene\")\n\n\n\n\n\n\n\nmed.s = apply(exprs(TCGA_eset),2,median)\nhist(med.s, main =\"median by sample\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantile Normlization\n\n\n\nIf quantile normalization was applied by sample, why aren’t all medians and all IQR’s the same in the histograms by sample?\nAt least two reasons: 1) QN was applied at the proble level. Within each study data sere subsequently aggregated first by probeset and then by gene. 2) To (hopefully) increase comparabiity across studies, data where further process with a batch adjustment model that regresses out gene specific effects.\n\n\n\nClustered heatmap of the top 100 most variable genes in the Yoshirara study. The technology is Agilent. @yoshihara2012 describes the preprocessing approach. This set of 40 patients is “Dataset B” in [@yoshihara2012].\n\nsds = apply(exprs(GSE32063_eset),1,sd)\nlibrary(gplots)\nheatmap.2(exprs(GSE32063_eset)[order(sds,decreasing=TRUE)[1:20],])\n\n\n\n\n\n\n\n\n\nDistribution of location (median) and scale (Interquartile Range, or IQR), by gene and by sample.\n\niqr.g = apply(exprs(GSE32063_eset),1,IQR)\nhist(iqr.g, main =\"IQR by gene\")\n\n\n\n\n\n\n\niqr.s = apply(exprs(GSE32063_eset),2,IQR) \nhist(iqr.s, main =\"IQR by sample\")\n\n\n\n\n\n\n\nmed.g = apply(exprs(GSE32063_eset),1,median)\nhist(med.g, main =\"median by gene\")\n\n\n\n\n\n\n\nmed.s = apply(exprs(GSE32063_eset),2,median)\nhist(med.s, main =\"median by sample\")"
  },
  {
    "objectID": "L7-mcmc.html#monte-carlo-markov-chains-mcmc",
    "href": "L7-mcmc.html#monte-carlo-markov-chains-mcmc",
    "title": "Lecture 7: Monte Carlo Markov Chains",
    "section": "Monte Carlo Markov Chains (MCMC)",
    "text": "Monte Carlo Markov Chains (MCMC)\n\nIntro\nFrom the previous section, we saw that for the two models we proposed, we are able to find conjugate prior distributions. When paired with the likelihood, these resulted in a posterior distribution that is not only in closed form but also in the same family as the prior, and amenable to some pencil-and-paper analysis. For example marginal distributions and marginal moments are easy to compute. Even in this case, we saw that generating a Monte Carlo sample from the posterior can be a useful shortcut for exploring variability in nonlinear transformation of the parameters such as the PPV or the log odds ratio.\nIn more complex situations, for example when we are dealing with prior knowledge on a parameter that may result in non-conjugate priors, or when dealing with a hierarchical set-up, little progress can be made analytically. We often have the numerator of the posterior in closed form, but cannot evaluate analytically the denominator. In such cases, we can still rely on computational solutions to obtain approximately representative samples of the posterior distribution. With these samples, one can then obtain posterior summaries such as marginal densities, or probabilities of events defined in terms of several parameters, that otherwise would be difficult or impossible.\n\n\n\nGibbs and Metropolis Sampling\nTo motivate, we note that the expectation of any function \\(f\\) of a random variable \\(\\theta\\) with distribution \\(p(\\theta)\\) can be estimated arbitrarily accurately by:\nIn , a Monte Carlo sample from the joint distribution \\(p (\\theta_1,\\theta_2)\\) can be obtained by iteratively sampling \\(p(\\theta_1 | \\theta_2)\\) and \\(p(\\theta_2 | \\theta_1)\\), where these are known distributions, called “full conditional” distributions.\nThis is especially useful when the full conditionals are easy to sample from, but works in general, because full conditionals tend to be far more amenable to decent approximations that their multivariate counterparts.\nWhen the full conditionals are not easily tractable, a useful alternative is the Metropolis sampling algorithm.\nMost Bayesian texts, including “Modeling in Medical Decision Making” on Canvas have chapters on MCMC. A nice monograph is @Gamerman2006.\nI find Chi Feng’s Animations extremely effective to getan intuition for these samplers!"
  },
  {
    "objectID": "L7-mcmc.html#a-simple-parametric-model-for-znf487",
    "href": "L7-mcmc.html#a-simple-parametric-model-for-znf487",
    "title": "Lecture 7: Monte Carlo Markov Chains",
    "section": "A simple parametric model for ZNF487",
    "text": "A simple parametric model for ZNF487\n\nData\nWe now introduce coding for MCMC’s. This week’s section has more example and coding details.\nConsider again the debulking variable with optimal as \\(1\\) for the ZNF487 gene. We first look at the dot plots in both the log scale and the original intensity scale (obtined by exponentiating the value in the database).\n\npar(mfrow = c(1,2))\nplot(XX,YY,xlab=c(\"Log Expression of\",GeneName),cex=2)\nplot(exp(XX),YY,xlab=c(\"Expression of\",GeneName),cex=2)\n\n\n\n\nPlots for ZNF487\n\n\n\n\n\n\n\nLikelihood and Prior\nTo illustrate, we model the two class conditional distributions of expression using gamma densities. The model specification is in this code chunk, which we will feed to JAGS via rJAGS below. JAGS is persnickety about paramter inputs. Check section 9.2 of the JAGS manual.\n\nGamModel =\"model {\n    # Likelihood:\n    for( i in 1 : n0 ) { x0[i] ~ dgamma(ss0,rr0) } \n    for( j in 1 : n1 ) { x1[j] ~ dgamma(ss1,rr1) }\n    # Prior:\n    ss0 ~ dnorm( 0, 1.0E-3)T(0,)\n    rr0 ~ dnorm( 0, 1.0E-3)T(0,)\n    ss1 ~ dnorm( 0, 1.0E-3)T(0,) \n    rr1 ~ dnorm( 0, 1.0E-3)T(0,) \n}\n\"\n\nss0, rr0, ss1 and rr1 are unknown shape and rate parameters. They are by definition positive. The priors for all these are “half normal” obtained by centering a normal at 0 and restricting is to have positive values. JAGS expect the normal scale to be specified as “precision”, formally defined as the reciprocal of the variance. A small precision will give you a flat half normal, but one that will eventially die out. You can set the precision so that the range of the prior stretches across all a priori plausible values, and only rule out values that are clearly implausible. Let’s take a look.\n\nhist(abs(rnorm(1600,0,sd=sqrt(1/.001))),main=\"\",xlab=\"parameter (rr or ss)\",nclass=50)\n\n\n\n\nIllustration of the Effect of Precision on Half Normal Prior\n\n\n\n\n\n\n\nrJAGS\nWe use RJags to run this. We first import the three packages we wish to utilize for RJags to work:\n\nlibrary(coda)\nlibrary(rjags)\nlibrary(R2jags)\n\nWe run four short chains, to illustrate the initial aches and pains of convergence, then run 4 longer chains with 10000 iterations, the first 1000 of which (“burn-in”) are discarded via n.adapt.\n\nGamModelJ = jags.model(textConnection(GamModel),\n                   data = list( x0 = exp(XX[YY==0]), \n                                n0 = sum(YY==0), \n                                x1 = exp(XX[YY==1]), \n                                n1 = sum(YY==1)),\n                   n.chains = 4,\n                   n.adapt = 1)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 40\n   Unobserved stochastic nodes: 4\n   Total graph size: 48\n\nInitializing model\n\n\nWarning in jags.model(textConnection(GamModel), data = list(x0 = exp(XX[YY == :\nAdaptation incomplete\n\nset.seed(117)\nmcmc.out.short = coda.samples(GamModelJ,c(\"rr0\",\"rr1\",\"ss0\",\"ss1\"),n.iter = 90,thin=1)\n\nNOTE: Stopping adaptation\n\nGamModelJ = jags.model(textConnection(GamModel),\n                   data = list( x0 = exp(XX[YY==0]), \n                                n0 = sum(YY==0), \n                                x1 = exp(XX[YY==1]), \n                                n1 = sum(YY==1)),\n                   n.chains = 4,\n                   n.adapt = 1000)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 40\n   Unobserved stochastic nodes: 4\n   Total graph size: 48\n\nInitializing model\n\nmcmc.out = coda.samples(GamModelJ,c(\"rr0\",\"rr1\",\"ss0\",\"ss1\"),n.iter = 9000,thin=100)\n\n\n\n\nTrace Plots\nIt is useful to look at trace plot of samples from the posterior. Multiple independent chains allow us to gauge convergence (more formal approaches are discussed in Section). We look for stable and overlapping traces. Chains in group 0 are closer and more stable than in group 1. In Group 1, between iterations 50 and 70 both parameters take a detour upwards, illustrating the correlation, and how correlated runs can visit region of relatively low probability for too long.\n\ncex &lt;- 0.7\npar(cex.lab=cex, cex.axis=cex, cex.main=0.85)\npar(mgp=c(1.5, 0.4, 0))\npar(oma=c(0,0,0,0))\npar(mar=rep(1.2, 4))\nplot(mcmc.out.short,smooth=F,auto.layout=T)\n\n\n\n\nMCMC Plots\n\n\n\n\n\nThe same diagnostic on the longer chain, after removing the burn-in, looks fine.\n\ncex &lt;- 0.7\npar(cex.lab=cex, cex.axis=cex, cex.main=0.85)\npar(mgp=c(1.5, 0.4, 0))\npar(oma=c(0,0,0,0))\npar(mar=rep(1.2, 4))\nplot(mcmc.out,smooth=F,auto.layout=T)\n\n\n\n\nMCMC Trace\n\n\n\n\nNote how the final marginal densities do not differ much from those of the first 90 iterations. So why go for the longer chain? When chains show questionable convergence, there is a bigger change that some entirely unexplored region of high posterior may exist. Converged chains don’t rule that out (we could have hit the same local mode four times!) but make it less likely. Also, other features like tail probaiblities or probabilities of rare events require better convergence and bigger sample sizes.\n\n\n\nPosterior Summaries of Class Conditional Densities and Their Functions\nWe next extract the the MCMC chain for each parameters.\n\nrr0 = as.vector(mcmc.out[[1]][,\"rr0\"]) # rate in dgamma R function\nrr1 = as.vector(mcmc.out[[1]][,\"rr1\"])\nss0 = as.vector(mcmc.out[[1]][,\"ss0\"]) # shape in dgamma R function (not to be confused with scale)\nss1 = as.vector(mcmc.out[[1]][,\"ss1\"])\n\nEach value of the chain gives us a model-based estimate of the class-conditional distributions. A straightforward summary is to average these densities point-wise over a grid.\n\n\nxx = seq(0,1,.01)\nMM = length(rr0)\nff0 = ff1 = matrix(NA,length(xx),MM)\nfor (mm in 1:MM) {\n  ff0[,mm] = dgamma(xx,ss0[mm],rr0[mm])\n  ff1[,mm] = dgamma(xx,ss1[mm],rr1[mm])\n}\nff0.postmean = apply(ff0,1,mean)\nff1.postmean = apply(ff1,1,mean)\n\n\nplot(xx,ff0.postmean,xlab=\"Expression\",ylab=\"Conditional Density\",type=\"l\",lwd=2); lines(xx,ff1.postmean,lwd=2,col=3); abline(0,0); rug(XXe[YY==0],lwd=2); rug(XXe[YY==1],col=3,lwd=2)\n\n\n\n\nConditional Density Plot\n\n\n\n\nWe can use these directly to visualize the log likelihood ratio and PPV. A better estimator can be constructed by calculating the log likelihood ration pointwise and averaging the results.\n\nllr.postmean = apply( log(ff1/ff0), 1, mean )\nplot(xx,llr.postmean,xlab=\"Expression\",ylab=\"Log Likelihood Ratio\",type=\"l\",lwd=2); abline(0,0)\n\n\n\n\nLog Likelihood Ratio\n\n\n\n\n\npi = .1\nppv.postmean = apply ( 1 / ( 1 + ((1-pi)/pi) * (ff0/ff1) ), 1, mean)\nplot(log(xx), ppv.postmean, xlab=\"Log Expression\",ylab=\"Probability of Optimal Debulking\",type=\"l\",ylim=c(0,1))\n\n\n\n\nPositive Predictive Value\n\n\n\n\n\n\nPosterior Uncertianty in Benefit Curves\nImportantly, we can also analyze the variability. We focus here on visualizing variability of the benefit curve. We evaluate the benefit curve at each draw of the parameter values, and graph a small subset.\n\nbenefit.uncertain = function(pp,\n                             minX = 0,\n                             maxX = 1.2,\n                   rrr0=rr0,\n                   rrr1=rr1,\n                   sss0=ss0,\n                   sss1=ss1,\n                   u00 = 3, \n                   u11 = 20, \n                   u10 = 2, \n                   u01 = 15,\n                   nn = 10\n                   ){\n  subs.chain = sample(1:length(rrr0),nn)\n                   rrr0=rr0[subs.chain]\n                   rrr1=rr1[subs.chain]\n                   sss0=ss0[subs.chain]\n                   sss1=ss1[subs.chain]\nuD2yes = pp*u11 + (1-pp)*u10\nuD2no = pp*u01 + (1-pp)*u00\nuNoMarker = max(uD2yes,uD2no)\ntau = seq(minX,maxX,by= ( maxX-minX )/100 )\nF0 = F1 = matrix(NA,length(tau),length(rrr0))\nfor (jj in 1:length(tau)){\n  F1[jj,] = pgamma(tau[jj],sss1,rrr1)\n  F0[jj,] = pgamma(tau[jj],sss0,rrr0)\n  }\nuMarker = pp * (1-F1) * u11 + (1-pp) * (1-F0)* u10 + pp * F1 * u01 +  (1-pp) * F0 * u00\nbenefitMarker = uMarker - uNoMarker\nreturn(list(tau=tau,benefitMarker=benefitMarker,\n            uD2yes=uD2yes,uD2no=uD2no))\n}\n\n\nset.seed(314)\nBU = benefit.uncertain(1/6)\nplot(log(BU$tau),BU$benefitMarker[,1],\n     type=\"l\",lwd=2,ylim=c(-1,.75),\n     ylab=\"Benefit of Biomarker\",xlab=\"tau\")\nfor(ll in 1:ncol(BU$benefitMarker)) lines(log(BU$tau),BU$benefitMarker[,ll])\nabline(0,0)\n\n\n\n\nBenefit of Biomarker against tau, with uncertainty. Prevalence .2\n\n\n\n\n\n\nBU = benefit.uncertain(.25)\nplot(log(BU$tau),BU$benefitMarker[,1],\n     type=\"l\",lwd=2,ylim=c(-1,.5),\n     ylab=\"Benefit of Biomarker\",xlab=\"tau\")\nfor(ll in 2:ncol(BU$benefitMarker)) lines(log(BU$tau),BU$benefitMarker[,ll])\nabline(0,0)\n\n\n\n\nBenefit of Biomarker against tau, with uncertainty. Prevalence .4"
  },
  {
    "objectID": "L7-mcmc.html#references",
    "href": "L7-mcmc.html#references",
    "title": "Lecture 7: Monte Carlo Markov Chains",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "L6-bayes.html#bayesian-models",
    "href": "L6-bayes.html#bayesian-models",
    "title": "Lecture 6: Bayesian Modeling",
    "section": "Bayesian Models",
    "text": "Bayesian Models\nSo far we focused on statistical summaries, but have paid little attention to uncertainty about them. When we say that the PPV at a level of -1 for ZNF487 expression is .2, how sure are we? When we look at the comparison between the PR curves or benefit curves of two biomarkers, how reliably can we say that one is above the other? We are going to approach these questions using Bayesian models. Both “Bayesian” and “model” are very loaded words. We could go w/out models at all and rely on resampling techniques like the bootstrap to generate uncertainty statements. Or we could specify models, but use non-Bayesian methods, such as maximum likelihood, for our uncertainty. There are pros and cons of each of these choices. Models are powerful and can amplify the value of your data if you get them approximately right (a nontrivial task). Bayes is powerful, general and simple in concept, but a bit high maintenance compared to its frequentist counterparts. There are cool model-free or model-robust Bayesian techniques, but we will only scratch the surface there.\nIf you are completely new to Bayesian learning, here is a gentle introduction with a cute animation and here is the Bayesrulesbook chapter on the Beta-Binomial case. You will not find it hard to scout material at the right level for you online. “Modeling in Medical Decision Making” has relevant chapters. I posted a copy on the canvas files. A great reference is @Hoff2009 A fun book, though perhaps way more than you signed up for, is [@mcelreath2020]. @sarma2020chi offers a brief review on how to think about, and specify, prior distributions, often a sticky points for Bayesian analysis.\nBayesian learning uses probability to represent both variation / randomness in the real world, and incomplete knowledge. As a result, probabilities provide a selef contained system that formally represents knowledge in the face of uncertainty and can be used to update knowledge when new information is introduced. In general, we typically wish to understand characteristics that govern a population, from which we normally have a subset of data representing it. Population quantities capturing these characteristics are usually represented in terms of a parameter \\(\\theta\\). The subset of data is represented through variables \\(x,y\\).\n\n\nBayes Rule\nThe following equation represents the basis of Bayesian modeling.\n\\[\\begin{equation}\n\\begin{split}\nP(\\theta | x,y) &= \\frac{P(x,y | \\theta) P(\\theta)}{\\int_\\theta P(x,y | \\theta) P(\\theta)d\\theta} = \\frac{P(x,y | \\theta) P(\\theta)}{P(x,y)}\\propto P(x,y | \\theta) P(\\theta)\n\\end{split}\n\\end{equation}\\]\nLikelihood: \\(P(x,y | \\theta)\\)\nPrior: \\(P(\\theta)\\)\nPosterior: \\(P(\\theta | x,y)\\)"
  },
  {
    "objectID": "L6-bayes.html#inference-on-sensitivity-and-specificity",
    "href": "L6-bayes.html#inference-on-sensitivity-and-specificity",
    "title": "Lecture 6: Bayesian Modeling",
    "section": "Inference on Sensitivity and Specificity",
    "text": "Inference on Sensitivity and Specificity\n\nLikelihood Case Control Design\nWe now focus, to begin, on a case-control example to evaluate a dichotomous biomarker. In this example, we assume that we know whether patients have a disease or not, which we represent with \\(y=1\\) for a disease case, and \\(y=0\\) for a non-disease case. Furthermore, we know the biomarker level of each patient, which is represented as \\(x=1\\) if they have, say, a high level of expression, and a \\(x=0\\) for a low level of expression. The following \\(2 \\times 2\\) table represents such a scenario.\nHere \\(m_0\\) and \\(m_1\\) represent the number of patients with no disease and a high biomarker, and the number of patients with disease and a high biomarker, respectively. The total counts for the margins for \\(y\\) (\\(n_0\\) and \\(n_1\\)) are fixed.\nIn such a set-up, the parameters of interest would usually then be the , denoted as\n\\[\n\\beta = p(x=1\\mid y=1)\n\\]\nand ,\n\\[\n\\alpha = p(x=0|y=0)\n\\]\nThe likelihood for learning about sensitivity and specificity from the observed data would then be,\n\\[\nL_{CC} = \\binom{n_1}{m_1} \\beta^{m_1}\\left(1-\\beta\\right)^{n_1-m_1}\\binom{n_0}{m_0}\\left(1-\\alpha\\right)^{m_0}\\alpha^{n_0-m_0}\n\\] \n\n\nLikelihood for Population-Based Design\nWe note that such a construct assumes ahead of time that the total number of disease and disease-free individuals are fixed. This may be too restrictive in some settings. Therefore, we may alternatively fix the sample size instead, so that \\(n_0\\) and \\(n_1\\) may vary as long as their sum is equal to a fixed \\(n = n_0 + n_1\\). Such a model, which we refer to as “population based”, would allow more flexibility and implies the following table.\nThe parameters associated with this table include the sensitivity and prevalence, \\(\\alpha, \\beta\\) from before, in addition to the , represented as,\n\\[\n\\pi = p(y=1)\n\\]\nThe table may be rewritten in terms of these three parameters as a table of proportions, given by\nThen the associated likelihood function can be represented in terms of the case control likelihood as,\n\\[\nL_{PB} = \\binom{n_0+n_1}{n_1}\\pi^{n_1}\\left(1-\\pi\\right)^{n_0}\\cdot L_{CC}\n\\]\nThis model allows for the observation of a different number of disease and no disease cases conditional on a fixed total sample size. The prevalence can then be estimated under such a model, which we note takes a binomial mass function form through the likelihood above.\n\n\nPosterior Inference\nThe likelihood function we have specified under both models can then be incorporated into a Bayesian model. Specifically, we may conduct Bayesian inference on the parameters of interest. Under the case control example, one idea may be to specify a uniform prior on both the parameters for specificity and sensitivity, \\(\\alpha, \\beta\\). The prior is given as,\n\\[\nP(\\alpha,\\beta) = 1, \\ \\ \\text{for} \\ \\ \\alpha \\in [0,1], \\beta \\in [0,1]\n\\]\nwhich when combined with the likelihood \\(L_{CC}\\) yields the posterior of the form,\n\\[\nP(\\alpha,\\beta|m_0,m_1) \\propto\n1 \\times \\binom{n_1}{m_1} \\beta^{m_1} ( 1-\\beta) ^{n_1-m_1}\n\\binom{n_0}{m_0} (1-\\alpha)^{m_0} \\alpha ^{n_0-m_0}\n\\] The uniform prior places equal mass on the possible support for \\(\\alpha,\\beta\\). One can recognize that the kernel of the posterior is consistent with that of a Beta distribution and therefore the normalizing constants can be easily derived. If instead we had prior information regarding \\(\\alpha,\\beta\\), we may instead model them each as a Beta distribution. Such a prior will jointly be,\n\\[\nP(\\alpha,\\beta) =\\frac{\\Gamma(b_0+b_1)}{\\Gamma(b_1)\\Gamma(b_0)}\\beta^{b_1-1}(1-\\beta)^{b_0-1}\\frac{\\Gamma(a_0+a_1)}{\\Gamma(a_1)\\Gamma(a_0)}(1-\\alpha)^{a_1-1}\\alpha^{a_0-1}\n\\]\nwhich when combined with the likelihood \\(L_{CC}\\) will result in the posterior form,\n\\[\nP(\\alpha,\\beta|m_0,m_1) \\propto \\beta^{m_1+b_1-1} ( 1-\\beta) ^{n_1-m_1 + b_0-1}(1-\\alpha)^{m_0 + a_1-1} \\alpha ^{n_0-m_0+a_0-1}\n\\]\nFor the population based set-up, where we only fixed the total number of sample cases, we may put Beta priors on each of the three parameters of interest, \\(\\alpha, \\beta, \\pi\\). The prior will then be with the form,\n\\[\\begin{equation}\n\\begin{split}\nP(\\alpha,\\beta,\\pi) & = \\frac{\\Gamma(p_0+p_1)}{\\Gamma(p_1)\\Gamma(p_0)}\\pi^{p_1-1}(1-\\pi)^{p_0-1}\\\n\\times \\\\\n&  \\frac{\\Gamma(b_0+b_1)}{\\Gamma(b_1)\\Gamma(b_0)}\\beta^{b_1-1}(1-\\beta)^{b_0-1}\\frac{\\Gamma(a_0+a_1)}{\\Gamma(a_1)\\Gamma(a_0)}(1-\\alpha)^{a_1-1}\\alpha^{a_0-1}\n\\end{split}\n\\end{equation}\\]\\end{equation}\\end{equation}\\end{equation}\\end{equation}\\end{equation}\nwhich leads to a posterior of the form,\n\\[\\begin{equation}\n\\begin{split}\nP(\\alpha,\\beta, \\pi|m_0,m_1) & \\propto \\pi^{n_1+p_1-1} ( 1-\\pi) ^{n_0+p_0-1} \\\\\n& \\beta^{m_1+b_1-1} ( 1-\\beta) ^{n_1-m_1 + b_0-1}(1-\\alpha)^{m_0 + a_1-1} \\alpha ^{n_0-m_0+a_0-1}\n\\end{split}\n\\end{equation}\\]\n\n\n\nPrediction of Future Observations\nNow suppose that we wanted to predict a future outcome \\(y^*\\) for a subject with a biomarker level of \\(x^*\\). Then, the is given by,\n\\[\\begin{equation}\n\\begin{split}\nP(y^*|x^*) &= \\int_{\\theta} P(y^* | x^*, \\theta) P(\\theta)d\\theta \\\\\n= \\int_{\\theta} \\dfrac{P(y^*,x^*| \\theta)}{P(x^*| \\theta)} P(\\theta)d\\theta\n\\end{split}\n\\end{equation}\\]\nThe prior predictive may be thought of as the data marginalized over the prior distribution, or the predictied value of a new data point before observing the actual sample itself. Related to this is the , which is interpreted as the predicted value of a new data point after observing the sample data. The posterior predictive is given by,\n\\[\nP(y^*|x^*, y, x) =\\int_{\\theta} P(y^* | x^*, \\theta) P(\\theta|y, x)d\\theta\n\\]"
  },
  {
    "objectID": "L6-bayes.html#likelihood-principle",
    "href": "L6-bayes.html#likelihood-principle",
    "title": "Lecture 6: Bayesian Modeling",
    "section": "Likelihood Principle",
    "text": "Likelihood Principle\nRelated to the above is the .\n\nFor example, two experiments to assess a proportion \\(\\theta\\)\nWe can illustrate the above principle using an example. Using the two experiments on the previous page, we would like to evaluate\nDifferent sampling models may result in different p-values:\n\npbinom(3, 12, 0.5)\n\n[1] 0.07299805\n\n1-pnbinom(8, 3, 0.5)\n\n[1] 0.03271484\n\n\n@lavine2020nams Has important insight about this if you are interested. His brief and enlightening paper begins by saying: “A fundamental idea in statistics and data science is that statistical procedures are judged by criteria such as misclassification rates, p-values, or convergence that measure how the procedure performs when applied to many possible data sets. But such measures gloss over quantifying the evidence in a particular data set. We show that assessing a procedure and assessing evidence are distinct. The main distinction is that procedures are assessed unconditionally, i.e., by averaging over many data sets, while evidence must be assessed conditionally by considering only the data at hand.”"
  },
  {
    "objectID": "L6-bayes.html#monte-carlo-explorations-of-posterior-distributions",
    "href": "L6-bayes.html#monte-carlo-explorations-of-posterior-distributions",
    "title": "Lecture 6: Bayesian Modeling",
    "section": "Monte Carlo Explorations of Posterior Distributions",
    "text": "Monte Carlo Explorations of Posterior Distributions\nWe now re-examine the case control scenario with a uniform prior and how it can be implemented in R. We first assume that \\(m_0 = 1, n_0 = 10, m_1 = 7\\) and \\(n_1 = 10\\).\n\nx1 = 7\nn1 = 10\nx0 = 1\nn0 = 10\n\nThen we conduct \\(100,000\\) draws from the posterior distributions of \\(\\alpha, \\beta\\) and \\(\\pi\\), under a uniform prior.\n\nMM = 100000 # monte carlo draws\na0 = b0 = a1 = b1 = p0 = p1 = 1 # prior hyperparameters (uniform)\nbeta = rbeta(MM,x1+b1,n1-x1+b0)\nalpha = rbeta(MM,n0-x0+b0,x0+b1)\n\nIn this case the posterior distribution is available in closed form, so many of the quantities we are interested in are available analytically, or via well-worn and accurate numerical approximations such as the Incomplete Beta function. Even here it is far more straightforward to explore properties of the posteior distribution by generating a sample. For example, it is trivial to derive distributions of arbitrary functions of multiple parameters, which would otherwise normally require some gymnastic around tansformations of variables.\n\n\npar(mfrow = c(1,2))\nhist(beta,nclass=100,xlim=c(0,1), xlab = expression(beta))\nhist(alpha,nclass=100,xlim=c(0,1), xlab = expression(alpha))\n\n\n\n\nMonte Carlo Approximations of the Posterior Distributions of Parameters Alpha and Beta\n\n\n\n\nThe above figures are the histograms approximating the posterior densities for each of the parameters of interest.\n\nWe can also obtain summary statistics by directly looking at the mean and standard deviation of the obtained samples.\n\nmean(alpha)\n\n[1] 0.8329337\n\nsd(alpha)\n\n[1] 0.1035844\n\nmean(beta)\n\n[1] 0.6665761\n\nsd(beta)\n\n[1] 0.1303295\n\n\nWe may also examine the positive distribution of the positive predictive value. This illustrate how easy it is to derive posterior distribution of transformations of the variables. To begin, we fix the prevalence of the population at \\(0.25\\).\n\npi = 0.25\npi.x = (pi*beta)/(pi*beta + (1-pi)*(1-alpha))\nhist(pi.x, nclass = 100, xlim = c(0,1))\n\n\n\n\nPosterior Distribution of the Positive Predictive Value\n\n\n\n\nWe can then obtain a point estimate of the mean of the posterior predictive at a prevalence rate of \\(0.25\\) and the proportion of samples above \\(0.5\\).\n\nmean(pi.x)\n\n[1] 0.6034726\n\nmean(pi.x &gt; 0.5)\n\n[1] 0.7209\n\n\nThe posterior predictive value can be analyzed further. Specifically, we can plot the joint distribution of the posterior predictive value against \\(\\alpha\\) and \\(\\beta\\), made using ggplot2.\n\npar(mfrow = c(1,2), pty = \"s\")\nsmoothScatter(alpha,pi.x)\nsmoothScatter(beta,pi.x)\n\n\n\n\nAppoximate Joint Distribution of the Positive Predictive Value and Alpha or Beta\n\n\n\n\n\nWe may also analyze the sensitivity to a conjugate prior.\n\nb0 = 10; b1 = 40\nbeta.pre = rbeta(MM,b1,b0)\nbeta.post = rbeta(MM,x1+b1,n1-x1+b0) \nplot(density(beta.post),lwd=2,xlab=\"BETA\",main=\"\") \nlines(density(beta.pre),lwd=2,col=3)\n\n\n\n\nPosterior Visualizations with hyperparameters b0 = 10, b1 = 40\n\n\n\n\n\nb0 = 2; b1 = 2\nbeta.pre = rbeta(MM,b1,b0)\nbeta.post = rbeta(MM,x1+b1,n1-x1+b0) \nplot(density(beta.post),lwd=2,xlab=\"BETA\",main=\"\") \nlines(density(beta.pre),lwd=2,col=3)\n\n\n\n\nPosterior Visualizations under b0 = 2, b1 = 2\n\n\n\n\n\nWe will now focus on the population-based example, whereas previously we saw the case-control study.\n\nx1 = 7\nn1 = 10\nx0 = 2\nn0 = 27\n\nThen we conduct \\(100,000\\) draws from the posterior distributions of \\(\\alpha, \\beta\\) and \\(\\pi\\), under a uniform prior.\n\nMM = 100000 # monte carlo draws\na0 = b0 = a1 = b1 = p0 = p1 = 1 # prior hyperparameters (uniform) \nbeta = rbeta(MM,x1+b1,n1-x1+b0)\nalpha = rbeta(MM,n0-x0+b0,x0+b1)\npi = rbeta(MM,n1+p1,n0+p1)\n\n\nhist(alpha,nclass=100,xlim=c(0,1), xlab = expression(alpha))\n\n\n\n\nPosterior Distribution of for Alpha, Beta, and Pi Parameters\n\n\n\nhist(beta,nclass=100,xlim=c(0,1), xlab = expression(beta))\n\n\n\n\nPosterior Distribution of for Alpha, Beta, and Pi Parameters\n\n\n\nhist(pi,nclass=100,xlim=c(0,1), xlab = expression(pi))\n\n\n\n\nPosterior Distribution of for Alpha, Beta, and Pi Parameters\n\n\n\n\n\nWe can now analyze the distribution associated with the positive predictive value under an unknown prevalence rate, in the population based model. We can obtain summary statistics as before,\n\npi.x = (pi*beta)/(pi*beta+(1-pi)*(1-alpha))\nmean(pi.x)\n\n[1] 0.7165021\n\nmean(pi.x&gt;.5)\n\n[1] 0.93288\n\n\nThe histogram is as follows.\n\nhist(pi.x,nclass=100,xlim=c(0,1), xlab = expression(pi))\n\n\n\n\nDistribution of the Posterior Predictive Value\n\n\n\n\nWe can then look at the alternate visualization of the joint distribution under an unknown prevalence rate.\n\npar(mfrow = c(1,3), pty = \"s\")\nsmoothScatter(alpha, pi.x, xlab = expression(alpha))\nsmoothScatter(beta, pi.x, xlab = expression(beta))\nsmoothScatter(pi, pi.x, xlab = expression(pi))\n\n\n\n\nAlternative Joint Distribution of the Positive Predictive Value and Alpha/Beta/Pi\n\n\n\n\n\n\npar(pty=\"s\")\nsmoothScatter(log(beta/(1-alpha)),pi.x)\n\n\n\n\nJoint Density of PPV versus Log Ratio of Beta/(1-Alpha)\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\n\n\nConsider this scenario: a patient you know well is asking for advice on how to process the risk information they are gathering online.\n\nhow do you describe to them in simple words what the PPV probability represents?\nthey also found a Bayesian statement of uncertainty about the relevant PPV (say a posterior IQR). How do you describe the role of the prior in generating this IQR? What questions should they be asking about that prior?"
  },
  {
    "objectID": "L6-bayes.html#references",
    "href": "L6-bayes.html#references",
    "title": "Lecture 6: Bayesian Modeling",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "L4-metrics.html#znf487-and-debulking-in-yoshihara-study-b",
    "href": "L4-metrics.html#znf487-and-debulking-in-yoshihara-study-b",
    "title": "Lecture 4: Basics of Biomarker Evaluation",
    "section": "ZNF487 and debulking in Yoshihara Study B",
    "text": "ZNF487 and debulking in Yoshihara Study B\nWe first focus on the gene ZNF487 contained within the GSE32063_eset dataset. ZNF487 stands for “Zinc Finger Protein 487”. The exprs function allows us to pull out expression-level data, while pData retrieves the phenotype data, which are the clinical characteristics and outcomes of patients. In the next chunk of code, we will consider the debulking variable as our response variable, and the expression data for the ZNF487 gene as our predictor variable, or biomarker.\n\n\n\n\n\n\nDebulking\n\n\n\nThe term debulking captures whether the patient’s surgery was successful in removing the tumor mass (optimal debulking) in contrast to the case where additional tumor cells where thought to be present based on the surgeon’s inspection, but could not be removed (suboptimal debulking).\nA discussion of the clinical relevance of this question is in the introduction of @Riester2014. A useful debulking marker could spare an unnecessary surgery to patients who will not benefit. However, a high degree of reliability would be needed for the decision to forego surgery, as the benefit of a hypotetical successful surgery could be substantial.\n\n\n\nlibrary(curatedOvarianData)\ndata(GSE32063_eset)\ntable(pData(GSE32063_eset)[,\"debulking\"])\n\n\n   optimal suboptimal \n        19         21 \n\n\nWe will further define the debulking variable to be \\(1\\) if optimal, and \\(0\\) if suboptimal. For ZNF487 this results in higher levels of gene expression being generally associated with optimal debulking."
  },
  {
    "objectID": "L4-metrics.html#visualizations-of-biomarker-distribution-conditional-on-outcome",
    "href": "L4-metrics.html#visualizations-of-biomarker-distribution-conditional-on-outcome",
    "title": "Lecture 4: Basics of Biomarker Evaluation",
    "section": "Visualizations of Biomarker Distribution Conditional on Outcome",
    "text": "Visualizations of Biomarker Distribution Conditional on Outcome\n\nDot Plots\nA most basic way to begin visualization is a pair of dot-plots depicting class-conditional distributions of expression. It allows one to visually gauge the overall separation between expression levels corresponding to optimal versus suboptimal debulking status. The plot appears to indicate that larger and more positive expression values of the biomarker are associated with a debulking status of \\(1\\), or optimal.\n\nGeneName = \"ZNF487\"\nXX = exprs(GSE32063_eset)[GeneName,]\nYY = pData(GSE32063_eset)[,\"debulking\"] == \"optimal\"\nplot(XX,YY,xlab=c(\"Log Expression of\",GeneName),\n     ylab=\"Debulking Status\",cex=2)\n\n\n\n\nDotplot for ZNF487\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBefore you go any further pause to think about what you learned from the dot plot about the potential for ZNF487 to serve as a useful biomarker.\nThink about the question in the abstract and in the context of the surgery decision described above.\n\n\n\n\n\nConditional Density Plots\n\nffx = density(XX[YY==FALSE],from=-4,to=0)$x\nff0 = density(XX[YY==FALSE],from=-4,to=0)$y\nff1 = density(XX[YY==TRUE],from=-4,to=0)$y\nplot(ffx,ff0,xlab=c(\"Log Expression\",GeneName),\n     ylab=\"Density\",main = \"\",\n     ylim=c(0,1), col = \"blue\",type=\"l\",lwd=2)\nlines(ffx,ff1, col = \"green\",lwd=2)\nrug(XX[YY==FALSE],ticksize = .05,lwd=2, col = \"blue\")\nrug(XX[YY==TRUE],ticksize = .05,lwd=2, col = \"green\")\n\n\n\n\nDensity Plot for ZNF487 expression\n\n\n\n\nWe can also visualize the data via the empirical density curves of expression for different group by debulking status. The green curve is associated with optimal debulking, and the blue with suboptimal debulking. The density plots above are essentially capturing the same variation as the dot-plot. The marks at the bottom correspond to the dotplots points. The density plot provides a different view of the overall variation, particularly in the area of overlap. Generally, multiple visualizations of the same data may assist in better understanding properties of the data.\nWith small sample sizes this visualization will be very sensitive to the tuning parameters of the density estimate (try the “adjust” input which controls the smoothness of the curve). That said if you have a decent guess about the smoothness of the density, you can use the estimated curves to get various types of useful probabilistic predictions and estimates. Some are coming next.\n\n\n\nPositive Predictive Value Curves\nThe previous sets of plots start to indicate that the ZNF487 biomarker may be informative for the purpose of predicting debulking status. Clinically, a biomarker may be used to classify a new patient after having measured her specific level. We are then interested in understanding the or ppv associated with the measured expression, that is the conditional probability of the label given the observed biomarker level. Bayes’ rule allows us to calculate this conditional (or personalized) probability if we know the frequency of optimally debulkable tumors in a population of reference (prevalence) of which the patient in question is a random representative.\nThe expression measurements we used here are obtained from a fresh frozen tumor sample taken at the time of surgery. If we discovered a usefl biomarker, we would also try to measure it differently, for example based on a less invasive procedure such as a biopsy (wich uses a needle to remove a small section of the tumor). To think about the utility of a marker, imagine it is available before the surgery is performed.\n\nprev = .1\nppv = prev * ff1 / ( prev * ff1 + (1-prev) * ff0)\nplot(ffx,ppv,ylim=c(0,1),\n     xlab=c(\"Log Expression\",GeneName),\n     ylab=\"Probability of optimal debulking\",type = \"l\",lwd=2)\nprev = .2\nppv2 = prev * ff1 / ( prev * ff1 + (1-prev) * ff0) # BAYES RULE\nlines(ffx,ppv2,lty=\"dotted\")\n\n\n\n\nPPV Plot for ZNF487 expression\n\n\n\n\nThe code above computes ppv and graphs it with prevalence set at prev = .1 and \\(.2\\). The dotted line corresponds to a prevalence of \\(.2\\).\n\n\n\n\n\n\n\nDiscussion Points:\n\n\n\n\nWhich shape do you wish a ppv curve to have for a predictive biomarker to be useful?\nThe Yoshihara study B includes about the same number of optimal and suboptimal cases. Why would we be interested in evaluating PPV at prevalences of 10 and 20 percent?\n(related to 2.) Yoshihara et al describe the combined collection of studies A and B by saying “patients who were diagnosed with advanced stage high-grade serous ovarian cancer between July 1997 and June 2010 were included in this study”. Below is breakdown of optimal and suboptimal for study A. Comment.\n\n\n\n\nlibrary(curatedOvarianData)\ndata(GSE32062.GPL6480_eset)\ntable(pData(GSE32062.GPL6480_eset)[,\"debulking\"])\n\n\n   optimal suboptimal \n       103        157 \n\n\n\n\n\n(log) Likelihood Ratio Curve\nThe ppv depends on the empirical densities of the biomarkers only through their ratio. This ratio corresponds to the likelihood ratio when using Bayes’ rule. Higher values of the ZNF487 biomarker results in a higher ratio which in turn indicates a higher probability of optimal debulking. The next plot is the empirical log-likelihood ratio of the optimal vs. suboptimal debulking outcomes, as a function of the gene expression level.\n\nff0 = density(XX[YY==FALSE],from=-4,to=0)$y\nff1 = density(XX[YY==TRUE],from=-4,to=0)$y\nffx = density(XX[YY==FALSE],from=-4,to=0)$x\nplot(ffx,log(ff1/ff0),xlab=paste(\"Log Expression\",GeneName),ylab=\"Log Density Ratio\",\n     type = \"l\",lwd=2)\nabline(0,0)\n\n\n\n\nLog-likelihood Ratio for ZNF487 expression"
  },
  {
    "objectID": "L4-metrics.html#threshold-based-classification",
    "href": "L4-metrics.html#threshold-based-classification",
    "title": "Lecture 4: Basics of Biomarker Evaluation",
    "section": "Threshold-based Classification",
    "text": "Threshold-based Classification\n\n2x2 tables\nFor this discussion, a classifier is a hard and fast decision rule to separate patients in two groups for the purpose of treatment decisions. The simplest classifier we can construct using this biomarker is to establish a threshold such that patients with expression above the threshold are classified as likely optimal. In keeping with medical terminology we refer to the individuals with the more severe disease, in this case the suboptimally debulked patients, as “positive”. If we were to decide to set threshold at \\(-1\\), the reported confusion matrix associated with such a decision rule would be given by the table below.\n\ntable(XX &lt; -1,YY==0,dnn=list(\"Biomarker Positive\",\"True Positive\"))\n\n                  True Positive\nBiomarker Positive FALSE TRUE\n             FALSE     7    0\n             TRUE     12   21\n\n\nWe observe that all true suboptimal debulking cases were correctly classified. We say that the true positive rate (or sensitivity) is \\(1\\). On the other hand among the true optimal debulking cases, \\(7\\) out of \\(19\\) were correctly predicted. The true negative rate is then \\(7/19\\) corresponding to a specificity of \\(1 - 7/19\\).\n\n\n\n\n\n\nDiscussion Point\n\n\n\nIn which scenarios is is this a good cutoff?\n\n\n\n\n\nVisualizing Properties of Alternative Thresholds\nThere are many valid alternatives for investigating and visualizing the properties of a threshold-based classifier. These include\n\nReceiver Operating Characteristic (ROC) curves, which plots sensitivity against one minus specificity\nPrecision versus Recall plots, which plots positive predictive value against sensitivity\nTotal Operating Characteristic. @pontius2014\nDetection Error Tradeoff @Martin:1997ve.\n\n@saito2015 compares ROC and PR in some detail.\n\n\n\nThe ROC curve\nWe will now motivate and introduce the concept of the ROC Curve. It is useful to begin with cumulative distributions.\n\nplot(ecdf(XX[YY==FALSE]),main=\"\",ylab=\"Empirical CDFs\",col=\"blue\",xlim=range(XX))\nlines(ecdf(XX[YY==TRUE]),col=\"green\")\nabline(v=-1, col = \"red\")\n\n\n\n\nEmpirical CDFs of ZNF487 for Optimal and Suboptimal debulking\n\n\n\n\n\nIn the figure above, the blue curve represents the empirical CDFs of the suboptimal debulking biomarker values, and the green curve the empirical CDFs of the optimal. One can then imagine setting many thresholds across the biomarker expression values (x-axis) and pairing the blue/green CDF values obtained. For example the earlier threshold of \\(-1\\) is also shown. It crosses the blue line at the true positive rate, and the green line at the false negative rate, or one minus the true negative rate.\n\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following object is masked from 'package:BiocGenerics':\n\n    var\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\nplot(roc(YY,XX),lwd=2,col=\"blue\")\n\nSetting levels: control = FALSE, case = TRUE\n\n\nSetting direction: controls &lt; cases\n\n\n\n\n\nEmpirical AUC of ZNF487 Expression for discrimination of Optimal v. Suboptimal\n\n\n\n\n\nThe empirical ROC curve can then be computed by comparing the pairings from many such thresholds. The ROC curve is a 2-D plot with the true positive rate (sensitivity) on the y-axis and the false positive rate (one minus specificity) on the x-axis. It yields the tradeoffs between these two rates for a given cutoff. In other words, each point on the curve represents the true and false positive rates associated with a threshold. The 45 degree line (colored red) of the ROC curve represents the curve one would obtain if the two cumulative distributions were the same. The ROC curve can be used to informally assess the relative merits of alternative cutoffs, as well as the overall separation of the curves. Directly leading from the ROC Curve is the AUC (Area under the Curve). This is a widely used metric for comparing different classification methods. The AUC is represented visually above as the area under the black curve (including the area to the right of the red line).\n\n\n\n\n\n\n\nNote\n\n\n\nThe general rule of thumb is that given a classification method and two biomarkers, the biomarker with the higher AUC under the same method tends to be a better classifier.\nWhat are some limitations of this metric?\n\n\n\nWe can also build a smooth version of the ROC curve, for example by calculating estimates of the class-conditional cumulative distributions from the smooth density plot we derived earlier.\n\nFF0 = cumsum(ff0); FF0 = FF0 / max(FF0)\nFF1 = cumsum(ff1); FF1 = FF1 / max(FF1)\nplot(1-FF0,1-FF1,\n     xlab=c(\"False Positive Rate\",GeneName),\n     ylab=\"True Positive Rate\",\n     type = \"l\",lwd=2)\nabline(0,1)\n\n\n\n\nROC for ZNF487 derived from class-conditional smooth density estimates\n\n\n\n\n\nThe AUC nonparametrically compares the two distributions, and it turns out that testing for whether the ROC significantly deviates from the diagonal line can be done equivalently by the non-parametric rank-sum test, which is implemented below.\n\nwilcox.test(XX[YY==TRUE],XX[YY==FALSE])\n\n\n    Wilcoxon rank sum exact test\n\ndata:  XX[YY == TRUE] and XX[YY == FALSE]\nW = 340, p-value = 6.261e-05\nalternative hypothesis: true location shift is not equal to 0\n\n\nThe null hypothesis is that the biomarker level of a randomly selected sample from the set of optimal cases will have the same chance of being greater than or less than a randomly selected sample from the set of suboptimal cases. The p-value above strongly indicates potential departure from the null.\n\nWhen searching for biomarkers, a statistically significant difference from the diagonal may or may not be associated with a clinical useful biomarker. For example, let us examine the dot-plots of the ANKRD66 gene.\n\nGeneName = \"ANKRD66\"\nXX_ANKRD66 = exprs(GSE32063_eset)[GeneName,]\nYY_ANKRD66 = pData(GSE32063_eset)[,\"debulking\"] == \"optimal\"\nplot(XX_ANKRD66,YY_ANKRD66,\n     xlab=c(\"Log Expression of\",GeneName),cex=2)\n\n\n\n\nDotplot for ANKRD66\n\n\n\n\n\nThe dot-plot gives no visual indication that there is good separation of biomarker expression across the two debulking outcomes. However, the p-value from the rank sum test below for these two outcomes is \\(0.05042\\), which, although not technically significant at the traditional \\(.05\\) threshold, provides at least some indication of a departure from equal distributions. This departure is primarily attributable to the a) two outliers in the suboptimal class and b) an accumulation of points slightly above -4 in the optimal class which has a strong effect on the ranks but happens within a range unlikely to translate into biologically meaningful activity. Two points emerge: differences in ranks do not necessarily translate in clinically useful biomarkers. Lack of overlap in the tails can quickly produce significant Wilcoxon tests.\n\nwilcox.test(XX_ANKRD66[YY_ANKRD66==TRUE],\n            XX_ANKRD66[YY_ANKRD66==FALSE])\n\n\n    Wilcoxon rank sum exact test\n\ndata:  XX_ANKRD66[YY_ANKRD66 == TRUE] and XX_ANKRD66[YY_ANKRD66 == FALSE]\nW = 272, p-value = 0.05042\nalternative hypothesis: true location shift is not equal to 0\n\n\nAn even more important disconnect between statistical significance and clinical utility occurs in larger studies, where biomarker may achieve a rejection of the null as a result of biologically weak differences between the two class conditional distributions.\n\nFinally, we discuss on how the ROC relates to the CDF and the labeling of positive and negative cases. Suppose that large or high values of the biomarker are associated with positive cases. In such a case, the ROC curve is created by plotting the following function:\n\\[\nROC_p = \\{1-F_0(c), 1-F_1(c)\\} \\qquad \\text{for} \\ -\\infty &lt; c &lt; \\infty\n\\]\nwhere \\(F_1(x), F_0(x)\\) are the CDFs of the positive and negative cases, respectively. The ROC plot in such a case is creating by plotting the above pairing across many thresholds \\(c\\). If instead it is the case that large or high values of the biomarker are associated with negative cases, then the ROC curve is created by plotting instead:\n\\[\nROC_n = \\{F_0(c), F_1(c)\\} \\qquad \\text{for} \\ -\\infty &lt; c &lt; \\infty\n\\]\nWe will adopt this convention to avoid any labeling confusions.\nA fun fact is that the vertical distance between the diagonal and the ROC curve adds to Sensitivity + Specificity -1, a quantity called the Youden’s index and sometime used to pick a threshold.\n\n\n\nThe Precision / Recall curve\nThe logic of the Precision recall curve is similar: vary the cutoff and graph two interesting summary of biomarker performance. In this case the summaries are sensitivity and PPV. I find this closer to the relevant clinical question. The formula is\n\\[\nPR_p = \\{ 1-F_1(c), \\pi F_1(c) / [\\pi F_1(c) + (1-\\pi)F_0(c)] \\} \\qquad \\text{for} \\ -\\infty &lt; c &lt; \\infty\n\\] By default, most packages will create PR curves directly from the empirical 2x2 tables generated at various cutoffs, which means that in this formula the prevalence \\(\\pi\\) is set at the study proportion of positive cases. What does this tells us about comparing PR curves across studies?\n\nroc_ZNF487 = roc(YY,XX)\n\nSetting levels: control = FALSE, case = TRUE\n\n\nSetting direction: controls &lt; cases\n\nplot(precision ~ recall,\n     coords(roc_ZNF487, \"all\", ret = c(\"recall\", \"precision\"), transpose = FALSE),\n        type=\"l\")\n\n\n\n\nEmpirical AUC of ZNF487 Expression for discrimination of Optimal v. Suboptimal\n\n\n\n\n\n\n\nThe DET curve\nFor a final digression, the DET curve also visualizes properties of the biomarker by summarizing error rates at many cutoffs. Unlike the ROC, it considers the false negative rate and false positive rates. Rather than starting with a grid of possible cutoffs, one starts with a grid of possible error rates. In one implementation, you pick the same error rate for both false alarms and false negatives. Then you compute the quantiles corresponding to those error rates in the biomarker scale, and standardize them by subtracting the class-conditional mean and dividing by the class-conditional standard deviation. The DET plots the results against each other. If the distributions are the same, the graph is the \\(Y=-X\\) line. Good biomarkers generate lines that lie below.\nI have not seen much use. It seems cool but it does take a bit to get used to it.\n\nDET = function(XX,YY){\n   mm0 = mean(XX[YY==FALSE])\n   sd0 = sqrt(var(XX[YY==FALSE]))\n   mm1 = mean(XX[YY==TRUE])\n   sd1 = sqrt(var(XX[YY==TRUE]))\n   pp = seq(0.01,.99,length.out=128)\n   zz0 = ( quantile(XX[YY==FALSE], probs = 1-pp) - mm0 ) / sd0\n   zz1 = ( quantile(XX[YY==TRUE], probs = pp) - mm1 ) / sd1\n   output = list(zz0=zz0,zz1=zz1)\n   return(output)\n}\nDET_ZNF487 = DET(XX,YY)\nplot(DET_ZNF487$zz0,DET_ZNF487$zz1,\n     xlab=c(\"False Positive Rate Deviate\",GeneName),\n     ylab=\"False Negative Rate Deviate\", type = \"l\",lwd=2)\nabline(1,-1)\n\n\n\n\nDET curve for ZNF487 derived from class-conditional smooth density estimates"
  },
  {
    "objectID": "L4-metrics.html#comparing-znf487-and-igha1",
    "href": "L4-metrics.html#comparing-znf487-and-igha1",
    "title": "Lecture 4: Basics of Biomarker Evaluation",
    "section": "Comparing ZNF487 and IGHA1",
    "text": "Comparing ZNF487 and IGHA1\nIGHA1 is another gene that behaves differently in the optimal vs. suboptimal group. The pattern is a change in both location and scale. The shift is large but there is no “clean” region where only one group is present. Also the directionality is reversed compared to ZNF487 so to make things comparable we will change the sign.\n\nGeneName = \"ZNF585B\"\nXX_ZNF585B = exprs(GSE32063_eset)[GeneName,]\nYY = pData(GSE32063_eset)[,\"debulking\"] == \"optimal\"\nplot(XX_ZNF585B,YY,xlab=c(\"Log Expression of\",GeneName),\n     ylab=\"Debulking Status\",cex=2)\n\n\n\n\nDotplot for ZNF585B\n\n\n\n\n\nPPV comparison\n\nffx = density(XX[YY==FALSE],from=-4,to=0)$x\nff0 = density(XX[YY==FALSE],from=-4,to=0)$y\nff1 = density(XX[YY==TRUE],from=-4,to=0)$y\nprev = .2\nppv_ZNF487 = prev * ff1 / ( prev * ff1 + (1-prev) * ff0)\nplot(ffx,ppv_ZNF487,ylim=c(0,1),col=\"blue\",\n     xlab=c(\"Log Expression\",GeneName),\n     ylab=\"Probability of optimal debulking\",type = \"l\",lwd=2)\nffx = density(XX_ZNF585B[YY==FALSE],from=-4,to=0)$x\nff0 = density(XX_ZNF585B[YY==FALSE],from=-4,to=0)$y\nff1 = density(XX_ZNF585B[YY==TRUE],from=-4,to=0)$y\nppv_ZNF585B = prev * ff1 / ( prev * ff1 + (1-prev) * ff0)\nlines(ffx,ppv_ZNF585B,col=\"orange\",lwd=2)\n\n\n\n\nPPV Plot for ZNF487 and IGHA1 expression\n\n\n\n\nOpen for comments.\n\n\n\nROC comparison\n\nlibrary(pROC)\nplot(roc(YY,XX),lwd=2,col=\"blue\")\n\nSetting levels: control = FALSE, case = TRUE\n\n\nSetting direction: controls &lt; cases\n\nplot(roc(YY,XX_ZNF585B),lwd=2,col=\"orange\",add=TRUE)\n\nSetting levels: control = FALSE, case = TRUE\nSetting direction: controls &lt; cases\n\n\n\n\n\nEmpirical AUC of ZNF487 Expression for discrimination of Optimal v. Suboptimal\n\n\n\n\nOpen for comments.\n\n\n\nPR comparison\n\nplot(precision ~ recall,\n     coords(roc(YY,XX), \"all\", ret = c(\"recall\", \"precision\"), transpose = FALSE),\n        type=\"l\",col=\"blue\")\n\nSetting levels: control = FALSE, case = TRUE\n\n\nSetting direction: controls &lt; cases\n\n\nSetting levels: control = FALSE, case = TRUE\n\n\nSetting direction: controls &lt; cases\n\nlines(precision ~ recall,\n     coords(roc(YY,XX_ZNF585B), \"all\", ret = c(\"recall\", \"precision\"), transpose = FALSE),\n        type=\"l\",col=\"orange\")\n\nSetting levels: control = FALSE, case = TRUE\nSetting direction: controls &lt; cases\n\n\nSetting levels: control = FALSE, case = TRUE\n\n\nSetting direction: controls &lt; cases\n\n\n\n\n\nEmpirical PR Curve of ZNF487 Expression for discrimination of Optimal v. Suboptimal\n\n\n\n\nOpen for comments.\n\n\n\nDET comparison\n\nDET_ZNF585B = DET(XX_ZNF585B,YY)\nplot(DET_ZNF487$zz0,DET_ZNF487$zz1,\n     xlab=c(\"False Positive Rate Deviate\",GeneName),\n     ylab=\"False Negative Rate Deviate\", type = \"l\",lwd=2,col=\"blue\")\nlines(DET_ZNF585B$zz0,DET_ZNF585B$zz1,col=\"orange\",lwd=2)\nabline(1,-1)\n\n\n\n\nDET curve for ZNF487 derived from class-conditional smooth density estimates\n\n\n\n\n\n\n\nThe Skill Plot\n[https://doi.org/10.1111/j.1541-0420.2007.00781_1.x]"
  },
  {
    "objectID": "L4-metrics.html#references",
    "href": "L4-metrics.html#references",
    "title": "Lecture 4: Basics of Biomarker Evaluation",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "L11-regmean.html#intro",
    "href": "L11-regmean.html#intro",
    "title": "Lecture 11: Regression to the Mean",
    "section": "Intro",
    "text": "Intro\nRegression to the mean refers to the tendency of units selected based on performance in noisy criteria to revert back towards the center of the distribution of performance in replication experiments, or over time.\nIn this lecture we build some intuition based on a simple simulation and then explore regression to the mean in TCGA data. The goal is to motivate methods, like multilevel models, that can help you anticipate and predict the effects of regression to the mean on the practical performance of biomarkers selected through a discovery process.\n\nData\nContinuous genomic feature: gene expression microarray readout in the TCGA study\nBinary phenotype (optimal surgical debulking)\n\nlibrary(curatedOvarianData)\nlibrary(ROCR)\ndata(TCGA_eset)\nXX = as.matrix(cbind(exprs(TCGA_eset)))\nYY = 1 * as.vector(pData(TCGA_eset)[,\"debulking\"]==\"optimal\")\nXX = XX[,!is.na(YY)]; \nYY = YY[!is.na(YY)]\n\nXXX = XX\nYYY = YY\n# subset\nsubs = 1:100\nXX = XX[,subs]; YY = YY[subs]\n\nAs before, we create two sets of summary scores. ScoresSub yields the four metrics computed on the first 100 patients, while ScoresAll gives the four metrics computed on the entire set of patients.\n\nsource(\"RScripts/Scores.R\")\nScoresSub = CompScores(XX,YY)\nScoresAll = CompScores(XXX,YYY)\n\nWe also recreate the permutation distribution of the scores.\n\nset.seed(1)\nYYNull = YY[ sample(1:length(YY)) ]\nScoresSubNull = CompScores(XX,YYNull)\n\nset.seed(1)\nYYYNull = YYY[ sample(1:length(YYY)) ]\nScoresAllNull = CompScores(XXX,YYYNull)\n\n\n\nMotivation\nBefore looking at regression to the mean, let’s first consider some simple exploration of the TCGA data. I picked a cutoff on the AUC and applied it to both the subsample and the full sample. Then I cross-tabulated discoveries. I did that with both the real data and the data after permutation of the obtimal debulking label.\n\nacut = .59\naucDiscSub = ScoresSub[,\"AUC\"]&gt;acut\naucDiscSubNull= ScoresSubNull[,\"AUC\"]&gt;acut\naucDiscAll = ScoresAll[,\"AUC\"]&gt;acut\naucDiscAllNull = ScoresAllNull[,\"AUC\"]&gt;acut\ntable(aucDiscSub,aucDiscAll)\n\n          aucDiscAll\naucDiscSub FALSE TRUE\n     FALSE  9854   51\n     TRUE   3167   32\n\n\n\ntable(aucDiscSubNull)\n\naucDiscSubNull\nFALSE  TRUE \n 9344  3760 \n\ntable(aucDiscAllNull)\n\naucDiscAllNull\nFALSE  TRUE \n13099     5 \n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat can we learn from the null distribution?"
  },
  {
    "objectID": "L11-regmean.html#simulated-example",
    "href": "L11-regmean.html#simulated-example",
    "title": "Lecture 11: Regression to the Mean",
    "section": "Simulated Example",
    "text": "Simulated Example\nSimulated example of the regression to the mean phenomenon. Here for simplicity I bypass the two group setting and just model a single group. The lessons in this example translate almost directly to making inferences on fold change. Fold change is defined over two groups. The analogy is between the means in this simulation and the mean difference in the two group case. The caveat is that the sample size does translate directly from one scenario to the other (the TCGA data are not paired), but the general behavior of the estimates as sample size(s) increase remains the same.\n\nN1 = 10\nN2 = 100\nNG = 50\n\nset.seed(127)\nTrueNoise = rexp(NG,1/5)\nset.seed(123)\nTrueMeans = rnorm(NG,0,1)\nset.seed(124)\nMeans1 = rnorm(NG,TrueMeans,TrueNoise*sqrt(1/N1))\nset.seed(125)\nMeans2 = ( N1*Means1 + (N2-N1) * \n             rnorm(NG,TrueMeans,TrueNoise*sqrt(1/(N2-N1))) ) / N2\n\nIn this simulation, I introduce two sources of variation: variation in the gene-level parametrs (TrueMeans and TrueNoise) and sampling variation. As you go through the results try to tease out the roles of these two sources of variation. Figuring it out on your own is the best strategy. This is a good read if you are stuck @Barnett2004ije\n\nSelecting biomarkers based on fold change after 10 and 100 observations\n\ncutoff = 1.4\nTrueDiscoveries = abs(TrueMeans) &gt; cutoff\nDiscoveries1 = abs(Means1) &gt; cutoff\nDiscoveries2 = abs(Means2) &gt; cutoff\nND = sum(Discoveries1)\n\nCross-tabulating result, with gold standard\n\ntable(Discoveries1,Discoveries2,TrueDiscoveries)\n\n, , TrueDiscoveries = FALSE\n\n            Discoveries2\nDiscoveries1 FALSE TRUE\n       FALSE    26    1\n       TRUE     16    1\n\n, , TrueDiscoveries = TRUE\n\n            Discoveries2\nDiscoveries1 FALSE TRUE\n       FALSE     0    1\n       TRUE      2    3\n\n\n\n\nplot(c(0,N2*1.2),range(Means1),type=\"n\",\n     xlab=\"SAMPLE SIZE\",ylab=\"FOLD CHANGE\")\npoints(rep(0,ND),TrueMeans[Discoveries1==\"TRUE\"],pch=\"-\",cex=2,col=\"red\")\npoints(rep(N1,ND),Means1[Discoveries1==\"TRUE\"],pch=\"-\",cex=2)\npoints(rep(N2,ND),Means2[Discoveries1==\"TRUE\"],pch=\"-\",cex=2)\nsegments(rep(0,ND),TrueMeans[Discoveries1==\"TRUE\"],\n         rep(N1,ND),Means1[Discoveries1==\"TRUE\"])\nsegments(rep(N1,ND),Means1[Discoveries1==\"TRUE\"],\n         rep(N2,ND),Means2[Discoveries1==\"TRUE\"])\nabline(h=cutoff,col=\"blue\",lwd=2)\nabline(h=-cutoff,col=\"blue\",lwd=2)\n\n\n\n\nEach line corresponts to a simulated marker. True means are graphed at n=0 in red. Blue lines represent discovery cutoffs. Only marker that exceed the cutoffs in absolute value at n=10 (small study) are graphed here.\n\n\n\n\n\n\nplot(c(0,N2*1.2),range(Means1),type=\"n\",\n     xlab=\"SAMPLE\",ylab=\"ESTIMATED FOLD CHANGE\")\npoints(rep(0,NG),TrueMeans,pch=\"-\",cex=2, col = \"red\")\npoints(rep(N1,NG),Means1,pch=\"-\",cex=2)\npoints(rep(N2,NG),Means2,pch=\"-\",cex=2)\nsegments(rep(0,NG),TrueMeans,rep(N1,NG),Means1)\nsegments(rep(N1,NG),Means1,rep(N2,NG),Means2)\n\n\n\n\nEach line corresponts to a simulated marker. True means are graphed at n=0 in red. Blue lines represent discovery cutoffs. Same as the previous figure except now all markers are graphed."
  },
  {
    "objectID": "L11-regmean.html#regression-to-the-mean-in-the-tcga-data",
    "href": "L11-regmean.html#regression-to-the-mean-in-the-tcga-data",
    "title": "Lecture 11: Regression to the Mean",
    "section": "Regression to the mean in the TCGA data",
    "text": "Regression to the mean in the TCGA data\n\npcut = 4.25\nacut = .66\nfcut = .5\n\nallTrue = abs(ScoresSub[,\"FoldChange\"])&gt;fcut & \n  ScoresSub[,\"nlpvalueT\"]&gt;pcut & ScoresSub[,\"AUC\"]&gt;acut\naucOnly = abs(ScoresSub[,\"FoldChange\"])&lt;fcut & \n  ScoresSub[,\"nlpvalueT\"]&lt;pcut & ScoresSub[,\"AUC\"]&gt;acut\npOnly = abs(ScoresSub[,\"FoldChange\"])&lt;fcut & \n  ScoresSub[,\"nlpvalueT\"]&gt;pcut & ScoresSub[,\"AUC\"]&lt;acut\nfcOnly = abs(ScoresSub[,\"FoldChange\"])&gt;fcut & \n  ScoresSub[,\"nlpvalueT\"]&lt;pcut & ScoresSub[,\"AUC\"]&lt;acut\nfcDisc = abs(ScoresSub[,\"FoldChange\"])&gt;fcut\n\n\n\nN1 = 100\nN2 = length(YYY)\nNG = nrow(XXX)\nNDfc = sum(fcDisc)\nplot(c(N1*.8,N2*1.2),range(ScoresSub[,\"FoldChange\"]),\n     type=\"n\",xlab=\"SAMPLE\",ylab=\"ESTIMATED FOLD CHANGE\")\ntitle(\"\")\npoints(rep(N1,NDfc),ScoresSub[fcDisc,\"FoldChange\"],\n       pch=\"-\",cex=2)\npoints(rep(N2,NDfc),ScoresAll[fcDisc,\"FoldChange\"],\n       pch=\"-\",cex=2)\nsegments(rep(N1,NDfc),ScoresSub[fcDisc,\"FoldChange\"],\n         rep(N2,NG),ScoresAll[fcDisc,\"FoldChange\"])\n\n\n\n\nSame format as simulated data (except no truth :). Only plotting markers discovered by fold change int he small sample at a threshold of .05.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou are the advisor to an investor who is considering funding a company that collected data on 100 samples. The company is proposing to commercialize a marker whose fold change is greater than 1, emphasizing the clinical implication of such a large difference. You have seen data like this figure before. How do you explain to the investor what is likely to happen and why?\n\n\n\nScatterplot version of the same data, to emphasize “shrinkage”.\n\nScores0 = ScoresSub[fcOnly,]\nScores1 = CompScores(XXX[fcOnly,],YYY)\nplot(Scores0[,\"FoldChange\"],Scores1[,\"FoldChange\"],\n     asp=1,ylim=range(Scores0[,\"FoldChange\"]))\nabline(h=fcut); abline(h=-fcut); abline(v=fcut)\nabline(v=-fcut); abline(0,1)\n\n\n\n\n\n\n\n\n\nLet’s now look at the p-value counterpart of this figure.\n\nScores0 = ScoresSub[pOnly,]\nScores1 = CompScores(XXX[pOnly,],YYY)\n#par(pty=\"s\")\nplot(Scores0[,\"nlpvalueT\"],Scores1[,\"nlpvalueT\"],\n     xlim=c(min(Scores1[,\"nlpvalueT\"]),max(Scores1[,\"nlpvalueT\"])))\nabline(v=pcut); abline(h=pcut); abline(0,1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ncompare and contrast the effect a bigger sample the means to the effect on the negative log p-values"
  },
  {
    "objectID": "L11-regmean.html#references",
    "href": "L11-regmean.html#references",
    "title": "Lecture 11: Regression to the Mean",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "L17-twomarkers.html",
    "href": "L17-twomarkers.html",
    "title": "Lecture 17",
    "section": "",
    "text": "Many statistical learning tools acan be used to identify predictors that, as a group, help us classify observations. This lecture covers a baic exercise in model building which, although extremely simplistic compared to even the most common of methods like regularized regression or random forests, can help build intuition for the challenges of building model from high dimensional noisy data. I also use this opportunity to switch to a time-to-event outcome.\n\n\nIn this section we will be utilizing data from the TCGA_eset dataset.\nWe will be considering continuous biomarker gene expressions in the TCGA study. The phenotype of interest will be a time-to-event variable, days_to_tumor_recurrence\n\nlibrary(survival)\nlibrary(curatedOvarianData)\ndata(TCGA_eset)\nGGG = as.matrix(cbind(exprs(TCGA_eset)))\nRecurrenceSurvObj = Surv( time = pData(TCGA_eset)[,\"days_to_tumor_recurrence\"],\n                          event = pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\")\nBinaryRecurrenceAt2y = pData(TCGA_eset)[,\"days_to_tumor_recurrence\"] &lt; 365*2\nBinaryRecurrenceAt2y[ pData(TCGA_eset)[,\"recurrence_status\"]!=\"recurrence\" & pData(TCGA_eset)[,\"days_to_tumor_recurrence\"] &lt; 365*2 ] = NA\n\n\nWe will then filter out the biomarkers with low IQR. A biomarker with a low IQR generally indicates a lack of variation within the range of possible values the biomarker takes. A lack of variation in turn may suggest a lack of discriminative ability. We will filter out genes with an IQR less than or equal to \\(1\\).\n\nIQR.cutoff = 1\nGGG.IQR = apply(GGG,1,IQR)\nGGG.filtered = GGG[GGG.IQR&gt;IQR.cutoff,]\nGGG.cor = cor(t(GGG.filtered))\n\n\n\n\n\nThen, we introduce a function that is similar to the CompScores function in preceeding sections. This new function, named CompScoresTE, will help us compute scoring metrics for recurrence based on marginal associations. Specifically, for each biomarker it computes the coefficient resulting from a Cox Proportional Hazards model fit on the biomarker, the negative log p-value of the coefficient, and the IQR of the biomarker.\n\n\nlibrary(survival)\nlibrary(survcomp)\n\nLoading required package: prodlim\n\nCompScoresTE = function(XX,YY){\nNGenes = nrow(XX)\nScoreNames = c(\"coxRR\",\"nlpvalue\",\"IQR\")\nSSS = data.frame(matrix(NA,NGenes,length(ScoreNames)))\ncolnames(SSS) = ScoreNames\nfor (gg in 1:NGenes){\n  cox.out = coxph(YY ~ XX[gg,])\n  SSS[gg,\"nlpvalue\"] = -log(summary(cox.out)$coefficients[,\"Pr(&gt;|z|)\"])\n  SSS[gg,\"coxRR\"] = summary(cox.out)$coefficients[,\"exp(coef)\"]\n  SSS[gg,\"IQR\"] = IQR(XX[gg,])\n}\nreturn(SSS)\n}\nScores = CompScoresTE(XX=GGG.filtered,YY=RecurrenceSurvObj)\n\n\nFrom this, we can resample the labels and obtain a null distribution for our data. We then set a cutoff of \\(1.2\\) for the coefficient from the Cox Proportional Hazards model and \\(7\\) for the negative log p-value of the coefficient. We then can tabulate which biomarkers are above these two values, in both the null and observed distributions.\n\nset.seed(1)\nLabelsNull = sample(1:ncol(GGG.filtered))\nRecurrenceSurvObjNull =  \n  Surv( time = pData(TCGA_eset)[LabelsNull,\"days_to_tumor_recurrence\"], event = pData(TCGA_eset)[LabelsNull,\"recurrence_status\"]==\"recurrence\")\nScoresNull = CompScoresTE(XX=GGG.filtered,YY=RecurrenceSurvObjNull)\ntable(Scores[,\"coxRR\"]&gt;1.2)\n\n\nFALSE  TRUE \n 2180     9 \n\ntable(ScoresNull[,\"coxRR\"]&gt;1.2)\n\n\nFALSE  TRUE \n 2185     4 \n\ntable(Scores[,\"nlpvalue\"]&gt;7)\n\n\nFALSE  TRUE \n 2183     6 \n\ntable(ScoresNull[,\"nlpvalue\"]&gt;7)\n\n\nFALSE  TRUE \n 2187     2 \n\n\n\n\n\n\n\n\n\nWe will now compute scores for pairs and pick the best partner biomarker. We will also examine all possible additional variables in a multivariable model.\nHere one of the two partners is fixed (in this case the winner of the one-gene-at-the-time competition). The score for the pair is the Wald test for the model as a whole (both variables in vs no variable in).\n\nCompScoresPairs1 = function(XX,YY,gg0){\nNGenes = nrow(XX)\nScoreNames = c(\"coxRR0\",\"coxRRa\",\"nlpvalueW\",\"cor\")\nSSS = data.frame(matrix(NA,NGenes,length(ScoreNames)))\ncolnames(SSS) = ScoreNames\nfor (gg in (1:NGenes) ){\n  cox.out = coxph(YY ~ XX[gg,]+XX[gg0,])\n  SSS[gg,\"coxRR0\"] = summary(cox.out)$coefficients[2,\"exp(coef)\"]\n  SSS[gg,\"coxRRa\"] = summary(cox.out)$coefficients[1,\"exp(coef)\"]\n  SSS[gg,\"nlpvalueW\"] = - log ( summary(cox.out)$wald[\"pvalue\"] )\n  SSS[gg,\"cor\"] = cor(XX[gg,],XX[gg0,])\n}\nreturn(SSS)\n}\n\nTopGene = (1:nrow(Scores))[Scores[,\"nlpvalue\"]==max(Scores[,\"nlpvalue\"])]\nTopGenes7 = (1:nrow(Scores))[Scores[,\"nlpvalue\"]&gt;7]\nScoresPairs1 = CompScoresPairs1(XX=GGG.filtered,YY=RecurrenceSurvObj,gg0=TopGene)\nTopPair1 = (1:nrow(ScoresPairs1))[ScoresPairs1[,\"nlpvalueW\"]==max(ScoresPairs1[,\"nlpvalueW\"])]\n\n\nWe can then plot the single predictor negative log p-value against the negative log p-value associated with multiple variables.\nThe lone point on the right is the best gene paired with itself, so the horizontal line represents the “bar” we need to meet for the pair to be better than the single.\nColors highlight with positive (blue) or negative (orange) correlation with the top gene, exceeding .1 in absolute value.\n\nplot( Scores[,\"nlpvalue\"],ScoresPairs1[,\"nlpvalueW\"], pch=\".\", cex=5, \n      ylab=\"Mutivariable negative log p-value\", \n      xlab=\"Single predictor negative log p-value\"  )\nabline(h=Scores[TopGene,\"nlpvalue\"])\nabline(0,1)\nPosCor = ScoresPairs1[ ,\"cor\"] &gt; .1\nNegCor = ScoresPairs1[ ,\"cor\"] &lt; - .1\npoints( Scores[ PosCor,\"nlpvalue\"],\n        ScoresPairs1[ PosCor,\"nlpvalueW\"], pch=\".\", col=\"blue\", cex=5 )\npoints( Scores[ NegCor,\"nlpvalue\"],\n        ScoresPairs1[ NegCor,\"nlpvalueW\"], pch=\".\", col=\"orange\", cex=5 )\n\n\n\n\nMultivariable vs. Single Predictor Negative Log P-value Plot\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nComment\n\n\n\n\n\n\nWe now take a slightly different approach by computing scores by pairs, picking one biomarker, and then looking at all possible “averaging partners”.\n\nCompScoresPairs2 = function(XX,YY,gg0){\nNGenes = nrow(XX)\nScoreNames = c(\"coxRRa\",\"nlpvalueW\",\"cor\")\nSSS = data.frame(matrix(NA,NGenes,length(ScoreNames)))\ncolnames(SSS) = ScoreNames\nfor (gg in 1:NGenes) {\n  XXa = ( XX[gg,]+XX[gg0,] ) / 2\n  cox.out = coxph(YY ~ XXa)\n  SSS[gg,\"coxRRa\"] = summary(cox.out)$coefficients[1,\"exp(coef)\"]\n  SSS[gg,\"nlpvalueW\"] = - log ( summary(cox.out)$wald[\"pvalue\"] )\n  SSS[gg,\"cor\"] = cor(XX[gg,],XX[gg0,])\n}\nreturn(SSS)\n}\n\nScoresPairs2 = CompScoresPairs2(XX=GGG.filtered,YY=RecurrenceSurvObj,gg0=TopGene)\nTopPair2 = (1:nrow(ScoresPairs2))[ScoresPairs2[,\"nlpvalueW\"]==\n                                    max(ScoresPairs2[,\"nlpvalueW\"])]\nTopPartners11 = (1:nrow(ScoresPairs2))[ScoresPairs2[,\"nlpvalueW\"]&gt;11]\nTopPartnersNegCor = (1:nrow(ScoresPairs2))[ScoresPairs2[,\"nlpvalueW\"]&gt;11 & \n                                             ScoresPairs2[ ,\"cor\"] &lt; - .1]\nTopPartnersPosCor = (1:nrow(ScoresPairs2))[ScoresPairs2[,\"nlpvalueW\"]&gt;11 & \n                                             ScoresPairs2[ ,\"cor\"] &gt; .1]\n\n\nThe plot of interest would then be the single predictor negative log p-value against the averaged predictor negative log p-value.\n\nplot( Scores[,\"nlpvalue\"],ScoresPairs2[,\"nlpvalueW\"], pch=\".\", cex=3, xlab=\"Single variable negative log p-value\", ylab=\"Averaged predictors negative log p-value\"  )\nabline(h=Scores[TopGene,\"nlpvalue\"])\nabline(0,1)\nPosCor = ScoresPairs2[ ,\"cor\"] &gt; .1\npoints( Scores[ PosCor,\"nlpvalue\"],ScoresPairs2[ PosCor,\"nlpvalueW\"], \n        pch=\".\", col=\"blue\", cex=5 )\nNegCor = ScoresPairs2[ ,\"cor\"] &lt; - .1\npoints( Scores[ NegCor,\"nlpvalue\"],ScoresPairs2[ NegCor,\"nlpvalueW\"], \n        pch=\".\", col=\"orange\", cex=5 )\n\n\n\n\nAveraged vs. Single Predictor Negative Log P-value Plot\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nComment:\n\nWhy is the largest p-value encountered in this point and not the previous one?\nWhy the lobster claw?\nThe second best gene used to be the best partner in the linear combination, but now when we simply average the result is terrible. Why?\n\nSome hints are in the following two figure, but it helps to puzzle it out for at least a bit before you proceed.\n\n\n\nThe following table reports the correlation, exponentiated coefficient value, and the associated scores.\n\ncbind(ScoresPairs2[TopGenes7,c(\"cor\",\"coxRRa\")],Scores[TopGenes7,c(\"coxRR\")])\n\n              cor    coxRRa Scores[TopGenes7, c(\"coxRR\")]\n143   0.002878691 1.0729832                     1.1662079\n642   1.000000000 0.7770615                     0.7770615\n665  -0.079376471 0.9343275                     1.3021766\n727   0.066969147 0.6088374                     0.7846375\n799   0.179723073 0.7048702                     0.8172432\n1529 -0.190374846 1.0129224                     1.2183982\n\n\n\nWe can also plot the multivariable negative log p-value against the averaged predictor negative log p-value, further greying out those with marginal positive association with the outcome.\n\nplot( ScoresPairs1[,\"nlpvalueW\"],ScoresPairs2[,\"nlpvalueW\"], pch=\".\", cex=5, xlab=\"Mutivariable negative log p-value\", ylab=\"Averaged predictors negative log p-value\" )\nabline(0,1)\nPosCor = ScoresPairs1[ ,\"cor\"] &gt; .1\nNegCor = ScoresPairs1[ ,\"cor\"] &lt; - .1\nPosCoef = ScoresPairs1[,\"coxRRa\"] &gt; 1\npoints( ScoresPairs1[ PosCor,\"nlpvalueW\"],ScoresPairs2[ PosCor,\"nlpvalueW\"], \n        pch=\".\", col=\"blue\", cex=5 )\npoints( ScoresPairs1[ NegCor,\"nlpvalueW\"],ScoresPairs2[ NegCor,\"nlpvalueW\"], \n        pch=\".\", col=\"orange\", cex=5 )\npoints( ScoresPairs1[ PosCoef,\"nlpvalueW\"],ScoresPairs2[ PosCoef,\"nlpvalueW\"], \n        pch=\".\", col=\"gray\", cex=5 )\n\n\n\n\nMultivariable vs. Averaged Predictor Negative Log P-value Plot\n\n\n\n\n\nAn additional plot below compares the top gene and the top pair as identified above.\n\nplot( GGG.filtered[TopGene,], GGG.filtered[TopPair1,])\n\n\n\n\nTop Pair vs. Top Gene Plot\n\n\n\n\n\n\n\n\nA few miscellaneious plots, mostly to give you a sense for the fact that signal is weak and modeling is hard.\nWe now plot the expression values for the genes with a high combined predictor negative log p-value and that are positively correlated with the identified best gene. The orange/black points indicates recurrence/no recurrence, with recurrence being orange.\n\npar(pty=\"s\")\nplot( GGG.filtered[TopGene,], GGG.filtered[TopPartnersPosCor[2],])\npoints(GGG.filtered[TopGene,], GGG.filtered[TopPartnersPosCor[2],],col=1+as.vector( pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\nScatterplot for High Combined Predictor NLP-value and Positive Correlation with Top Gene\n\n\n\n\n\nNG = nrow(GGG.filtered)\nNS = length(as.vector(pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\"))\npar(pty=\"m\")\nplot(GGG.filtered[TopGene,], rnorm(NS,0,.1)+as.vector(pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\n\n\n\n\n\nplot( .5 * (GGG.filtered[TopGene,]+GGG.filtered[TopPartnersPosCor[2],] ), rnorm(NS,0,.1)+as.vector(pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\n\n\n\n\n\nWe can also plot the expression values for the genes with a high combined predictor negative log p-value and that are negatively correlated with the identified best gene. The red/black points indicates recurrence/no recurrence, with recurrence being red in color.\n\npar(pty=\"s\")\nplot( GGG.filtered[TopGene,], GGG.filtered[TopPartnersNegCor[1],])\npoints(GGG.filtered[TopGene,], GGG.filtered[TopPartnersNegCor[1],],col=1+as.vector( pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\n\n\n\n\n\npar(pty=\"m\")\nplot(GGG.filtered[TopGene,], rnorm(NS,0,.1)+as.vector(pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\n\n\n\n\n\nplot( .5 * (GGG.filtered[TopGene,]+GGG.filtered[TopPartnersNegCor[1],] ), rnorm(NS,0,.1)+as.vector(pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\n\n\n\n\n\nThe following figures plot the expression values for the multivariable top pairs.\n\nplot( GGG.filtered[TopGene,], GGG.filtered[TopPair1,])\n\n\n\n\n\n\n\n\n\nplot( GGG.filtered[TopPair1,], GGG.filtered[TopPair2,])\n\n\n\n\n\n\n\n\n\nWe now plot the expression values for the top pairs by averaging.\n\nplot( GGG.filtered[TopGene,], GGG.filtered[TopPair2,])\n\n\n\n\n\n\n\n\n\nplot( GGG.filtered[TopPair1,], GGG.filtered[TopPair2,])\n\n\n\n\n\n\n\n\n\nHere are more visualizations through a Kaplan-Meier Curve\n\nkm.as.one = survfit (RecurrenceSurvObj ~ 1)\nkm.by.topgene = survfit (RecurrenceSurvObj ~ GGG.filtered[TopGene,] &gt; median(GGG.filtered[TopGene,]))\nkm.by.toppair1 = survfit (RecurrenceSurvObj ~ GGG.filtered[TopPair1,]&gt;\nmedian(GGG.filtered[TopPair1,]))\nkm.by.toppair2 = survfit (RecurrenceSurvObj ~ GGG.filtered[TopPair2,]&gt;median(GGG.filtered[TopPair2,]))\n\n\nplot(km.as.one)\n\n\n\n\nKaplan-Meier Curve Regressed on Intercept Only\n\n\n\n\n\nplot(km.by.topgene)\n\n\n\n\nKaplan-Meier Curve Regressed on Top Gene by Median\n\n\n\n\n\nplot(km.by.toppair1)\n\n\n\n\nKaplan-Meier Curve Regressed on Top Pair 1\n\n\n\n\n\nplot(km.by.toppair2)\n\n\n\n\nKaplan-Meier Curve Regressed on Top Pair 2\n\n\n\n\n\nWe can also obtain the Cox Proprotional Hazards Model.\n\ncox.pair1 = coxph(RecurrenceSurvObj ~ GGG.filtered[TopGene,]+GGG.filtered[TopPair1,])\nsummary(cox.pair1)\n\nCall:\ncoxph(formula = RecurrenceSurvObj ~ GGG.filtered[TopGene, ] + \n    GGG.filtered[TopPair1, ])\n\n  n= 522, number of events= 266 \n   (56 observations deleted due to missingness)\n\n                             coef exp(coef) se(coef)      z Pr(&gt;|z|)    \nGGG.filtered[TopGene, ]  -0.24020   0.78647  0.06799 -3.533 0.000411 ***\nGGG.filtered[TopPair1, ]  0.14613   1.15735  0.04258  3.432 0.000598 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                         exp(coef) exp(-coef) lower .95 upper .95\nGGG.filtered[TopGene, ]     0.7865      1.272    0.6883    0.8986\nGGG.filtered[TopPair1, ]    1.1574      0.864    1.0647    1.2581\n\nConcordance= 0.579  (se = 0.02 )\nLikelihood ratio test= 25.72  on 2 df,   p=3e-06\nWald test            = 25.53  on 2 df,   p=3e-06\nScore (logrank) test = 25.6  on 2 df,   p=3e-06\n\npair2.mean = ( GGG.filtered[TopGene,]+GGG.filtered[TopPair2,] ) / 2\ncox.pair2 = coxph(RecurrenceSurvObj ~ pair2.mean)\nsummary(cox.pair2)\n\nCall:\ncoxph(formula = RecurrenceSurvObj ~ pair2.mean)\n\n  n= 522, number of events= 266 \n   (56 observations deleted due to missingness)\n\n               coef exp(coef) se(coef)      z Pr(&gt;|z|)    \npair2.mean -0.49620   0.60884  0.09887 -5.019  5.2e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n           exp(coef) exp(-coef) lower .95 upper .95\npair2.mean    0.6088      1.642    0.5016     0.739\n\nConcordance= 0.593  (se = 0.02 )\nLikelihood ratio test= 26.28  on 1 df,   p=3e-07\nWald test            = 25.19  on 1 df,   p=5e-07\nScore (logrank) test = 25.36  on 1 df,   p=5e-07\n\ncor( t(GGG.filtered[c(TopGene,TopPair1,TopPair2),]) )\n\n             FAH         ATF3        FZD4\nFAH  1.000000000  0.002878691  0.06696915\nATF3 0.002878691  1.000000000 -0.06247520\nFZD4 0.066969147 -0.062475205  1.00000000"
  },
  {
    "objectID": "L17-twomarkers.html#finding-partners",
    "href": "L17-twomarkers.html#finding-partners",
    "title": "Lecture 17",
    "section": "",
    "text": "Many statistical learning tools acan be used to identify predictors that, as a group, help us classify observations. This lecture covers a baic exercise in model building which, although extremely simplistic compared to even the most common of methods like regularized regression or random forests, can help build intuition for the challenges of building model from high dimensional noisy data. I also use this opportunity to switch to a time-to-event outcome.\n\n\nIn this section we will be utilizing data from the TCGA_eset dataset.\nWe will be considering continuous biomarker gene expressions in the TCGA study. The phenotype of interest will be a time-to-event variable, days_to_tumor_recurrence\n\nlibrary(survival)\nlibrary(curatedOvarianData)\ndata(TCGA_eset)\nGGG = as.matrix(cbind(exprs(TCGA_eset)))\nRecurrenceSurvObj = Surv( time = pData(TCGA_eset)[,\"days_to_tumor_recurrence\"],\n                          event = pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\")\nBinaryRecurrenceAt2y = pData(TCGA_eset)[,\"days_to_tumor_recurrence\"] &lt; 365*2\nBinaryRecurrenceAt2y[ pData(TCGA_eset)[,\"recurrence_status\"]!=\"recurrence\" & pData(TCGA_eset)[,\"days_to_tumor_recurrence\"] &lt; 365*2 ] = NA\n\n\nWe will then filter out the biomarkers with low IQR. A biomarker with a low IQR generally indicates a lack of variation within the range of possible values the biomarker takes. A lack of variation in turn may suggest a lack of discriminative ability. We will filter out genes with an IQR less than or equal to \\(1\\).\n\nIQR.cutoff = 1\nGGG.IQR = apply(GGG,1,IQR)\nGGG.filtered = GGG[GGG.IQR&gt;IQR.cutoff,]\nGGG.cor = cor(t(GGG.filtered))\n\n\n\n\n\nThen, we introduce a function that is similar to the CompScores function in preceeding sections. This new function, named CompScoresTE, will help us compute scoring metrics for recurrence based on marginal associations. Specifically, for each biomarker it computes the coefficient resulting from a Cox Proportional Hazards model fit on the biomarker, the negative log p-value of the coefficient, and the IQR of the biomarker.\n\n\nlibrary(survival)\nlibrary(survcomp)\n\nLoading required package: prodlim\n\nCompScoresTE = function(XX,YY){\nNGenes = nrow(XX)\nScoreNames = c(\"coxRR\",\"nlpvalue\",\"IQR\")\nSSS = data.frame(matrix(NA,NGenes,length(ScoreNames)))\ncolnames(SSS) = ScoreNames\nfor (gg in 1:NGenes){\n  cox.out = coxph(YY ~ XX[gg,])\n  SSS[gg,\"nlpvalue\"] = -log(summary(cox.out)$coefficients[,\"Pr(&gt;|z|)\"])\n  SSS[gg,\"coxRR\"] = summary(cox.out)$coefficients[,\"exp(coef)\"]\n  SSS[gg,\"IQR\"] = IQR(XX[gg,])\n}\nreturn(SSS)\n}\nScores = CompScoresTE(XX=GGG.filtered,YY=RecurrenceSurvObj)\n\n\nFrom this, we can resample the labels and obtain a null distribution for our data. We then set a cutoff of \\(1.2\\) for the coefficient from the Cox Proportional Hazards model and \\(7\\) for the negative log p-value of the coefficient. We then can tabulate which biomarkers are above these two values, in both the null and observed distributions.\n\nset.seed(1)\nLabelsNull = sample(1:ncol(GGG.filtered))\nRecurrenceSurvObjNull =  \n  Surv( time = pData(TCGA_eset)[LabelsNull,\"days_to_tumor_recurrence\"], event = pData(TCGA_eset)[LabelsNull,\"recurrence_status\"]==\"recurrence\")\nScoresNull = CompScoresTE(XX=GGG.filtered,YY=RecurrenceSurvObjNull)\ntable(Scores[,\"coxRR\"]&gt;1.2)\n\n\nFALSE  TRUE \n 2180     9 \n\ntable(ScoresNull[,\"coxRR\"]&gt;1.2)\n\n\nFALSE  TRUE \n 2185     4 \n\ntable(Scores[,\"nlpvalue\"]&gt;7)\n\n\nFALSE  TRUE \n 2183     6 \n\ntable(ScoresNull[,\"nlpvalue\"]&gt;7)\n\n\nFALSE  TRUE \n 2187     2"
  },
  {
    "objectID": "L17-twomarkers.html#two-markers-at-the-time",
    "href": "L17-twomarkers.html#two-markers-at-the-time",
    "title": "Lecture 17",
    "section": "",
    "text": "We will now compute scores for pairs and pick the best partner biomarker. We will also examine all possible additional variables in a multivariable model.\nHere one of the two partners is fixed (in this case the winner of the one-gene-at-the-time competition). The score for the pair is the Wald test for the model as a whole (both variables in vs no variable in).\n\nCompScoresPairs1 = function(XX,YY,gg0){\nNGenes = nrow(XX)\nScoreNames = c(\"coxRR0\",\"coxRRa\",\"nlpvalueW\",\"cor\")\nSSS = data.frame(matrix(NA,NGenes,length(ScoreNames)))\ncolnames(SSS) = ScoreNames\nfor (gg in (1:NGenes) ){\n  cox.out = coxph(YY ~ XX[gg,]+XX[gg0,])\n  SSS[gg,\"coxRR0\"] = summary(cox.out)$coefficients[2,\"exp(coef)\"]\n  SSS[gg,\"coxRRa\"] = summary(cox.out)$coefficients[1,\"exp(coef)\"]\n  SSS[gg,\"nlpvalueW\"] = - log ( summary(cox.out)$wald[\"pvalue\"] )\n  SSS[gg,\"cor\"] = cor(XX[gg,],XX[gg0,])\n}\nreturn(SSS)\n}\n\nTopGene = (1:nrow(Scores))[Scores[,\"nlpvalue\"]==max(Scores[,\"nlpvalue\"])]\nTopGenes7 = (1:nrow(Scores))[Scores[,\"nlpvalue\"]&gt;7]\nScoresPairs1 = CompScoresPairs1(XX=GGG.filtered,YY=RecurrenceSurvObj,gg0=TopGene)\nTopPair1 = (1:nrow(ScoresPairs1))[ScoresPairs1[,\"nlpvalueW\"]==max(ScoresPairs1[,\"nlpvalueW\"])]\n\n\nWe can then plot the single predictor negative log p-value against the negative log p-value associated with multiple variables.\nThe lone point on the right is the best gene paired with itself, so the horizontal line represents the “bar” we need to meet for the pair to be better than the single.\nColors highlight with positive (blue) or negative (orange) correlation with the top gene, exceeding .1 in absolute value.\n\nplot( Scores[,\"nlpvalue\"],ScoresPairs1[,\"nlpvalueW\"], pch=\".\", cex=5, \n      ylab=\"Mutivariable negative log p-value\", \n      xlab=\"Single predictor negative log p-value\"  )\nabline(h=Scores[TopGene,\"nlpvalue\"])\nabline(0,1)\nPosCor = ScoresPairs1[ ,\"cor\"] &gt; .1\nNegCor = ScoresPairs1[ ,\"cor\"] &lt; - .1\npoints( Scores[ PosCor,\"nlpvalue\"],\n        ScoresPairs1[ PosCor,\"nlpvalueW\"], pch=\".\", col=\"blue\", cex=5 )\npoints( Scores[ NegCor,\"nlpvalue\"],\n        ScoresPairs1[ NegCor,\"nlpvalueW\"], pch=\".\", col=\"orange\", cex=5 )\n\n\n\n\nMultivariable vs. Single Predictor Negative Log P-value Plot\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nComment\n\n\n\n\n\n\nWe now take a slightly different approach by computing scores by pairs, picking one biomarker, and then looking at all possible “averaging partners”.\n\nCompScoresPairs2 = function(XX,YY,gg0){\nNGenes = nrow(XX)\nScoreNames = c(\"coxRRa\",\"nlpvalueW\",\"cor\")\nSSS = data.frame(matrix(NA,NGenes,length(ScoreNames)))\ncolnames(SSS) = ScoreNames\nfor (gg in 1:NGenes) {\n  XXa = ( XX[gg,]+XX[gg0,] ) / 2\n  cox.out = coxph(YY ~ XXa)\n  SSS[gg,\"coxRRa\"] = summary(cox.out)$coefficients[1,\"exp(coef)\"]\n  SSS[gg,\"nlpvalueW\"] = - log ( summary(cox.out)$wald[\"pvalue\"] )\n  SSS[gg,\"cor\"] = cor(XX[gg,],XX[gg0,])\n}\nreturn(SSS)\n}\n\nScoresPairs2 = CompScoresPairs2(XX=GGG.filtered,YY=RecurrenceSurvObj,gg0=TopGene)\nTopPair2 = (1:nrow(ScoresPairs2))[ScoresPairs2[,\"nlpvalueW\"]==\n                                    max(ScoresPairs2[,\"nlpvalueW\"])]\nTopPartners11 = (1:nrow(ScoresPairs2))[ScoresPairs2[,\"nlpvalueW\"]&gt;11]\nTopPartnersNegCor = (1:nrow(ScoresPairs2))[ScoresPairs2[,\"nlpvalueW\"]&gt;11 & \n                                             ScoresPairs2[ ,\"cor\"] &lt; - .1]\nTopPartnersPosCor = (1:nrow(ScoresPairs2))[ScoresPairs2[,\"nlpvalueW\"]&gt;11 & \n                                             ScoresPairs2[ ,\"cor\"] &gt; .1]\n\n\nThe plot of interest would then be the single predictor negative log p-value against the averaged predictor negative log p-value.\n\nplot( Scores[,\"nlpvalue\"],ScoresPairs2[,\"nlpvalueW\"], pch=\".\", cex=3, xlab=\"Single variable negative log p-value\", ylab=\"Averaged predictors negative log p-value\"  )\nabline(h=Scores[TopGene,\"nlpvalue\"])\nabline(0,1)\nPosCor = ScoresPairs2[ ,\"cor\"] &gt; .1\npoints( Scores[ PosCor,\"nlpvalue\"],ScoresPairs2[ PosCor,\"nlpvalueW\"], \n        pch=\".\", col=\"blue\", cex=5 )\nNegCor = ScoresPairs2[ ,\"cor\"] &lt; - .1\npoints( Scores[ NegCor,\"nlpvalue\"],ScoresPairs2[ NegCor,\"nlpvalueW\"], \n        pch=\".\", col=\"orange\", cex=5 )\n\n\n\n\nAveraged vs. Single Predictor Negative Log P-value Plot\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nComment:\n\nWhy is the largest p-value encountered in this point and not the previous one?\nWhy the lobster claw?\nThe second best gene used to be the best partner in the linear combination, but now when we simply average the result is terrible. Why?\n\nSome hints are in the following two figure, but it helps to puzzle it out for at least a bit before you proceed.\n\n\n\nThe following table reports the correlation, exponentiated coefficient value, and the associated scores.\n\ncbind(ScoresPairs2[TopGenes7,c(\"cor\",\"coxRRa\")],Scores[TopGenes7,c(\"coxRR\")])\n\n              cor    coxRRa Scores[TopGenes7, c(\"coxRR\")]\n143   0.002878691 1.0729832                     1.1662079\n642   1.000000000 0.7770615                     0.7770615\n665  -0.079376471 0.9343275                     1.3021766\n727   0.066969147 0.6088374                     0.7846375\n799   0.179723073 0.7048702                     0.8172432\n1529 -0.190374846 1.0129224                     1.2183982\n\n\n\nWe can also plot the multivariable negative log p-value against the averaged predictor negative log p-value, further greying out those with marginal positive association with the outcome.\n\nplot( ScoresPairs1[,\"nlpvalueW\"],ScoresPairs2[,\"nlpvalueW\"], pch=\".\", cex=5, xlab=\"Mutivariable negative log p-value\", ylab=\"Averaged predictors negative log p-value\" )\nabline(0,1)\nPosCor = ScoresPairs1[ ,\"cor\"] &gt; .1\nNegCor = ScoresPairs1[ ,\"cor\"] &lt; - .1\nPosCoef = ScoresPairs1[,\"coxRRa\"] &gt; 1\npoints( ScoresPairs1[ PosCor,\"nlpvalueW\"],ScoresPairs2[ PosCor,\"nlpvalueW\"], \n        pch=\".\", col=\"blue\", cex=5 )\npoints( ScoresPairs1[ NegCor,\"nlpvalueW\"],ScoresPairs2[ NegCor,\"nlpvalueW\"], \n        pch=\".\", col=\"orange\", cex=5 )\npoints( ScoresPairs1[ PosCoef,\"nlpvalueW\"],ScoresPairs2[ PosCoef,\"nlpvalueW\"], \n        pch=\".\", col=\"gray\", cex=5 )\n\n\n\n\nMultivariable vs. Averaged Predictor Negative Log P-value Plot\n\n\n\n\n\nAn additional plot below compares the top gene and the top pair as identified above.\n\nplot( GGG.filtered[TopGene,], GGG.filtered[TopPair1,])\n\n\n\n\nTop Pair vs. Top Gene Plot\n\n\n\n\n\n\n\n\nA few miscellaneious plots, mostly to give you a sense for the fact that signal is weak and modeling is hard.\nWe now plot the expression values for the genes with a high combined predictor negative log p-value and that are positively correlated with the identified best gene. The orange/black points indicates recurrence/no recurrence, with recurrence being orange.\n\npar(pty=\"s\")\nplot( GGG.filtered[TopGene,], GGG.filtered[TopPartnersPosCor[2],])\npoints(GGG.filtered[TopGene,], GGG.filtered[TopPartnersPosCor[2],],col=1+as.vector( pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\nScatterplot for High Combined Predictor NLP-value and Positive Correlation with Top Gene\n\n\n\n\n\nNG = nrow(GGG.filtered)\nNS = length(as.vector(pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\"))\npar(pty=\"m\")\nplot(GGG.filtered[TopGene,], rnorm(NS,0,.1)+as.vector(pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\n\n\n\n\n\nplot( .5 * (GGG.filtered[TopGene,]+GGG.filtered[TopPartnersPosCor[2],] ), rnorm(NS,0,.1)+as.vector(pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\n\n\n\n\n\nWe can also plot the expression values for the genes with a high combined predictor negative log p-value and that are negatively correlated with the identified best gene. The red/black points indicates recurrence/no recurrence, with recurrence being red in color.\n\npar(pty=\"s\")\nplot( GGG.filtered[TopGene,], GGG.filtered[TopPartnersNegCor[1],])\npoints(GGG.filtered[TopGene,], GGG.filtered[TopPartnersNegCor[1],],col=1+as.vector( pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\n\n\n\n\n\npar(pty=\"m\")\nplot(GGG.filtered[TopGene,], rnorm(NS,0,.1)+as.vector(pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\n\n\n\n\n\nplot( .5 * (GGG.filtered[TopGene,]+GGG.filtered[TopPartnersNegCor[1],] ), rnorm(NS,0,.1)+as.vector(pData(TCGA_eset)[,\"recurrence_status\"]==\"recurrence\") )\n\n\n\n\n\n\n\n\n\nThe following figures plot the expression values for the multivariable top pairs.\n\nplot( GGG.filtered[TopGene,], GGG.filtered[TopPair1,])\n\n\n\n\n\n\n\n\n\nplot( GGG.filtered[TopPair1,], GGG.filtered[TopPair2,])\n\n\n\n\n\n\n\n\n\nWe now plot the expression values for the top pairs by averaging.\n\nplot( GGG.filtered[TopGene,], GGG.filtered[TopPair2,])\n\n\n\n\n\n\n\n\n\nplot( GGG.filtered[TopPair1,], GGG.filtered[TopPair2,])\n\n\n\n\n\n\n\n\n\nHere are more visualizations through a Kaplan-Meier Curve\n\nkm.as.one = survfit (RecurrenceSurvObj ~ 1)\nkm.by.topgene = survfit (RecurrenceSurvObj ~ GGG.filtered[TopGene,] &gt; median(GGG.filtered[TopGene,]))\nkm.by.toppair1 = survfit (RecurrenceSurvObj ~ GGG.filtered[TopPair1,]&gt;\nmedian(GGG.filtered[TopPair1,]))\nkm.by.toppair2 = survfit (RecurrenceSurvObj ~ GGG.filtered[TopPair2,]&gt;median(GGG.filtered[TopPair2,]))\n\n\nplot(km.as.one)\n\n\n\n\nKaplan-Meier Curve Regressed on Intercept Only\n\n\n\n\n\nplot(km.by.topgene)\n\n\n\n\nKaplan-Meier Curve Regressed on Top Gene by Median\n\n\n\n\n\nplot(km.by.toppair1)\n\n\n\n\nKaplan-Meier Curve Regressed on Top Pair 1\n\n\n\n\n\nplot(km.by.toppair2)\n\n\n\n\nKaplan-Meier Curve Regressed on Top Pair 2\n\n\n\n\n\nWe can also obtain the Cox Proprotional Hazards Model.\n\ncox.pair1 = coxph(RecurrenceSurvObj ~ GGG.filtered[TopGene,]+GGG.filtered[TopPair1,])\nsummary(cox.pair1)\n\nCall:\ncoxph(formula = RecurrenceSurvObj ~ GGG.filtered[TopGene, ] + \n    GGG.filtered[TopPair1, ])\n\n  n= 522, number of events= 266 \n   (56 observations deleted due to missingness)\n\n                             coef exp(coef) se(coef)      z Pr(&gt;|z|)    \nGGG.filtered[TopGene, ]  -0.24020   0.78647  0.06799 -3.533 0.000411 ***\nGGG.filtered[TopPair1, ]  0.14613   1.15735  0.04258  3.432 0.000598 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                         exp(coef) exp(-coef) lower .95 upper .95\nGGG.filtered[TopGene, ]     0.7865      1.272    0.6883    0.8986\nGGG.filtered[TopPair1, ]    1.1574      0.864    1.0647    1.2581\n\nConcordance= 0.579  (se = 0.02 )\nLikelihood ratio test= 25.72  on 2 df,   p=3e-06\nWald test            = 25.53  on 2 df,   p=3e-06\nScore (logrank) test = 25.6  on 2 df,   p=3e-06\n\npair2.mean = ( GGG.filtered[TopGene,]+GGG.filtered[TopPair2,] ) / 2\ncox.pair2 = coxph(RecurrenceSurvObj ~ pair2.mean)\nsummary(cox.pair2)\n\nCall:\ncoxph(formula = RecurrenceSurvObj ~ pair2.mean)\n\n  n= 522, number of events= 266 \n   (56 observations deleted due to missingness)\n\n               coef exp(coef) se(coef)      z Pr(&gt;|z|)    \npair2.mean -0.49620   0.60884  0.09887 -5.019  5.2e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n           exp(coef) exp(-coef) lower .95 upper .95\npair2.mean    0.6088      1.642    0.5016     0.739\n\nConcordance= 0.593  (se = 0.02 )\nLikelihood ratio test= 26.28  on 1 df,   p=3e-07\nWald test            = 25.19  on 1 df,   p=5e-07\nScore (logrank) test = 25.36  on 1 df,   p=5e-07\n\ncor( t(GGG.filtered[c(TopGene,TopPair1,TopPair2),]) )\n\n             FAH         ATF3        FZD4\nFAH  1.000000000  0.002878691  0.06696915\nATF3 0.002878691  1.000000000 -0.06247520\nFZD4 0.066969147 -0.062475205  1.00000000"
  },
  {
    "objectID": "L10-fdr.html#multiple-testing",
    "href": "L10-fdr.html#multiple-testing",
    "title": "Lecture 10: False Discovery Rates",
    "section": "Multiple Testing",
    "text": "Multiple Testing\n\nIntro\nIn our previous discussion we played with various approaches for discovering sets of promising biomarkers. How can we assess the quality of the discovery process and results? The most basic version of this assessment is based on assuming there is a binary truth at the gene level, representing biomarker with and without biological signal, and that the discovery process is about revealing this vector of binary labels. Formally, this is a multiple hypothesis testing problem.\nThe literature of multiple testing is enormously big. A favorite of mine is @Tukey:1991ga\n\n\nSetting and notation:\n\\(g = 1, \\ldots, G\\) genomic features, for example genes in gene-level analysis of expression data\n\\(i = 1, \\ldots, I\\) subjects in the discovery sample\n\\(x_{1g}, \\ldots, x_{Ig}\\) observed quantitative level of the expression of gene \\(g\\) in the \\(I\\) subjects\n\\(y_{1}, \\ldots, y_{I}\\) binary class labels for the \\(I\\) subjects\n\\(z_g = z_g (x_{1g}, \\ldots, x_{Ig}, y_{1}, \\ldots, y_{I})\\) a statistic used to select, or “discover” biomarkers. For example the absolute value of a t-statistic, the AUC or the fold change. We assume that larger values of the statistic are indicative of the signal we try to discover.\n\\(H_{0g}\\) is the event that for gene \\(g\\) there is no signal, that is if the two classes have identical distributions for the expression \\(x\\).\n\\(p_g = P ( z_g &gt; c | H_{0g})\\) p-value.\n\n\n\nData\nContinuous genomic feature: gene expression microarray readout in the TCGA study\nBinary phenotype (optimal surgical debulking)\n\nlibrary(curatedOvarianData)\nlibrary(ROCR)\ndata(TCGA_eset)\nXX = as.matrix(cbind(exprs(TCGA_eset)))\nYY = 1 * as.vector(pData(TCGA_eset)[,\"debulking\"]==\"optimal\")\nXX = XX[,!is.na(YY)]; \nYY = YY[!is.na(YY)]\n\nXXX = XX\nYYY = YY\n# subset\nsubs = 1:100\nXX = XX[,subs]; YY = YY[subs]\n\n\n\nDistribution of p-values\nWe next create two sets of summary scores. ScoresSub yields the four metrics computed on the first 100 patients, while ScoresAll gives the four metrics computed on the entire set of patients.\n\nsource(\"RScripts/Scores.R\")\nScoresSub = CompScores(XX,YY)\nScoresAll = CompScores(XXX,YYY)\n\nA useful place to start a discussion about multiple testing are the histograms of the p-values obtained with the t-test.\n\npar(mfrow = c(1, 2), pty = \"s\")\nhist(exp(-ScoresSub[,\"nlpvalueT\"]),\n     main=\"Subset\",xlab=\"p-value\")\nhist(exp(-ScoresAll[,\"nlpvalueT\"]),\n     main=\"Full Set\",xlab=\"p-value\")\n\n\n\n\nHistograms of P-values, for the 100 patient subset (left) and Entire Set\n\n\n\n\n\npar(mfrow = c(1, 2), pty = \"s\")\nplot(ecdf(exp(-ScoresSub[,\"nlpvalueT\"])),\n     main=\"Subset\",xlab=\"p-value\",ylab=\"Empirical CDF\"); abline(0,1)\nplot(ecdf(exp(-ScoresAll[,\"nlpvalueT\"])),\n     main=\"Full Set\",xlab=\"p-value\",ylab=\"Empirical CDF\" ); abline(0,1)\n\n\n\n\nEmpirical CDFs of P-values, for the 100 patient subset (left) and Entire Set\n\n\n\n\n\n\n\n\n\n\nHigher Criticism\n\n\n\nReview: if the null hypothesis is correct, the sampling distribution of the p-value is uniform in (0,1). “Sampling distribution” refers to hypothetical repetitions of the same experiment, in this case under the null.\n\nThese histograms show a single experiment. The distribution arises from variation across biomarkers. Can we still learn something useful about the frequentist multiple testing problem?\nHow would you test for the “global null”, that is the scenario where each and every biomarker is independent of the debulking status?\n\n\n\nHint: @Donoho2015ss"
  },
  {
    "objectID": "L10-fdr.html#false-discovery-rates",
    "href": "L10-fdr.html#false-discovery-rates",
    "title": "Lecture 10: False Discovery Rates",
    "section": "False Discovery Rates",
    "text": "False Discovery Rates\nA simple way to think about the discovery process is to focus on a list of promising candidates (or “discoveries”), as we did in our previous lecture. If we know the true data generating model for each gene, we could, for example, look at this table:\nIt is common to study the proportion \\(R_0/R\\) of discoveries for which the true data generating model is null.\n\n\n\n\n\n\nNote\n\n\n\n\\(R_0/R\\) is unknown. It depends on both the data and the parameter (the vector of indicators of whether eagh gene is null)\n\nWhen is \\(R_0/R\\) an appropriate quantity to focus on?\n\n\n\nThis parameter can be estimated from a couple of different perspectives. If you are interested in evaluating the list generating process you may be interested in a frequentist expectation. Bounds can be obtained using methods like Benjamini-Hochberg (see below). If your focus is on the actual list rather than the procedure, Bayesian estimates may be your choice.\nWe review many of the connections here: @muel:parm:rice:2007\n\n\nFrequentist Definition of FDR\n\n\n\nThe Benjamini-Hochberg Algorithm\n\n\n\nrankedPValuesSub = sort( exp(-ScoresSub[,\"nlpvalueT\"]) )\nrankedPValuesAll = sort( exp(-ScoresAll[,\"nlpvalueT\"]) )\npar(mfrow = c(1, 2), pty = \"s\")\nplot( (1:10)/length(rankedPValuesSub), rankedPValuesSub[1:10],\n      xlab=\"Rank/NGenes\", ylab=\"p-value\")\nabline(0,.07)\nplot( (1:30)/length(rankedPValuesAll), rankedPValuesAll[1:30],\n      xlab=\"Rank/NGenes\", ylab=\"p-value\" )\nabline(0,.07)\n\n\n\n\nBenjamini-Hochberg Plots\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHow would you comment these results?\n\n\n\n\n\nEmpirical Null Distribtution of Scores\nIt is simple to permute the labels of the subjects and recompute the scores. After permutation, for each gene, the link between expression and debulking has been broken. Discoveries are now random. We will look at a single permutation for illustration. As the number of features is large a single permutation can give reasonable indications. In a real application we may want to use multiple permutation and average over the inferential results, particularly if we are interested in events with small probability.\n\nset.seed(1)\nYYNull = YY[ sample(1:length(YY)) ]\nScoresSubNull = CompScores(XX,YYNull)\n\nset.seed(1)\nYYYNull = YYY[ sample(1:length(YYY)) ]\nScoresAllNull = CompScores(XXX,YYYNull)\n\n\nacut = .6\naucDiscAll = ScoresAll[,\"AUC\"]&gt;acut\naucDiscAllNull = ScoresAllNull[,\"AUC\"]&gt;acut\ntable(aucDiscAll)\n\naucDiscAll\nFALSE  TRUE \n13076    28 \n\ntable(aucDiscAllNull)\n\naucDiscAllNull\nFALSE  TRUE \n13103     1 \n\n\n\n\n\n\n\n\nNote\n\n\n\n\nis it correct to conclude that of the 28 discovery, only 1 is likely false?\nwhat is 1/28 and estimate of?\n\n\n\n\n\n\nEmpirical Bayes estimate of the false discovery rate:\nEmpirical Bayes FDR makes the 1/28 story a bit more formal. The thinking is now conditional on the observed set of data, specifically the observed set of scores, the \\(z\\)’s. The \\(z\\)’s can coincide with the p-values, but this logic does not require p-values, so the p-value calculation adds an unnecessary step.\nDefine \\(F(z) = P ( z_g \\leq z)\\) to the the true marginal distribution of the scores, and \\(\\bar F(z) = 1 - F(z) = P ( z_g &gt; z)\\). Now restrict attention to the genes whose true generating model is null and let \\(\\bar F_0(z) = 1 - F_0(z) = P ( z_g &gt; z | H_{og})\\). In a genemo where \\(p_A\\) genes are from some alternative (each gene can have its own!) and the remaining \\(1-p_A\\) are from the same null, the unknown proportion of false discoveries can be rewritten as:\n\\[\n\\frac{R_0}{R} = \\frac{ (1-p_A) * \\bar F_0 (z)}{(1-p_A) * \\bar F_0 (z) + p_A \\bar F_A (z) } =\\frac{  (1-p_A) \\bar F_0 (z)}{ \\bar F (z) } \\approx\\frac{ \\bar F_0 (z)}{ \\bar F (z) }\n\\]\nIn EB, the denominator, for any given cutoff, can be estimated empirically from the geneome-wide distribution of \\(z_g\\)’s. Just don’t pick the cutoff so that the list is empty.\nThe numerator is a bit trickier. If the disctribution of the \\(z\\)’s under the null is known (as is the case for example with \\(z\\)-scores for which normality can be trusted, \\(\\bar F_0 (z)\\) can be estimated that way. If not, one approach is to use the geneome-wide distribution of \\(z_g\\)’s after a permutation that mimics the global null. \\(p_A\\) is not identifiable w/out parametric / smoothness assumptions on the distributions of the \\(z\\)’s. A surprisingly useful approximation is \\(1-p_A = 1\\), which gives a conservative bounds to EF FDR, but often a reasonably realistic one.\n@Efron2003as\n\n\n\n\n\n\nNote\n\n\n\n\ntie this back to the 1/28 story\n\n\n\n\n\n\nEmpirical Bayes estimate of the local FDR\nLet’s look at estimates of densities corresponding to \\(F\\) and \\(F_0\\). These densities are normalized to integrate to \\(1\\).\n\nplot(density(ScoresAllNull[,\"nlpvalueT\"]),col=gray(.7),lwd=4,xlim=c(0,6),\n     main=\"\",xlab=\"z score\")\nlines(density(ScoresAll[,\"nlpvalueT\"]),col=2,lwd=4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ndoes this figure suggests a quick and dirty way of estimating \\(1-p_A\\)? Think through the assumptions would would be making.\n\n\n\nThis figure does suggest a way of evaluating the false discovery rate specifically for discoveries at and around a score of \\(z\\). Imagine you have estimates \\(\\hat f\\) and \\(\\hat f_0\\).\n\\[\n\\text{fdr}(z) = \\frac{ (1-\\hat p_A) * \\hat f_0 (z)}{(1-\\hat p_A) * \\hat f_0 (z) + \\hat p_A f_A (z) } =\\frac{  (1-\\hat p_A) \\hat f_0 (z)}{ \\hat f (z) } \\approx\\frac{ \\hat f_0 (z)}{ \\hat f (z) }\n\\] ### Summary\nIf you can trust the assumptions behind the p-value calculation, then:\nelse:\n\n\n\nAddendum: Familywise Error Control\nA different way of thinking about multiple testing is to control the probability of falsely rejecting any null hypothesis (Familywise Error Control).\n\n\n\n\n\n\nNote\n\n\n\nHow do you decide whether FDR or FEC is a better fit for your analysis?\n\n\nThe Bonferroni method provides a bound to familywise error. Here is an exampe of how it works."
  },
  {
    "objectID": "L10-fdr.html#references",
    "href": "L10-fdr.html#references",
    "title": "Lecture 10: False Discovery Rates",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "L8-timetoevent.html#time-to-event-biomarkers",
    "href": "L8-timetoevent.html#time-to-event-biomarkers",
    "title": "Lecture 8: Time to Event Data",
    "section": "Time-to-Event Biomarkers",
    "text": "Time-to-Event Biomarkers\nWe will now look at time-to-event outcomes. In many clinical applications, the researcher will have access to both whether or not an event occurred, but the also the event occurred. Only considering one of the two pieces of information will result in an either incomplete or incorrect analysis of a problem of interest. Being able to use both types of data results in better inferences.\n\nCensored Data\nAn important new concept in this lecture is that of censored data. For example, the ovarian cancer studies considered in curatedOvarianData, inluding Yoshihara B, only followed patient for a limited period of time. As a result, the time elapsed between diagnosis and death (survival time) is known for some but not for all patients. The outcome data includes “days_to_death” and “vital_status”. Let’s take a look.\n\nlibrary(curatedOvarianData)\ndata(GSE32063_eset)\nlibrary(survival)\nhead(cbind(pData(GSE32063_eset)[,\"days_to_death\"],\n           pData(GSE32063_eset)[,\"vital_status\"]))\n\n     [,1]   [,2]      \n[1,] \"780\"  \"living\"  \n[2,] \"1110\" \"living\"  \n[3,] \"600\"  \"deceased\"\n[4,] \"2910\" \"living\"  \n[5,] \"1710\" \"deceased\"\n[6,] \"810\"  \"deceased\"\n\n\nThe vital status variable captures whether a patient was alive at the end of the study, in which case the days-to-death variable is a lower bound to the time . The jargon for this in biostat is that the time-to-the event is “right censored”. Censored data will require different statistical approaches (e.g. they come with a different likelihood function) compared to non-censored data. Ignoring censoring can lead to substantial biases. Thinking hard about the censoring mechanism is also very important.\nThis is a commonly used way to encode the censoring information:\n\nSurvObj = \n  Surv( time = pData(GSE32063_eset)[,\"days_to_death\"], \n        event = pData(GSE32063_eset)[,\"vital_status\"]==\"deceased\")\nhead(SurvObj)\n\n[1]  780+ 1110+  600  2910+ 1710   810 \n\n\n\n\n\nSurvival and Hazard Functions\nA quick reminder of the terminology: the survival function is the probability of surviving until time \\(t\\). The hazard \\(h\\), or intensity, is the rate of occurrence of the event relative to the number of individual still available to experience it.\n\\[\\begin{eqnarray*}\nS(t) & = & P ( \\mbox{Event occurs after time t}) \\\\\nF(t) & = & 1 - S(t) \\\\\ndF(t) / dt & = & f(t) \\\\\nh(t) & = & f(t) / S(t)\n\\end{eqnarray*}\\]\nYou can go back and forth between \\(h\\) and \\(F\\) under smoothenss conditions.\nTo check you followed the logic so far, say \\(S(t)\\) depends on some parameters \\(\\theta\\) and try to write down the likelihood function for \\(\\theta\\) the six observations in the code chunk just above.\n\n\nKaplan-Maier Construction\nThe Kaplan-Maier algorithm provides a nonparametric maximum likelihood estimate of the survival function for censored data. It is the counterpart of the empirical survival function (i.e. one minus the empirical c.d.f.) which we may use in fully observed data.\nThe following plot yields the Kaplan-Meier curve. The survfit functions produces this if you set up a “regression” only including the intercept.\n\nlibrary(survminer)\nkm.as.one = survfit (SurvObj ~ 1)\nggsurvplot(km.as.one,data=SurvObj,\n           risk.table.fontsize = 4, break.time.by = 365,\n           tables.theme = theme_cleantable(), \n           axes.offset = FALSE, tables.y.text = FALSE,\n           risk.table = \"nrisk_cumcensor\")\n\n\n\n\nKaplan-Meier Curve\n\n\n\n\nThe Kaplan Meier learning tool and associated Kaplan Meier curves: an introduction tutorial are a good way to get a sense for how KM works, with code. Check out the “worse and best case scenario” figures in the tutorial. They give you a sense for the extra uncertainty brought in by censoring. This uncertainty is in addition to the sampling uncertainty we are all accustomed to. Another Introduction to Survival Analysis using R.\n\nNext, this is the same population split by debulking status.\n\nlibrary(survminer)\nDebulking = pData(GSE32063_eset)[,\"debulking\"]\nkm.by.debulking = survfit (SurvObj ~ Debulking)\nggsurvplot(km.by.debulking,data=SurvObj,\n           risk.table = \"nrisk_cumcensor\",conf.int = TRUE,\n           risk.table.fontsize = 4, break.time.by = 365,\n           tables.theme = theme_cleantable(), \n           axes.offset = FALSE, tables.y.text = FALSE)\n\n\n\n\nKaplan-Meier Curve by Debulking Status"
  },
  {
    "objectID": "L8-timetoevent.html#modeling-dependence-between-a-biomarker-and-a-censored-outcome",
    "href": "L8-timetoevent.html#modeling-dependence-between-a-biomarker-and-a-censored-outcome",
    "title": "Lecture 8: Time to Event Data",
    "section": "Modeling Dependence Between a Biomarker and a Censored Outcome",
    "text": "Modeling Dependence Between a Biomarker and a Censored Outcome\nWe normally visualize dependence via scatterplots. In this case the response variable is censored, so a scatterplot might look something like this.\n\npendant.plot = function(time,status,biomarker){\n  TT = max(time)*1.17\n  plot(biomarker[status==\"deceased\"],time[status==\"deceased\"],xlab=\"Biomarker\",ylab=\"Event Time\",pch=16,cex=2,xlim=c(min(biomarker),max(biomarker)),ylim=c(min(time),max(time)))\n  points(biomarker[status==\"living\"],time[status==\"living\"],pch=1,cex=2)\n  segments(biomarker[status==\"living\"],time[status==\"living\"],\n           biomarker[status==\"living\"],rep(TT,sum(status==\"living\")))\n}\npendant.plot(time=pData(GSE32063_eset)[,\"days_to_death\"],\n          status=pData(GSE32063_eset)[,\"vital_status\"],\n          biomarker=exprs(GSE32063_eset)[\"ZNF487\",])\n\n\n\n\nScatterplot of survival time by ZNF487 expression\n\n\n\n\n\n\nConcordance Index\nThere is a popular way to compute a nonparametric measure of dependence that accounts for this type of censoring: the concordance index. The basic building block are concordant pairs: a pair of patients is called concordant if the biomarker is higher for the patient who experiences the event at a later timepoint. With censored data, we exclude all the pairs for which it is not possible to established whether they are concordant or not. The concordance probability (C-index) is the proportion of concordant pairs among all pairs of subjects. Similar to the AUC, 50 percent represents no dependence. A C-index above 50 percent indicates a negative dependence and a value below 50 percent indicates a positive dependence. For details see What is Harrell’s C-index?\nLet’s look at ZNF487:\n\nconcordance(SurvObj ~ exprs(GSE32063_eset)[\"ZNF487\",])\n\nCall:\nconcordance.formula(object = SurvObj ~ exprs(GSE32063_eset)[\"ZNF487\", \n    ])\n\nn= 40 \nConcordance= 0.6389 se= 0.05912\nconcordant discordant     tied.x     tied.y    tied.xy \n       253        143          0          8          0 \n\n\nThe C-index was introduced to measure the discrimination of a risk prediction model, in which case the prediction is a real or ordinal valued risk score, and the model works well if low risk goes with longer survival.\n\n\n\nLog Hazard Modeling\nThe next level of analysis is regression. The most common way to model time-to-event data, with or without censoring, is via hazard (or intensity) functions.\n@KraghAndersen2021sim provide a thoughtful and concise introduction to time-to-event data. Highly recommended.\n\n\nExponential and Weibull Time-to-Event Distributions\nLet’s start our discussion by calculating the hazard function for Exponential and Weibull distribution.\nThe Weibull fits a lot of cancer survival data fairly well. @Plana2022nc looks at Weibull fit across hundreds of studies —very interesting work.\nThe hazard of the weibull is a polynomial function of time. The \\(v\\) parameter controls whether the event rate is slowing down or picking up speed with time. \\(\\lambda\\) acts as an intercept for hazard. A popular tactic is to model \\(log h\\), via \\(\\log \\lambda\\) as a function of the biomarker.\nTo illustrate this, we will consider the POSTN gene within the GSE32063_eset dataset. In the coding chunk that follows, we will consider XX as the gene expression and XXgmedian as the binary variable created through dichotomizing the expression values at the median.\n\nlibrary(curatedOvarianData)\ndata(GSE32063_eset)\nlibrary(survival)\nGeneName = \"POSTN\"\nXX = exprs(GSE32063_eset)[GeneName,]\nXXgmedian = 1 * ( XX &gt; median(XX) )\nSurvObj = \n  Surv( time = pData(GSE32063_eset)[,\"days_to_death\"], \n        event = pData(GSE32063_eset)[,\"vital_status\"]==\"deceased\")\nPOSTN.frame = data.frame(time = pData(GSE32063_eset)[,\"days_to_death\"], \n              event = pData(GSE32063_eset)[,\"vital_status\"]==\"deceased\",\n              expression = XX,\n              gtmedian = XXgmedian)\n\nThe next yields the scatterplot and the Kaplan-Meier curves stratified by an indicator of whether the biomarker exceeds the population median (with and w/out confidence bands), for illustration.\n\npendant.plot(time=pData(GSE32063_eset)[,\"days_to_death\"],\n          status=pData(GSE32063_eset)[,\"vital_status\"],\n          biomarker=exprs(GSE32063_eset)[\"POSTN\",])\nkm.by.gene = survfit (SurvObj ~ XXgmedian)\nggsurvplot(km.by.gene,data=POSTN.frame)\n\n\n\n\nKaplan-Meier Curve on Median Cut-off\n\n\n\n\n\n\n\nKaplan-Meier Curve on Median Cut-off\n\n\n\nggsurvplot(km.by.gene,data=POSTN.frame,conf.int=TRUE)\n\n\n\n\nKaplan-Meier Curve on Median Cut-off\n\n\n\n\n\nThe following gives the survival concordance objects.\n\nconcordance(SurvObj ~ XXgmedian, reverse=TRUE)\n\nCall:\nconcordance.formula(object = SurvObj ~ XXgmedian, reverse = TRUE)\n\nn= 40 \nConcordance= 0.5821 se= 0.06193\nconcordant discordant     tied.x     tied.y    tied.xy \n       137         72        187          4          4 \n\nconcordance(SurvObj ~ XX, reverse=TRUE)\n\nCall:\nconcordance.formula(object = SurvObj ~ XX, reverse = TRUE)\n\nn= 40 \nConcordance= 0.6389 se= 0.07398\nconcordant discordant     tied.x     tied.y    tied.xy \n       253        143          0          8          0 \n\n\nThe loss of concordance gives you one way to think about the information loss from dichotimization.\n\nThen, we can call out the Cox-Proportional Hazards Model for both the median cut-off variable and the entire gene expression variable. This is a concise introduction to assumptions and interpretation in Cox Proportional Hazards Regression Analysis\n\nsummary(coxph(SurvObj~XXgmedian))\n\nCall:\ncoxph(formula = SurvObj ~ XXgmedian)\n\n  n= 40, number of events= 22 \n\n            coef exp(coef) se(coef)     z Pr(&gt;|z|)  \nXXgmedian 0.7955    2.2156   0.4544 1.751     0.08 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n          exp(coef) exp(-coef) lower .95 upper .95\nXXgmedian     2.216     0.4513    0.9092     5.399\n\nConcordance= 0.582  (se = 0.062 )\nLikelihood ratio test= 3.18  on 1 df,   p=0.07\nWald test            = 3.06  on 1 df,   p=0.08\nScore (logrank) test = 3.22  on 1 df,   p=0.07\n\n\n\nsummary(coxph(SurvObj~XX))\n\nCall:\ncoxph(formula = SurvObj ~ XX)\n\n  n= 40, number of events= 22 \n\n      coef exp(coef) se(coef)     z Pr(&gt;|z|)  \nXX 0.15808   1.17126  0.08006 1.975   0.0483 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n   exp(coef) exp(-coef) lower .95 upper .95\nXX     1.171     0.8538     1.001      1.37\n\nConcordance= 0.639  (se = 0.074 )\nLikelihood ratio test= 3.94  on 1 df,   p=0.05\nWald test            = 3.9  on 1 df,   p=0.05\nScore (logrank) test = 4.1  on 1 df,   p=0.04\n\n\n\n\n\n\n\n\nMetrics\n\n\n\n\nDoes this regression provide useful metrics for evaluating whether POSTN is a useful biomarker?\nWhat are some of their strengths and limitations?\n\n\n\n\nNow, we can also fit the Cox Proportional Hazards Model to POSTN, which is now a full continuous biomarker, and plot the predicted survival curve for an individual with a biomarker value of \\(5\\) for POSTN.\n\n\nfit &lt;- coxph(SurvObj ~ XX)\npar(pty = \"s\", mfrow = c(1,1))\nplot(survfit(fit, newdata=data.frame(XX = - 5)), xscale=365.25, xlab = \"Years\", ylab=\"Survival Probability\", col = c(1,3,3))\n\n\n\n\nCox Proportional Hazards Curve for Individual with POSTN Level of 5\n\n\n\n\n\n\n\n\n\n\n\\(Y|X\\) versus \\(X|Y\\)\n\n\n\nWith binary data, we operated by modeling class conditional distributions \\(X|Y\\), and converting to PPV using Bayes rule. With survival data we modeled \\(Y|X\\).\n\nWhat are some of the pros and cons of the two approaches?\nWhat is the equivalent to PPV in time-to-event data?"
  },
  {
    "objectID": "L8-timetoevent.html#references",
    "href": "L8-timetoevent.html#references",
    "title": "Lecture 8: Time to Event Data",
    "section": "References",
    "text": "References"
  }
]